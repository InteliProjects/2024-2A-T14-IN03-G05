{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJZtUGVIKfUQ"
      },
      "source": [
        "# Análise do Arquivo Players\n",
        "\n",
        "Este notebook é dedicado à análise da tabela **Players** fornecida pela IBM, que contém dados detalhados sobre os jogadores, incluindo informações sobre seus desempenho e seus respectivos resultados. O objetivo deste notebook é facilitar a visualização e a análise desses dados, proporcionando estatísticas essenciais para estudos e pesquisas.\n",
        "\n",
        "## Objetivo\n",
        "\n",
        "O objetivo deste notebook é fornecer uma análise detalhada dos dados de jogadores, ajudando a identificar padrões e tendências que possam ser úteis para diversas aplicações, como previsões de resultados e desempenho dos jogadores.\n",
        "\n",
        "## Como Usar Este Notebook\n",
        "\n",
        "1. **Configuração do Ambiente**:\n",
        "   - **Google Colab**: No Google Colab, será necessário fazer o upload das tabelas para o Google Drive e montar o drive no notebook.\n",
        "   - **Localmente**: Se for rodar o notebook localmente, é necessário baixar as tabelas e colocá-las no mesmo diretório do notebook ou ajustar os caminhos dos arquivos conforme necessário.\n",
        "\n",
        "2. **Instalação de Dependências**:\n",
        "   - Certifique-se de que todas as bibliotecas necessárias estão instaladas. Você pode instalar as dependências utilizando o seguinte comando:\n",
        "     ```python\n",
        "     !pip install -r requirements.txt\n",
        "     ```\n",
        "\n",
        "3. **Execução do Notebook**:\n",
        "   - Siga as células de código sequencialmente para garantir que todas as etapas sejam executadas corretamente. Cada seção do notebook está organizada para facilitar a compreensão e a análise dos dados.\n",
        "\n",
        "## Nesse Notebook Será Abordado\n",
        "\n",
        "1. **Pré-processamento de Dados**:\n",
        "   - Limpeza dos dados, incluindo o tratamento de valores ausentes e a remoção de duplicatas.\n",
        "   - Normalização e padronização dos dados utilizando técnicas como `StandardScaler` e `MinMaxScaler`.\n",
        "   - Codificação de variáveis categóricas utilizando `LabelEncoder`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISE4gfz7LMsa"
      },
      "source": [
        "# Dependências\n",
        "Para rodar o notebook de forma local, é recomendado que inicie uma venv (ambiente virtual) e instale as dependências.\n",
        "\n",
        "Se estiver utilizando o Google Colab, pule esta etapa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xV1e2ukqLRNo",
        "outputId": "41c1faf0-a482-4e8d-ae98-12410830f742"
      },
      "outputs": [],
      "source": [
        "# Instala as dependências\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHk2tQqDLbmL"
      },
      "source": [
        "# Importando bibliotecas\n",
        "\n",
        "Aqui é importado as dependências necessárias para a executação do projeto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "Dnq8BzrWLgJb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd  # para ler, visualizar e printar informações do DataFrame\n",
        "import matplotlib.pyplot as plt  # para construir e customizar gráficos\n",
        "import seaborn as sns  # para visualizar gráficos\n",
        "import numpy as np  # para operações matemáticas e manipulação de arrays\n",
        "import math  # para executar operações matemáticas\n",
        "from scipy.stats.mstats import winsorize  # para realizar a winsorização\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder  # para pré-processamento de dados\n",
        "import statistics as sts  # para realizar cálculos estatísticos\n",
        "import matplotlib as mpl  # para customizações adicionais em gráficos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flHs8kgrLjRR"
      },
      "source": [
        "# Carregando o dataset\n",
        "\n",
        "Feita a importação do arquivo para leitura dos dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "fi2J6GBHLotZ"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('../../notebooks/data/players_nao_tratado.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K36vxKCnTviS"
      },
      "source": [
        "# Pré-processamento de dados do arquivo players\n",
        "O pré-processamento dos dados é uma etapa fundamental na construção de modelos preditivos eficazes. Ele garante que os dados estejam em uma forma adequada para análise, eliminando inconsistências, ajustando escalas e transformando variáveis para que possam ser utilizadas de forma eficiente pelos algoritmos de aprendizado de máquina.\n",
        "\n",
        "Nesta seção, será realizado uma série de procedimentos para preparar o dataset para as etapas de modelagem subsequentes. As etapas incluem o tratamento de valores ausentes, a remoção de outliers, a codificação de variáveis categóricas e a normalização de variáveis numéricas. Essas ações são essenciais para melhorar a qualidade dos dados e, consequentemente, a performance do modelo preditivo.\n",
        "\n",
        "Cada uma dessas etapas será detalhada a seguir, explicando as técnicas utilizadas e os motivos por trás de cada decisão tomada.\n",
        "\n",
        "## Objetivo do Pré-Processamento de Dados\n",
        "\n",
        "O principal objetivo desta seção é preparar os dados para análises subsequentes, garantindo que eles estejam completos, consistentes e prontos para modelagem. As etapas a seguir abordam o tratamento de valores ausentes, remoção de colunas irrelevantes, tratamento de outliers e transformação de variáveis.\n",
        "\n",
        "## Como Usar Este Notebook\n",
        "\n",
        "1. **Configuração do Ambiente**:\n",
        "   - **Google Colab**: Se estiver usando o Google Colab, faça o upload das tabelas para o Google Drive e monte o drive no notebook.\n",
        "   - **Localmente**: Se estiver rodando o notebook localmente, baixe as tabelas e coloque-as no mesmo diretório do notebook ou ajuste os caminhos dos arquivos conforme necessário.\n",
        "\n",
        "2. **Instalação de Dependências**:\n",
        "   - Certifique-se de que todas as bibliotecas necessárias estão instaladas no ambiente de execução. Para garantir isso, você pode utilizar um arquivo de dependências (como `requirements.txt`), ou instalar as bibliotecas manualmente.\n",
        "\n",
        "3. **Execução do Notebook**:\n",
        "   - Siga as células de código sequencialmente para garantir que todas as etapas sejam executadas corretamente. Ao final do pré-processamento, os dados estarão prontos para modelagem e análise.\n",
        "\n",
        "## Etapas do Pré-Processamento\n",
        "\n",
        "1. **Tratamento de Valores Ausentes**:\n",
        "   - A identificação de valores ausentes (missing values) é essencial para garantir a integridade dos dados. Nesta etapa, serão identificadas colunas com valores faltantes e os métodos de imputação ou remoção desses valores serão definidos. Dependendo do contexto, os valores ausentes podem ser preenchidos com a média, mediana, ou descartados.\n",
        "   \n",
        "2. **Exclusão de Colunas**:\n",
        "   - Algumas colunas podem não ser relevantes para a análise ou podem conter muitos valores ausentes. Neste caso, a exclusão dessas colunas se torna uma opção importante para garantir a qualidade do dataset e evitar viés nas análises.\n",
        "\n",
        "3. **Identificação de Outliers por Gráficos**:\n",
        "   - A visualização de dados por meio de gráficos, como boxplots, permite identificar a presença de outliers de forma visual. Isso ajuda a entender a distribuição das variáveis e identificar valores que se desviam significativamente do padrão esperado.\n",
        "\n",
        "4. **Identificação de Outliers Usando o IQR**:\n",
        "   - O método do intervalo interquartil (IQR) será utilizado para identificar outliers de maneira sistemática. Valores que estejam além de 1.5 vezes o IQR, abaixo do primeiro quartil ou acima do terceiro quartil, serão considerados outliers e tratados adequadamente.\n",
        "\n",
        "5. **Tratamento de Outliers por Winsorização**:\n",
        "   - Em vez de excluir outliers, que podem conter informações valiosas, utilizaremos a técnica de **winsorização**. Ela limita os valores extremos dentro de um intervalo aceitável, substituindo-os por valores próximos ao limite superior ou inferior da distribuição, preservando assim a integridade do dataset sem remover dados.\n",
        "\n",
        "6. **Codificação de Variáveis Categóricas**:\n",
        "   - As variáveis categóricas, como o nome dos times ou outras características qualitativas, serão transformadas em uma forma numérica para que possam ser utilizadas por algoritmos de aprendizado de máquina. A técnica de **One-Hot Encoding** ou **Label Encoding** será utilizada para esse processo, dependendo do número de categorias e da necessidade do modelo.\n",
        "\n",
        "7. **Normalização dos Dados**:\n",
        "   - Para garantir que todas as variáveis numéricas estejam na mesma escala, aplicaremos a normalização ou padronização dos dados. Isso é particularmente importante para algoritmos que são sensíveis à escala das variáveis, como métodos baseados em distância (KNN, SVM, etc.). As técnicas de **MinMaxScaler** ou **StandardScaler** serão aplicadas conforme a necessidade da modelagem.\n",
        "\n",
        "## Resumo das Etapas\n",
        "\n",
        "Após o pré-processamento, os dados estarão limpos e prontos para modelagem. O tratamento de valores ausentes, a remoção ou ajuste de outliers e a transformação de variáveis categóricas garantem que os dados estejam em uma condição ideal para algoritmos de aprendizado de máquina. A normalização das variáveis numéricas assegura que as variáveis estejam na mesma escala, o que é fundamental para melhorar o desempenho dos modelos preditivos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTQrgvSmRAhc"
      },
      "source": [
        "Foi removido essas colunas, pois essas informações podem ser obtidas através de outras colunas no conjunto de dados. A soma ou combinação de outras colunas pode fornecer os mesmos valores ou informações equivalentes, tornando essas colunas redundantes para a análise. Ao eliminar essas colunas, o DataFrame fica mais enxuto e eficiente para o processamento e modelagem dos dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "YoVb88tRRp4I"
      },
      "outputs": [],
      "source": [
        "colunas_para_eliminar = [\n",
        "    'yellow_cards_overall',\n",
        "    'red_cards_overall',\n",
        "    'sm_minutes_played_recorded_overall',\n",
        "    'minutes_played_overall',\n",
        "    'appearances_overall',\n",
        "    'assists_overall',\n",
        "    'clean_sheets_overall',\n",
        "    'conceded_overall',\n",
        "    'shots_total_overall'\n",
        "]\n",
        "\n",
        "# Eliminando as colunas\n",
        "df = df.drop(columns=colunas_para_eliminar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzuRz_CDRyoh"
      },
      "source": [
        "As colunas mostradas abaixo que foram excluídas foram devido à falta de informações em todas as linhas, ou seja, não tinha informações. A exclusão dessas colunas foi necessária para garantir a análise correta dos dados, pois nelas havia a existências de todos os dados nulos ou com N/A."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "bTBMdz9sRy2v"
      },
      "outputs": [],
      "source": [
        "colunas_para_eliminar = [\n",
        "    'short_passes_per_game_overall',\n",
        "    'long_passes_per_game_overall',\n",
        "    'distance_travelled_per_game_overall',\n",
        "    'chances_created_per_game_overall',\n",
        "    'aerial_duels_per_game_overall',\n",
        "    'possession_regained_per_90_overall',\n",
        "    'possession_regained_total_overall',\n",
        "    'possession_regained_per90_percentile_overall',\n",
        "    'additional_info',\n",
        "    'tackles_successful_total_overall',\n",
        "    'through_passes_total_overall',\n",
        "    'through_passes_per_90_overall',\n",
        "    'long_passes_total_overall',\n",
        "    'long_passes_per_90_overall',\n",
        "    'long_passes_per90_percentile_overall',\n",
        "    'short_passes_total_overall',\n",
        "    'short_passes_per_90_overall',\n",
        "    'short_passes_per90_percentile_overall',\n",
        "    'chances_created_total_overall',\n",
        "    'chances_created_per_90_overall',\n",
        "    'chances_created_per90_percentile_overall',\n",
        "    'shots_per_goal_conceded_overall',\n",
        "    'xg_faced_per_90_overall',\n",
        "    'xg_faced_per90_percentile_overall',\n",
        "    'xg_faced_per_game_overall',\n",
        "    'xg_faced_total_overall',\n",
        "    'pressures_total_overall',\n",
        "    'pressures_per_90_overall',\n",
        "    'pressures_per90_percentile_overall',\n",
        "    'market_value',\n",
        "    'market_value_percentile',\n",
        "    'pen_save_percentage_overall',\n",
        "    'sm_minutes_played_per90_percentile_overall',\n",
        "    'aerial_duels_total_overall',\n",
        "    'aerial_duels_per_90_overall',\n",
        "    'aerial_duels_per90_percentile_overall',\n",
        "    'aerial_duels_won_percentage_overall',\n",
        "    'pen_committed_per90_percentile_overall',\n",
        "    'through_passes_per90_percentile_overall',\n",
        "    'tackles_successful_per90_percentile_overall',\n",
        "    'progressive_passes_total_overall',\n",
        "    'distance_travelled_total_overall',\n",
        "    'distance_travelled_per_90_overall',\n",
        "    'distance_travelled_per90_percentile_overall',\n",
        "    'hattricks_total_overall',\n",
        "    'three_goals_in_a_game_total_overall',\n",
        "    'three_goals_in_a_game_percentage_overall',\n",
        "    'man_of_the_match_total_overall',\n",
        "    'annual_salary_eur',\n",
        "    'annual_salary_eur_percentile',\n",
        "    'annual_salary_gbp',\n",
        "    'annual_salary_usd'\n",
        "]\n",
        "\n",
        "# Eliminando as colunas\n",
        "df = df.drop(columns=colunas_para_eliminar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTnQgGT7ScoP"
      },
      "source": [
        " Removemos os dados relacionados aos goleiros, pois eles não contribuem para a análise preditiva de jogadores de outras posições. Por exemplo, a métrica saves_total_overall, que contabiliza o número de defesas realizadas por um jogador durante o jogo, é específica para goleiros e não tem relevância na avaliação de outros atletas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "VYqUMTcfScEx"
      },
      "outputs": [],
      "source": [
        "colunas_para_eliminar = [\n",
        "    'saves_total_overall',\n",
        "    'save_percentage_percentile_overall',\n",
        "    'sm_goals_conceded_total_overall',\n",
        "    'shots_faced_per_90_overall',\n",
        "    'shots_faced_per90_percentile_overall',\n",
        "    'save_percentage_overall',\n",
        "    'inside_box_saves_total_overall',\n",
        "    'punches_total_overall',\n",
        "    'punches_per_90_overall',\n",
        "    'saves_per_90_overall',\n",
        "    'shots_faced_total_overall',\n",
        "    'pens_saved_total_overall',\n",
        "    'punches_total_overall',\n",
        "    'punches_per_90_overall',\n",
        "    'punches_per90_percentile_overall'\n",
        "]\n",
        "\n",
        "# Eliminando as colunas\n",
        "df = df.drop(columns=colunas_para_eliminar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Hz83f32Sv2q"
      },
      "source": [
        "As colunas como birthday, birthday_GMT, league, season, e nationality foram excluídas porque fornecem informações que não impactam diretamente a análise de desempenho dos jogadores em campo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "GBTKuL96SwXV"
      },
      "outputs": [],
      "source": [
        "colunas_para_eliminar = [\n",
        "    'birthday',\n",
        "    'birthday_GMT',\n",
        "    'league',\n",
        "    'season',\n",
        "    'nationality'\n",
        "]\n",
        "\n",
        "# Eliminando as colunas\n",
        "df = df.drop(columns=colunas_para_eliminar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNTloSADUR95"
      },
      "source": [
        "\n",
        "Essas colunas foram excluídas porque os dados que elas fornecem podem ser derivados de outras informações já presentes na tabela, evitando redundância. Com base em métricas agregadas e mais amplas, como estatísticas gerais de desempenho, podemos calcular as mesmas informações de forma mais eficiente. Dessa forma, simplificamos o conjunto de dados sem perder informações relevantes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "qYzl8qdfURvH"
      },
      "outputs": [],
      "source": [
        "colunas_para_eliminar = [\n",
        "    'assists_per_game_overall',\n",
        "    'passes_per_game_overall',\n",
        "    'passes_completed_per_game_overall',\n",
        "    'key_passes_per_game_overall',\n",
        "    'crosses_per_game_overall',\n",
        "    'tackles_per_game_overall',\n",
        "    'tackles_successful_per_game_overall',\n",
        "    'dispossesed_per_game_overall',\n",
        "    'pressures_per_game_overall',\n",
        "    'saves_per_game_overall',\n",
        "    'interceptions_per_game_overall',\n",
        "    'dribbles_successful_per_game_overall',\n",
        "    'shots_off_target_per_game_overall',\n",
        "    'dribbles_per_game_overall',\n",
        "    'shots_on_target_per_game_overall',\n",
        "    'aerial_duels_won_per_game_overall',\n",
        "    'shots_per_game_overall',\n",
        "    'dribbled_past_per_game_overall',\n",
        "    'blocks_per_game_overall',\n",
        "    'clearances_per_game_overall',\n",
        "    'pen_committed_per_game_overall',\n",
        "    'hit_woodwork_per_game_overall',\n",
        "    'offsides_per_game_overall',\n",
        "    'xa_per_game_overall',\n",
        "    'npxg_per_game_overall',\n",
        "    'fouls_drawn_per_game_overall',\n",
        "    'fouls_committed_per_game_overall',\n",
        "    'duels_per_game_overall',\n",
        "    'duels_won_per_game_overall',\n",
        "    'accurate_crosses_per_game_overall',\n",
        "    'goals_involved_per_90_overall',\n",
        "    'assists_per_90_overall',\n",
        "    'goals_per_90_overall',\n",
        "    'goals_per_90_home',\n",
        "    'goals_per_90_away',\n",
        "    'conceded_per_90_overall',\n",
        "    'cards_per_90_overall',\n",
        "    'passes_per_90_overall',\n",
        "    'passes_completed_per_90_overall',\n",
        "    'tackles_per_90_overall',\n",
        "    'shots_per_90_overall',\n",
        "    'shots_on_target_per_90_overall',\n",
        "    'shots_off_target_per_90_overall',\n",
        "    'tackles_successful_per_90_overall',\n",
        "    'interceptions_per_90_overall',\n",
        "    'crosses_per_90_overall',\n",
        "    'key_passes_per_90_overall',\n",
        "    'dribbles_per_90_overall',\n",
        "    'dribbles_successful_per_90_overall',\n",
        "    'dribbled_past_per_90_overall',\n",
        "    'blocks_per_90_overall',\n",
        "    'clearances_per_90_overall',\n",
        "    'pen_committed_per_90_overall',\n",
        "    'hit_woodwork_per_90_overall',\n",
        "    'offsides_per_90_overall',\n",
        "    'xa_per_90_overall',\n",
        "    'npxg_per_90_overall',\n",
        "    'fouls_drawn_per_90_overall',\n",
        "    'fouls_committed_per_90_overall',\n",
        "    'xg_per_90_overall',\n",
        "    'aerial_duels_won_per_90_overall',\n",
        "    'duels_per_90_overall',\n",
        "    'duels_won_per_90_overall',\n",
        "    'dispossesed_per_90_overall',\n",
        "    'accurate_crosses_per_90_overall'\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnfZahTPUjOF"
      },
      "source": [
        "\n",
        "As colunas de percentis listadas podem ser obtidas por meio da divisão de métricas específicas já presentes no conjunto de dados. Por exemplo, a porcentagem de passes completos por jogo pode ser calculada dividindo o número total de passes completados pelo número total de passes tentados. Dessa forma, ao calcular essas porcentagens a partir das informações existentes, podemos evitar redundância e simplificar o conjunto de dados, mantendo a análise objetiva e eficiente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "Bx-5PRbUUjrO"
      },
      "outputs": [],
      "source": [
        "# Atualizando a lista de colunas para eliminar\n",
        "colunas_para_eliminar = [\n",
        "    'assists_per90_percentile_overall',\n",
        "    'passes_per90_percentile_overall',\n",
        "    'pass_completion_rate_percentile_overall',\n",
        "    'passes_completed_per90_percentile_overall',\n",
        "    'shots_per90_percentile_overall',\n",
        "    'shots_on_target_per90_percentile_overall',\n",
        "    'shots_off_target_per90_percentile_overall',\n",
        "    'tackles_per90_percentile_overall',\n",
        "    'interceptions_per90_percentile_overall',\n",
        "    'cross_completion_rate_percentile_overall',\n",
        "    'crosses_per90_percentile_overall',\n",
        "    'dribbles_per90_percentile_overall',\n",
        "    'conceded_per90_percentile_overall',\n",
        "    'dribbled_past_per90_percentile_overall',\n",
        "    'dribbles_successful_per90_percentile_overall',\n",
        "    'dribbles_successful_percentage_percentile_overall',\n",
        "    'blocks_per90_percentile_overall',\n",
        "    'shot_conversion_rate_percentile_overall',\n",
        "    'minutes_played_percentile_overall',\n",
        "    'matches_played_percentile_overall',\n",
        "    'min_per_goal_percentile_overall',\n",
        "    'min_per_conceded_percentile_overall',\n",
        "    'xa_per90_percentile_overall',\n",
        "    'npxg_per90_percentile_overall',\n",
        "    'fouls_drawn_per90_percentile_overall',\n",
        "    'fouls_committed_per90_percentile_overall',\n",
        "    'xg_per90_percentile_overall',\n",
        "    'average_rating_percentile_overall',\n",
        "    'clearances_per90_percentile_overall',\n",
        "    'hit_woodwork_per90_percentile_overall',\n",
        "    'offsides_per90_percentile_overall',\n",
        "    'aerial_duels_won_per90_percentile_overall',\n",
        "    'duels_won_per90_percentile_overall',\n",
        "    'duels_per90_percentile_overall',\n",
        "    'dispossesed_per90_percentile_overall',\n",
        "    'accurate_crosses_per90_percentile_overall',\n",
        "    'games_started_percentile_overall',\n",
        "    'games_subbed_in_percentile_overall',\n",
        "    'games_subbed_out_percentile_overall',\n",
        "    'goals_involved_per90_percentile_overall',\n",
        "    'goals_per90_percentile_overall',\n",
        "    'goals_per90_percentile_away',\n",
        "    'goals_per90_percentile_home',\n",
        "    'clean_sheets_percentage_percentile_overall',\n",
        "    'min_per_card_percentile_overall',\n",
        "    'cards_per90_percentile_overall',\n",
        "    'booked_over05_percentage_percentile_overall'\n",
        "]\n",
        "\n",
        "# Eliminando as colunas\n",
        "df = df.drop(columns=colunas_para_eliminar)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7H-Q31OlGfg",
        "outputId": "8c76c7e5-c6b8-4869-90a3-86a4b3dc12ee"
      },
      "outputs": [],
      "source": [
        "colunas = df.columns\n",
        "print(colunas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx9z9gy1WbJb"
      },
      "source": [
        "Foi feita a remoção de jogadores que não participaram de nenhuma partida, pois esses jogadores apresentavam um número elevado de dados nulos e valores \"N/A\", o que poderia comprometer a qualidade do modelo. Para isso, substituímos os valores nulos nas colunas de aparições por 0 e filtramos o DataFrame para manter apenas os jogadores que têm pelo menos uma aparição, seja em casa ou fora."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "Vjtzv1QjDyaj"
      },
      "outputs": [],
      "source": [
        "# Substitui valores nulos por 0 nas colunas de aparições\n",
        "df['appearances_home'] = df['appearances_home'].fillna(0)\n",
        "df['appearances_away'] = df['appearances_away'].fillna(0)\n",
        "\n",
        "# Filtra o DataFrame para remover os jogadores com aparições em casa e fora de casa igual a 0\n",
        "df = df[(df['appearances_home'] + df['appearances_away']) > 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av9B6uVxXLs7"
      },
      "source": [
        "Separando os goleiros em um DataFrame específico e removendo-os do DataFrame original foi uma etapa necessária para aprimorar a qualidade do modelo. Os goleiros desempenham funções muito diferentes dos outros jogadores em campo, o que pode distorcer as análises e os resultados do modelo se eles forem mantidos juntos com jogadores de campo. Ao isolar os goleiros, garantimos que suas características e desempenhos sejam avaliados de forma adequada e independente, melhorando assim a precisão e a relevância das análises realizadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "7UHV0E51Azcp"
      },
      "outputs": [],
      "source": [
        "# Separando os jogadores com position = 'Goalkeeper' em um novo DataFrame\n",
        "df_goalkeepers = df[df['position'] == 'Goalkeeper']\n",
        "\n",
        "# Removendo as linhas dos goleiros do DataFrame original\n",
        "df = df[df['position'] != 'Goalkeeper']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UzbuTdIXxsH"
      },
      "source": [
        "\n",
        "Substituir os nomes das posições por números usando um mapeamento, como o position_mapping, melhora a eficiência e a consistência dos dados. Números ocupam menos espaço e permitem operações de processamento mais rápidas em comparação com strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Fvhnw5p4tSf"
      },
      "outputs": [],
      "source": [
        "position_mapping = {\n",
        "    'Defender': 1,\n",
        "    'Midfielder': 2,\n",
        "    'Forward': 3\n",
        "    # Adicione mais posições conforme necessário\n",
        "}\n",
        "# Substituir os nomes das posições pelos números\n",
        "df['position'] = df['position'].replace(position_mapping)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rStYu7o8X9uG"
      },
      "source": [
        "Foi alterado o número da posição dos goleiro para 1, assim como foi alterado na dos outros jogadores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "Uft0_sGsYUEv"
      },
      "outputs": [],
      "source": [
        "df['position'] = df['position'].replace('Goalkeeper', 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUHZYRVcZg-J"
      },
      "source": [
        "Codificar categorias como clubes em IDs numéricos melhora a eficiência de processamento e análise de dados, pois simplifica a manipulação e comparação de dados. Além disso, reduz o uso de memória ao substituir strings por inteiros. Esse formato é ideal para algoritmos de machine learning e operações matemáticas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "xzf-mHcd5eI8"
      },
      "outputs": [],
      "source": [
        "df['Current Club'], unique_clubs = pd.factorize(df['Current Club'])\n",
        "\n",
        "# Adicionar 1 aos IDs para começar de 1 em vez de 0\n",
        "df['Current Club'] += 1\n",
        "\n",
        "# Criar o mapeamento dos IDs para os clubes\n",
        "club_id_mapping = pd.Series(index=range(1, len(unique_clubs) + 1), data=unique_clubs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SvxSo9LZiRj"
      },
      "source": [
        "Foi feito o mesmo com o data frame dos goleiros:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "nRFpEgWOZWZo"
      },
      "outputs": [],
      "source": [
        "# Codificar os clubes em df_goalkeepers\n",
        "df_goalkeepers['Current Club'], unique_clubs_goalkeepers = pd.factorize(df_goalkeepers['Current Club'])\n",
        "\n",
        "# Adicionar 1 aos IDs para começar de 1 em vez de 0\n",
        "df_goalkeepers['Current Club'] += 1\n",
        "\n",
        "# Criar o mapeamento dos IDs para os clubes\n",
        "club_id_mapping_goalkeepers = pd.Series(data=unique_clubs_goalkeepers, index=range(1, len(unique_clubs_goalkeepers) + 1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Tratamento de outliers\n",
        "Essa subseção foi feita a identificação e tratamento de outliers. Outliers são valores que se distanciam significativamente do restante dos dados, podendo distorcer análises e influenciar negativamente o desempenho do modelos preditivos. Dessa forma, é necessário identificar esses valores anômalos para decidir se eles devem ser tratados ou removidos, garantindo que as análises e modelos subsequentes sejam precisos e confiáveis.\n",
        "\n",
        "Nessa tabela, tratamos os outliers utilizando uma abordagem que envolveu a transformação das colunas categóricas em variáveis numéricas, facilitando o processo de detecção e manipulação dos outliers. Para essa transformação, foi utilizado o método Label Encoder, que converte as categorias em valores numéricos, atribuindo um número inteiro único para cada categoria. Essa transformação permitiu que os outliers fossem identificados e tratados de forma eficiente, melhorando a robustez dos modelos preditivos subsequentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# # Definindo features categóricas ou numéricas\n",
        "# colunas_numericas = []\n",
        "# colunas_categoricas = []\n",
        "\n",
        "# for each in df:\n",
        "#     coluna = df[each]\n",
        "#     if coluna.dtype in ['int64', 'float64']:\n",
        "#         coluna.fillna(0, inplace=True)\n",
        "#         colunas_numericas.append(coluna.name)\n",
        "#     elif coluna.dtype in ['object', 'category']:\n",
        "#         coluna.fillna(\"Sem dados\", inplace=True)\n",
        "#         colunas_categoricas.append(coluna.name)\n",
        "\n",
        "# # Tratamento de outliers\n",
        "# def tratar_outliers(df):\n",
        "#     for coluna in colunas_numericas:\n",
        "#         Q1 = df[coluna].quantile(0.25)\n",
        "#         Q3 = df[coluna].quantile(0.75)\n",
        "#         IQR = Q3 - Q1\n",
        "#         limite_inferior = Q1 - 1.5 * IQR\n",
        "#         limite_superior = Q3 + 1.5 * IQR\n",
        "#         outliers = (df[coluna] < limite_inferior) | (df[coluna] > limite_superior)\n",
        "#         media_coluna = df.loc[~outliers, coluna].mean()\n",
        "#         media_coluna = np.round(media_coluna)\n",
        "#         df.loc[outliers, coluna] = media_coluna\n",
        "#     return df\n",
        "\n",
        "# # Instanciando o LabelEncoder\n",
        "# le = LabelEncoder()\n",
        "\n",
        "# # Convertendo colunas categóricas para numéricas\n",
        "# for coluna in colunas_categoricas:\n",
        "#     df[coluna] = le.fit_transform(df[coluna])\n",
        "\n",
        "# # Chamando a função de tratamento de outliers\n",
        "# tratar_outliers(df)\n",
        "\n",
        "# # Salvando o DataFrame tratado em um arquivo CSV\n",
        "df.to_csv('../../notebooks/data/tratado/players_tratado.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXajp6Csykvz"
      },
      "source": [
        "## 2.6 Referências\n",
        "\n",
        "Está é uma seção de referências com relação as bibliotecas que utilizamos ao longo deste arquivo\n",
        "\n",
        "NUMPY. NumPy Documentation. Disponível em: <https://numpy.org/doc/>.\n",
        "\n",
        "‌PANDAS. pandas documentation. Disponível em: <https://pandas.pydata.org/docs/>.\n",
        "\n",
        "MATPLOTLIB. Matplotlib: Python plotting — Matplotlib 3.3.4 documentation. Disponível em: <https://matplotlib.org/stable/index.html>.\n",
        "\n",
        "‌SEABORN. seaborn: statistical data visualization — seaborn 0.9.0 documentation. Disponível em: <https://seaborn.pydata.org/>.\n",
        "\n",
        "‌SciPy documentation — SciPy v1.8.1 Manual. Disponível em: <https://docs.scipy.org/doc/scipy/>.\n",
        "\n",
        "‌PYTHON SOFTWARE FOUNDATION. Math — Mathematical Functions — Python 3.8.3rc1 Documentation. Disponível em: <https://docs.python.org/3/library/math.html>.\n",
        "\n",
        "‌SCIKIT-LEARN. scikit-learn: machine learning in Python. Disponível em: <https://scikit-learn.org/stable/>.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
