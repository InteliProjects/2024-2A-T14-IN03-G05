{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predição do Arquivo Players\n",
    "Este notebook é dedicado à implementação e análise de um modelo de classificação utilizando o algoritmo Random Forest para prever a probabilidade de jogadores marcarem gols com base em suas características, como desempenho do jogador, números de gols e outras métricas. O objetivo deste notebook é fornecer uma ferramenta para previsões, que pode ser usada para previsões de resultados.\n",
    "\n",
    "## Objetivo\n",
    "O objetivo desse notebook é fornecer previsões se um jogador marcará um gol em uma partida. Através de análise dos dados e do treinamento de um mondelo Randon Forest, buscando identificar padrões e caractéristicas que mais influenciam o desempenho dos jogadores.\n",
    "\n",
    "## Como usar Este Notebook\n",
    "\n",
    "\n",
    "1.   **Configuração do Ambiente:**\n",
    "      * **Google Colab:** No Google Colab, será necessário fazer o upload das tabelas para o Google Drive e montar o drive no notebook.\n",
    "      * **Localmente:** Se for rodar o notebook localmente, é necessário baixar as tabelas e colocá-las no mesmo diretório do notebook ou ajustar os caminhos dos arquivos conforme necessário.\n",
    "\n",
    "\n",
    "2.   **Instalação de Dependências:**\n",
    "       * Certifique-se de que todas as bibliotecas necessárias estão instaladas. Você pode instalar as dependências utilizando o seguinte comando:\n",
    "\n",
    "\n",
    "```\n",
    " !pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "3.   **Execução do Notebook:**\n",
    "      * Siga as células de código sequencialmente para garantir que todas as etapas sejam executadas corretamente. Cada seção do notebook está organizada para facilitar a compreensão e a análise dos dados.\n",
    "\n",
    "##Nesse Notebook Será Abordado\n",
    "1. **Preparação e Treinamento de Dados:**\n",
    "      * Seleção e preparação das features e da variável target a partir do dataset, incluindo o tratamento de dados ausentes e a padronização das variáveis.\n",
    "      * Implementação do modelo Random Forest para classificação dos jogadores com base em seu desempenho.\n",
    "\n",
    "           \n",
    "2. **Implementação de Função de Previsão:**\n",
    "     * Desenvolvimento de uma função que permite prever a probabilidade de um jogador específico marcar um gol.\n",
    "3. **Avaliação do Modelo:**\n",
    "      * Cálculo de métricas de desempenho, como acurácia, precisão, recall e F1-score, para avaliar a eficácia do modelo.\n",
    "      * Visualização da matriz de confusão para compreender melhor as previsões do modelo.\n",
    "\n",
    "\n",
    "# Dependências\n",
    "Para rodar o notebook de forma local, é recomendado que inicie uma venv (ambiente virtual) e instale as dependências.\n",
    "\n",
    "Se estiver utilizando o Google Colab, pule esta etapa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando bibliotecas\n",
    "Aqui é importado as dependências necessárias para a executação do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando o dataset\n",
    "Feita a importação do arquivo para leitura dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../notebooks/data/tratado/players_tratado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste para criação da tabela de id e full_name de acordo com o estilo do código do usuário\n",
    "\n",
    "# Resetando o índice para criar uma coluna de 'id'\n",
    "player_table = df.reset_index()[['index', 'full_name']]\n",
    "player_table.columns = ['id', 'table_name']\n",
    "\n",
    "# Exibindo a tabela ajustada no Jupyter Notebook\n",
    "display(player_table)\n",
    "# Salvando a tabela em CSV\n",
    "player_table.to_csv('player_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar as features e a target\n",
    "df['target'] = df['goals_overall'].apply(lambda x: 1 if x > 0 else 0)\n",
    "X = df.drop(columns=['goals_overall', 'full_name', 'target'])  # Remove as colunas desnecessárias\n",
    "y = df['target']  # Define a coluna 'target' como alvo\n",
    "\n",
    "# Dividir os dados em conjunto de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.6, random_state=42)\n",
    "\n",
    "# Treinar o modelo\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Padronizar os dados com a mesma escala\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Aplica a padronização nos dados de treino\n",
    "X_test = scaler.transform(X_test)  # Aplica a mesma padronização nos dados de teste\n",
    "\n",
    "# Treinar o modelo\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "columns_to_remove = ['goals_overall', 'full_name', 'target']\n",
    "columns_to_remove = [col for col in columns_to_remove if col in df.columns]\n",
    "original_columns = df.drop(columns=columns_to_remove).columns\n",
    "\n",
    "# Seleciona apenas as colunas numéricas\n",
    "X_numeric = X.select_dtypes(include=[np.number])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "imputer = SimpleImputer()\n",
    "\n",
    "X_imputed = imputer.fit_transform(X_numeric)\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção das principais features\n",
    "\n",
    "Nessa etapa, utilizamos o método Random Forest para identificar as 10 principais features que o modelo utiliza para prever a probabilidade de um jogador marcar um gol, além de determinar a ordem de importância de cada uma delas. Esse processo é fundamental para entender quais variáveis mais influenciam no desempenho dos jogadores, garantindo um modelo mais rápido e eficiente para futuras previsões. Esse processo é fundamental para entender quais fatores têm maior impacto no resultado final, permitindo uma tomada de decisões mais assertiva na análise de desempenho dos jogadores.\n",
    "\n",
    "Além disso, utilizamos o método StandardScaler para normalizar as variáveis numéricas do conjunto de dados, garantindo que todas as features tenham a mesma escala. Isso é importante porque algoritmos como o Random Forest podem ser sensíveis a variáveis com diferentes magnitudes, o que pode influenciar negativamente o desempenho do modelo. A normalização permite que o modelo trate todas as variáveis de forma equilibrada, evitando vieses e melhorando a precisão das previsões."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O gráfico foi gerado para visualizar a importância das principais features do modelo, facilitando a interpretação dos resultados. Após calcular a importância de cada variável com o Random Forest, criamos um DataFrame organizado que exibe as variáveis em ordem de relevância. A seguir, foi utilizada uma visualização em formato de gráfico de barras horizontais para destacar as 10 features mais importantes, invertendo o eixo y para que as mais relevantes apareçam no topo. Esse gráfico oferece uma representação clara e intuitiva de quais variáveis têm maior impacto no desempenho do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica a importância das features do modelo\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Cria um DataFrame para organizar as importâncias das features\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': df.drop(columns=['goals_overall', 'full_name', 'target']).columns,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# Ordena as features pela importância\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Exibe as 10 principais features\n",
    "print(feature_importances.head(10))\n",
    "\n",
    "# Opcional: visualiza as importâncias das features\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Importância das Principais Features')\n",
    "plt.barh(feature_importances['Feature'].head(10), feature_importances['Importance'].head(10))\n",
    "plt.gca().invert_yaxis()  # Inverte o eixo y para que a feature mais importante apareça no topo\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organização dos dados\n",
    "\n",
    "Por se tratar de um modelo que prevê uma probabilidade de um jogador marcar um gol, o grupo optou por manter uma proporção de 60% de dados de treinamento e 40% de dados de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação de Função de Previsão\n",
    "Nesta seção, desenvolvemos uma função personalizada que permite prever a probabilidade de um jogador específico marcar um gol, usando o modelo treinado. A função verifica se o jogador está presente no dataset, prepara seus dados de forma consistente com o modelo e calcula a probabilidade da previsão.\n",
    "\n",
    "**Desenvolvimento da Função predict_player_goal(player_id):**\n",
    "\n",
    "A função predict_player_goal é criada para prever a probabilidade de um jogador marcar um gol. Ela realiza uma série de verificações e pré-processamentos nos dados do jogador antes de fazer a previsão com o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para prever a probabilidade de gol\n",
    "def predict_player_goal(table_name):\n",
    "    global imputer, scaler, model, original_columns, df\n",
    "\n",
    "    # Verifica se o nome do jogador existe na tabela player_table\n",
    "    if table_name not in player_table['table_name'].values:\n",
    "        return f\"Jogador com nome '{table_name}' não encontrado.\"\n",
    "\n",
    "    # Obtém o id do jogador\n",
    "    player_id = player_table.loc[player_table['table_name'] == table_name, 'id'].values[0]\n",
    "\n",
    "    # Verifica se o nome completo (full_name) existe no DataFrame original\n",
    "    if table_name not in df['full_name'].values:\n",
    "        return f\"Jogador com nome completo '{table_name}' não encontrado no DataFrame original.\"\n",
    "\n",
    "    # Seleciona os dados do jogador usando o full_name\n",
    "    player_data = df[df['full_name'] == table_name].copy()\n",
    "\n",
    "    # Remove as colunas desnecessárias, verifica se elas existem\n",
    "    columns_to_drop = ['goals_overall', 'target', 'full_name']\n",
    "    columns_to_drop = [col for col in columns_to_drop if col in player_data.columns]\n",
    "    player_data = player_data.drop(columns=columns_to_drop)\n",
    "\n",
    "     # Realinhar as colunas do player_data para que correspondam ao original_columns\n",
    "    player_data = player_data.reindex(columns=original_columns, fill_value=0)\n",
    "\n",
    "    # Seleciona apenas as colunas numéricas\n",
    "    player_data_numeric = player_data.select_dtypes(include=[np.number])\n",
    "\n",
    "\n",
    "    # Imputação de dados\n",
    "    player_data_imputed = imputer.transform(player_data_numeric)\n",
    "\n",
    "     # Padronização dos dados\n",
    "    player_data_scaled = scaler.transform(player_data_imputed)\n",
    "\n",
    "    # Previsão da probabilidade de marcar um gol\n",
    "    probabilidade = model.predict_proba(player_data)[:, 1]\n",
    "\n",
    "    return f\"A probabilidade do jogador '{table_name}' (ID: {player_id}) marcar um gol é de {probabilidade[0]*100:.2f}%.\"\n",
    "\n",
    "# Exemplo de uso\n",
    "table_name = \"Paulinho\"\n",
    "print(predict_player_goal(table_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta etapa do processo, utilizamos um conjunto de hiperparâmetros específicos para otimizar o desempenho do modelo RandomForestClassifier. Os hiperparâmetros ajustados foram:\n",
    "\n",
    "- n_estimators: número de árvores na floresta, definido como 100.\n",
    "- max_depth: profundidade máxima de cada árvore, definido como sem limite (None).\n",
    "- min_samples_split: número mínimo de amostras necessárias para dividir um nó, definido como 2.\n",
    "- min_samples_leaf: número mínimo de amostras necessárias para estar em um nó folha, definido como 1.\n",
    "- bootstrap: habilitação do bootstrap para amostragem dos dados, definido como True.\n",
    "\n",
    "Além disso, aplicamos a validação cruzada com 5 divisões estratificadas (StratifiedKFold) para garantir que o modelo fosse avaliado de forma equilibrada, considerando a distribuição das classes da variável-alvo em cada um dos folds. O GridSearchCV foi utilizado para explorar e selecionar a melhor combinação desses hiperparâmetros, garantindo a escolha do modelo com o melhor desempenho em termos de acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Definir a target como uma classificação binária (0 ou 1)\n",
    "df_copy = df.copy()\n",
    "df_copy['target_rf'] = df_copy['goals_overall'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Remover as colunas desnecessárias\n",
    "columns_to_remove_rf = ['goals_overall', 'full_name', 'target_rf']\n",
    "columns_to_remove_rf = [col for col in columns_to_remove_rf if col in df_copy.columns]\n",
    "X_rf = df_copy.drop(columns=columns_to_remove_rf)\n",
    "y_rf = df_copy['target_rf']  # Target é a coluna 'target_rf'\n",
    "\n",
    "# Salvar as colunas originais para futura referência\n",
    "original_columns_rf = X_rf.columns\n",
    "\n",
    "# Selecionar apenas colunas numéricas\n",
    "X_numeric_rf = X_rf.select_dtypes(include=[np.number])\n",
    "\n",
    "# Padronizar os dados com a mesma escala e tratar valores faltantes\n",
    "scaler_rf = StandardScaler()\n",
    "imputer_rf = SimpleImputer(strategy='mean')\n",
    "\n",
    "X_imputed_rf = imputer_rf.fit_transform(X_numeric_rf)\n",
    "X_scaled_rf = scaler_rf.fit_transform(X_imputed_rf)\n",
    "\n",
    "# Definir os hiperparâmetros para o GridSearchCV\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [200],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1],\n",
    "    'bootstrap': [True]\n",
    "}\n",
    "\n",
    "# Instanciar o modelo RandomForest\n",
    "model_rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Aplicar a Validação Cruzada com 5 folds\n",
    "cv_rf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Usar GridSearchCV para otimizar os hiperparâmetros\n",
    "grid_search_rf = GridSearchCV(estimator=model_rf, param_grid=param_grid_rf, cv=cv_rf, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "# Ajustar o modelo aos dados\n",
    "grid_search_rf.fit(X_scaled_rf, y_rf)\n",
    "\n",
    "# Melhor modelo com os melhores hiperparâmetros\n",
    "best_model_rf = grid_search_rf.best_estimator_\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "\n",
    "print(f\"Melhores hiperparâmetros: {best_params_rf}\")\n",
    "\n",
    "# Função para prever a probabilidade de gol com o melhor modelo encontrado\n",
    "def predict_player_goal_rf(table_name):\n",
    "    global imputer_rf, scaler_rf, best_model_rf, original_columns_rf, df_copy\n",
    "\n",
    "    # Verifica se o nome do jogador existe na tabela player_table\n",
    "    if table_name not in player_table['table_name'].values:\n",
    "        return f\"Jogador com nome '{table_name}' não encontrado.\"\n",
    "\n",
    "    # Obtém o id do jogador\n",
    "    player_id_rf = player_table.loc[player_table['table_name'] == table_name, 'id'].values[0]\n",
    "\n",
    "    # Verifica se o nome completo (full_name) existe no DataFrame original\n",
    "    if table_name not in df_copy['full_name'].values:\n",
    "        return f\"Jogador com nome completo '{table_name}' não encontrado no DataFrame original.\"\n",
    "\n",
    "    # Seleciona os dados do jogador usando o full_name\n",
    "    player_data_rf = df_copy[df_copy['full_name'] == table_name].copy()\n",
    "\n",
    "    # Remove as colunas desnecessárias, verifica se elas existem\n",
    "    columns_to_drop_rf = ['goals_overall', 'target_rf', 'full_name']\n",
    "    columns_to_drop_rf = [col for col in columns_to_drop_rf if col in player_data_rf.columns]\n",
    "    player_data_rf = player_data_rf.drop(columns=columns_to_drop_rf)\n",
    "\n",
    "    # Realinhar as colunas do player_data para que correspondam ao original_columns_rf\n",
    "    player_data_rf = player_data_rf.reindex(columns=original_columns_rf, fill_value=0)\n",
    "\n",
    "    # Seleciona apenas as colunas numéricas\n",
    "    player_data_numeric_rf = player_data_rf.select_dtypes(include=[np.number])\n",
    "\n",
    "    # Imputação de dados\n",
    "    player_data_imputed_rf = imputer_rf.transform(player_data_numeric_rf)\n",
    "\n",
    "    # Padronização dos dados\n",
    "    player_data_scaled_rf = scaler_rf.transform(player_data_imputed_rf)\n",
    "\n",
    "    # Previsão da probabilidade de marcar um gol\n",
    "    probabilidade_rf = best_model_rf.predict_proba(player_data_scaled_rf)[:, 1]\n",
    "\n",
    "    return f\"A probabilidade do jogador '{table_name}' (ID: {player_id_rf}) marcar um gol é de {probabilidade_rf[0]*100:.2f}%.\"\n",
    "\n",
    "# Exemplo de uso\n",
    "table_name_rf = \"Paulinho\"\n",
    "print(predict_player_goal_rf(table_name_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Avaliação do Modelo\n",
    "\n",
    "Após o treinamento, é essencial avaliar o desempenho do modelo para verificar sua eficácia na classificação correta dos jogadores que marcaram gols. Nesta seção, calculamos métricas de desempenho como acurácia, acurácia balanceada, precisão, recall e F1-score. Além disso, visualizamos a matriz de confusão para entender as previsões do modelo. Dessa forma, ao analisar as métricas conseguimos avaliar de forma eficiente a execução do modelo, oque pode nos revelar se o conjunto de dados é satisfatório ou não para a tarefa proposta. Se o desempenho do modelo não for adequado, pode ser necessário realizar ajustes, como a coleta de mais dados, o balanceamento das classes ou a otimização de hiperparâmetros. Com esses insights, é possível aprimorar o modelo ou refinar a abordagem adotada, garantindo resultados mais precisos e confiáveis no futuro.\n",
    "\n",
    "**Cálculo das Métricas de Desempenho:**\n",
    "\n",
    "Utilizamos as previsões do modelo no conjunto de teste para calcular as principais métricas de desempenho. Essas métricas ajudam a entender a precisão do modelo e como ele lida com os falsos positivos e falsos negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputar e padronizar os dados de teste\n",
    "X_test_imputed = imputer.transform(X_test)  # X_test já é um ndarray\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Previsão no conjunto de teste\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calcular a acurácia\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calcular a acurácia balanceada\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Exibir as métricas\n",
    "print(f\"Acurácia do modelo: {accuracy * 100:.2f}%\")\n",
    "print(f\"Acurácia balanceada do modelo: {balanced_accuracy * 100:.2f}%\")\n",
    "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação das métricas com validação cruzada e hiperparâmetros\n",
    "Os resultados apresentados com acurácia, precisão e recall de 1.00 indicam que o modelo pode estar sofrendo de overfitting, o que significa que ele está memorizando os padrões dos dados de treino e não generalizando bem para novos dados. Isso é um problema porque um desempenho perfeito nas métricas dificilmente reflete a realidade de modelos de aprendizado de máquina e pode sugerir uma falta de variabilidade nos dados ou uma má configuração na validação cruzada.\n",
    "\n",
    "Portanto, é essencial revisar a estratégia de validação, ajustar melhor os hiperparâmetros e garantir que os dados estejam balanceados e diversos. O objetivo é obter um modelo que não apenas tenha bom desempenho em treino, mas que também seja robusto o suficiente para fazer previsões confiáveis em dados novos.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curva ROC e AUC para o Random Forest sem hiperparâmetros e validação cruzada\n",
    "A **Curva ROC (Receiver Operating Characteristic)** é uma ferramenta gráfica que ilustra a capacidade de um modelo de classificação binária em distinguir entre classes positivas e negativas. A curva traça a relação entre a **Taxa de Verdadeiros Positivos (TPR)** e a **Taxa de Falsos Positivos (FPR)** para diferentes limiares de decisão.\n",
    "\n",
    "O **AUC (Area Under the Curve)** mede a área sob a Curva ROC, fornecendo uma única métrica que reflete a capacidade do modelo de classificar corretamente as amostras. Um AUC próximo de 1 indica um modelo excelente, enquanto um AUC de 0.5 sugere que o modelo não é melhor que uma escolha aleatória.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "# Valores extraídos da matriz de confusão\n",
    "TP = 133\n",
    "FP = 40\n",
    "TN = 165\n",
    "FN = 15\n",
    "\n",
    "# Calcula a taxa de verdadeiros positivos (TPR) e a taxa de falsos positivos (FPR)\n",
    "# TPR = TP / (TP + FN)\n",
    "# FPR = FP / (FP + TN)\n",
    "tpr = TP / (TP + FN)\n",
    "fpr = FP / (FP + TN)\n",
    "\n",
    "# Como uma curva ROC requer múltiplos limiares para ser desenhada, normalmente precisaríamos das previsões de probabilidade.\n",
    "# Neste caso, vamos usar uma simplificação para plotar a curva com base nos valores da matriz de confusão.\n",
    "\n",
    "# Simulando os pontos da curva ROC com base nos valores da matriz de confusão\n",
    "fpr_values = np.array([0.0, fpr, 1.0])\n",
    "tpr_values = np.array([0.0, tpr, 1.0])\n",
    "\n",
    "# Calcula a AUC (Área sob a Curva)\n",
    "roc_auc = auc(fpr_values, tpr_values)\n",
    "\n",
    "# Plotando a curva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_values, tpr_values, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Linha aleatória\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Exibe a AUC calculada\n",
    "print(f\"AUC: {roc_auc:.2f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados\n",
    "\n",
    "Após gerar a Curva ROC e calcular o AUC, os seguintes resultados foram obtidos:\n",
    "\n",
    "- **Curva ROC**: A curva mostra a taxa de verdadeiros positivos (TPR) em função da taxa de falsos positivos (FPR) para diferentes limiares de decisão. O formato da curva fornece uma visão sobre o desempenho do modelo de Regressão Logística em discriminar entre classes positivas e negativas.\n",
    "\n",
    "- **AUC (Area Under the Curve)**: O valor calculado foi de **0.85**, indicando que o modelo possui uma capacidade de classificação. Um AUC próximo de 1 sugere que o modelo é muito eficaz em distinguir corretamente entre as classes.\n",
    "\n",
    "### Conclusão\n",
    "\n",
    "A avaliação do modelo usando a Curva ROC e AUC mostrou que o modelo tem um desempenho na tarefa de classificação:\n",
    "\n",
    "- **Desempenho de Classificação**: A curva ROC, que se aproxima do canto superior esquerdo do gráfico, demonstra que o modelo possui uma alta taxa de verdadeiros positivos em relação aos falsos positivos, o que é ideal para um classificador binário.\n",
    "\n",
    "- **Qualidade do Modelo**: Com um AUC de **0.85**, o modelo demonstra boa precisão e habilidade em classificar corretamente as instâncias. Este resultado sugere que o modelo pode ser adequado para ser utilizado no problema em questão, dado o seu alto poder discriminativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Visualização da Matriz de Confusão do modelo sem hiperparâmetros e validação cruzada\n",
    "Este código gera uma matriz de confusão para visualizar o desempenho do modelo de classificação em termos de suas previsões. Utilizando o Seaborn, uma biblioteca de visualização de dados do Python, o código cria um heatmap que exibe a matriz de confusão, onde as previsões corretas e incorretas do modelo são claramente indicadas. A matriz mostra a contagem de classificações corretas (verdadeiros positivos e negativos) e incorretas (falsos positivos e negativos) para as classes \"Positivo\" e \"Negativo\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Dados da matriz de confusão\n",
    "cm_data = [[219, 83],\n",
    "           [18, 209]]\n",
    "\n",
    "# Visualizar a matriz de confusão usando seaborn heatmap\n",
    "plt.figure(figsize=(8,6))  # Define o tamanho da figura\n",
    "sns.heatmap(cm_data, annot=True, fmt='d', cmap='Blues', xticklabels=['Negativo', 'Positivo'], yticklabels=['Negativo', 'Positivo'])\n",
    "plt.xlabel('Previsão')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Referências\n",
    "Está é uma seção de referências com relação as bibliotecas que utilizamos ao longo deste arquivo\n",
    "\n",
    "NUMPY. NumPy Documentation. Disponível em: https://numpy.org/doc/.\n",
    "\n",
    "‌PANDAS. pandas documentation. Disponível em: https://pandas.pydata.org/docs/.\n",
    "\n",
    "MATPLOTLIB. Matplotlib: Python plotting — Matplotlib 3.3.4 documentation. Disponível em: https://matplotlib.org/stable/index.html.\n",
    "\n",
    "‌SCIKIT-LEARN. scikit-learn: machine learning in Python. Disponível em: https://scikit-learn.org/stable/.\n",
    "\n",
    "‌SEABORN. seaborn: statistical data visualization — seaborn 0.9.0 documentation. Disponível em: <https://seaborn.pydata.org/>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
