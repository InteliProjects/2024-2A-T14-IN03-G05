{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdrTGkr-D0wZ"
      },
      "source": [
        "# Matches_Predicao\n",
        "\n",
        "Este notebook é dedicado à predição de dados da tabela **Matches** fornecida pela IBM, que contém dados detalhados sobre as partidas, incluindo informações como quantidade de gols nas partidas, cartões amarelos que têm no total, entre outros. O objetivo deste notebook é confirmar as hipóteses e prever mais informações com os dados dessa tabela.\n",
        "\n",
        "## Objetivo\n",
        "\n",
        "O objetivo deste notebook é fornecer uma predição de dados das partidas da série A do Campeonato Brasileiro, ajudando a identificar padrões e tendências que possam ser úteis para diversas aplicações, como previsões de resultados e desempenho dos times.\n",
        "\n",
        "## Como Usar Este Notebook\n",
        "\n",
        "1. **Configuração do Ambiente**:\n",
        "   - **Google Colab**: No Google Colab, será necessário fazer o upload das tabelas para o Google Drive e montar o drive no notebook.\n",
        "   - **Localmente**: Se for rodar o notebook localmente, é necessário baixar as tabelas e colocá-las no mesmo diretório do notebook ou ajustar os caminhos dos arquivos conforme necessário.\n",
        "\n",
        "2. **Instalação de Dependências**:\n",
        "   - Certifique-se de que todas as bibliotecas necessárias estão instaladas. Você pode instalar as dependências utilizando o seguinte comando:\n",
        "     ```python\n",
        "     !pip install -r requirements.txt\n",
        "     ```\n",
        "\n",
        "3. **Execução do Notebook**:\n",
        "   - Antes de rodar esse notebook, execute por completo o notebook `matches_tratado.ipynb` para que sejam exportadas em suas células a\n",
        "   respectiva tabela contendo os dados tratados, que serão utilizados neste notebook.\n",
        "   - Siga as células de código sequencialmente para garantir que todas as etapas sejam executadas corretamente. Cada seção do notebook está organizada para facilitar a compreensão e a análise dos dados.\n",
        "\n",
        "## Nesse Notebook Será Abordado\n",
        "\n",
        "1. **Modelagem para o problema**:\n",
        "   - Modelagem para o problema - proposta das features;\n",
        "   - Organização dos dados - como os dados foram organizados;\n",
        "   - Apresentar o modelo candidato - qual modelo estamos utilizando e para que;\n",
        "   - Métricas relacionadas ao modelo - avaliação de desempenho."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN5A-MUND0wv"
      },
      "source": [
        "# Dependências\n",
        "Para rodar o notebook de forma local, é recomendado que inicie uma venv (ambiente virtual) e instale as dependências.\n",
        "\n",
        "Se estiver utilizando o Google Colab, pule esta etapa.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV0yYXX-D0ww"
      },
      "source": [
        "# Instala as dependências"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDN9a4dnD0wx",
        "outputId": "966992f6-6f46-4d9c-bf6e-83c7fbf213e8"
      },
      "outputs": [],
      "source": [
        "# Instala as dependências\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc8BHdGvD0wy"
      },
      "source": [
        "# Importando bibliotecas\n",
        "\n",
        "Aqui é importado as dependências necessárias para a executação do projeto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "nw_BvFxND0wz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, balanced_accuracy_score, confusion_matrix, roc_curve, roc_auc_score, RocCurveDisplay, auc\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import label_binarize\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcAlix6kD0wz"
      },
      "source": [
        "# Carregando o Dataset\n",
        "Carrega o CSV da tabela matches tratado para criar um dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "rzxeSQhoD0wz"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('../../notebooks/data/tratado/matches_tratado.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cdx3TqrVD0w0"
      },
      "source": [
        "# 1. Organização dos dados\n",
        "\n",
        "Após diversos testes de proproções de conjuntos de dados, a combinação que trouxe uma maior acurácia para os modelos deste notebook foi o de 70% de dados para treinamento e 30% para dados de teste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJy3OgIrD0w0"
      },
      "source": [
        "# 2. Modelagem para o Problema (Seleção das Principais Features)\n",
        "\n",
        "Nesta etapa, utilizamos o **Random Forest** para identificar as principais variáveis (features) que influenciam diretamente o resultado das partidas de futebol. A escolha dessas features foi baseada em uma análise cuidadosa do que mais impacta o desempenho de uma equipe em uma partida de futebol, tanto do ponto de vista ofensivo quanto defensivo.\n",
        "\n",
        "## Proposta de Features e Linha de Raciocínio\n",
        "\n",
        "### Premissa da Modelagem:\n",
        "\n",
        "A modelagem é baseada na premissa de que o resultado de uma partida de futebol é influenciado por um conjunto de fatores que descrevem o desempenho passado e as condições pré-jogo das equipes envolvidas. Com isso, selecionamos as seguintes features como preditoras principais do resultado de uma partida:\n",
        "- **Características das equipes**: Fatores como os times jogando em casa e fora (`home_team_encoded` e `away_team_encoded`), além de seu desempenho prévio medido por estatísticas como `Pre-Match PPG (Home)` e `Pre-Match PPG (Away)` (pontos por jogo antes da partida) e o `xG` (gols esperados).\n",
        "- **Estatísticas ofensivas e defensivas**: Variáveis como número de chutes a gol, chutes no alvo, posse de bola e número de escanteios refletem o controle do time sobre o jogo e suas chances de marcar gols ou evitar que o adversário marque.\n",
        "- **Faltas e Cartões**: Disciplinas das equipes também são consideradas, com indicadores como `home_team_yellow_cards`, `away_team_red_cards`, que podem impactar o equilíbrio do jogo se um time estiver desfalcado ou punido.\n",
        "\n",
        "### Proposta das Features:\n",
        "\n",
        "#### Variáveis Utilizadas:\n",
        "Abaixo está a lista completa de features selecionadas para o modelo de previsão:\n",
        "- **Identificação das Equipes**: `home_team_encoded`, `away_team_encoded`.\n",
        "- **Desempenho Pré-Jogo**: `Pre-Match PPG (Home)`, `Pre-Match PPG (Away)`, `home_ppg`, `away_ppg`, `Home Team Pre-Match xG`, `Away Team Pre-Match xG`, `team_a_xg`, `team_b_xg`.\n",
        "- **Estatísticas do Jogo**:\n",
        "  - Ofensivas: `home_team_shots`, `away_team_shots`, `home_team_shots_on_target`, `away_team_shots_on_target`, `home_team_corner_count`, `away_team_corner_count`.\n",
        "  - Defensivas: `home_team_fouls`, `away_team_fouls`.\n",
        "- **Faltas e Cartões**: `home_team_yellow_cards`, `away_team_yellow_cards`, `home_team_red_cards`, `away_team_red_cards`.\n",
        "- **Posse de Bola**: `home_team_possession`, `away_team_possession`.\n",
        "- **Estatísticas Gerais**: `average_goals_per_match_pre_match`, `btts_percentage_pre_match` (ambos os times marcam), `average_corners_per_match_pre_match`, `average_cards_per_match_pre_match`.\n",
        "\n",
        "### Explicação do Raciocínio:\n",
        "\n",
        "1. **Desempenho Pré-Jogo**: Features como o `Pre-Match PPG` e `xG` são fundamentais para capturar a forma dos times antes da partida. Times com mais pontos por jogo e um alto valor de xG são mais propensos a manter bons desempenhos em jogos futuros.\n",
        "   \n",
        "2. **Estatísticas do Jogo**: O número de chutes e escanteios mostra como as equipes criam chances durante a partida, enquanto as faltas e cartões refletem o controle emocional e tático. Times mais ofensivos e disciplinados tendem a ganhar mais partidas.\n",
        "\n",
        "3. **Cartões e Faltas**: Faltas e cartões são indicadores importantes da disciplina e da capacidade de manter o ritmo do jogo. Times com muitos cartões podem estar em desvantagem durante a partida.\n",
        "\n",
        "4. **Posse de Bola**: Times com alta posse de bola geralmente controlam o jogo e têm maior probabilidade de vencer, pois criam mais oportunidades de gol e limitam as chances do adversário.\n",
        "\n",
        "### Normalização das Variáveis:\n",
        "Além da seleção cuidadosa das features, utilizamos o método **StandardScaler** para normalizar as variáveis numéricas. Isso foi essencial para garantir que todas as variáveis tenham a mesma escala, evitando que variáveis com magnitudes diferentes (como número de chutes vs. porcentagem de posse de bola) influenciem o modelo de forma desbalanceada.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZYqVHnGD0w1",
        "outputId": "bdf4c0f7-5462-4c68-b799-976229dfe00f"
      },
      "outputs": [],
      "source": [
        "# Criando a coluna de resultado\n",
        "df['result'] = np.where(df['home_team_goal_count'] > df['away_team_goal_count'], 2,\n",
        "                        np.where(df['home_team_goal_count'] < df['away_team_goal_count'], 1, 0))\n",
        "\n",
        "# Definindo a variável alvo e os preditores\n",
        "X = df[['home_team_encoded', 'away_team_encoded', 'Pre-Match PPG (Home)', 'Pre-Match PPG (Away)', 'home_ppg', 'away_ppg',\n",
        "        'home_team_goal_count', 'away_team_goal_count', 'home_team_corner_count', 'away_team_corner_count',\n",
        "        'home_team_yellow_cards', 'home_team_red_cards', 'away_team_yellow_cards', 'away_team_red_cards',\n",
        "        'home_team_shots', 'away_team_shots', 'home_team_shots_on_target', 'away_team_shots_on_target',\n",
        "        'home_team_shots_off_target', 'away_team_shots_off_target', 'home_team_fouls', 'away_team_fouls',\n",
        "        'home_team_possession', 'away_team_possession', 'Home Team Pre-Match xG', 'Away Team Pre-Match xG',\n",
        "        'team_a_xg', 'team_b_xg', 'average_goals_per_match_pre_match', 'btts_percentage_pre_match',\n",
        "        'average_corners_per_match_pre_match', 'average_cards_per_match_pre_match']]\n",
        "y = df['result']\n",
        "\n",
        "# Imputação de valores faltantes\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Padronização dos dados\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Dividindo os dados em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Criando e treinando o modelo de Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Fazendo previsões no conjunto de teste\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Função para prever o resultado do jogo entre dois times\n",
        "def predict_match_result(home_team_encoded, away_team_encoded):\n",
        "    global imputer, scaler, rf\n",
        "\n",
        "    # Seleciona as características do jogo a partir dos IDs dos times\n",
        "    match_data = df[(df['home_team_encoded'] == home_team_encoded) & (df['away_team_encoded'] == away_team_encoded)].copy()\n",
        "\n",
        "    # Se o DataFrame estiver vazio, retorna uma mensagem de erro\n",
        "    if match_data.empty:\n",
        "        return \"Jogo não encontrado no conjunto de dados.\"\n",
        "\n",
        "    # Realinhar as colunas para que correspondam ao conjunto de dados original usado para treinar o modelo\n",
        "    match_data = match_data.reindex(columns=X.columns, fill_value=0)\n",
        "\n",
        "    # Imputação e padronização dos dados\n",
        "    match_data_imputed = imputer.transform(match_data)\n",
        "    match_data_scaled = scaler.transform(match_data_imputed)\n",
        "\n",
        "    # Prevendo o resultado do jogo\n",
        "    prediction = rf.predict(match_data_scaled)[0]\n",
        "\n",
        "    if prediction == 2:\n",
        "        result = \"Vitória do time da casa\"\n",
        "    elif prediction == 1:\n",
        "        result = \"Vitória do time visitante\"\n",
        "    else:\n",
        "        result = \"Empate\"\n",
        "\n",
        "    return result\n",
        "\n",
        "# Exemplo de uso\n",
        "home_team_id = 10\n",
        "away_team_id = 13\n",
        "print(predict_match_result(home_team_id, away_team_id))\n",
        "\n",
        "# Avaliando o modelo\n",
        "print(\"Acurácia:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Matriz de confusão\\n\", confusion_matrix(y_pred, y_test) )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXNUfEgZD0w2"
      },
      "source": [
        "#### Importância das Features:\n",
        "Após treinar o modelo, podemos analisar a importância relativa de cada uma das variáveis preditoras. O modelo de Random Forest possui a capacidade de indicar quais features mais contribuíram para a decisão de cada árvore de decisão."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "id": "AgS0i3__D0w2",
        "outputId": "1044a1dc-10af-4a93-8051-98409b136a00"
      },
      "outputs": [],
      "source": [
        "# Verifica a importância das features do modelo treinado\n",
        "importances = rf.feature_importances_\n",
        "\n",
        "# Lista dos nomes das features\n",
        "feature_names = [\n",
        "    'home_team_encoded', 'away_team_encoded', 'Pre-Match PPG (Home)', 'Pre-Match PPG (Away)', 'home_ppg', 'away_ppg',\n",
        "    'home_team_goal_count', 'away_team_goal_count', 'home_team_corner_count', 'away_team_corner_count',\n",
        "    'home_team_yellow_cards', 'home_team_red_cards', 'away_team_yellow_cards', 'away_team_red_cards',\n",
        "    'home_team_shots', 'away_team_shots', 'home_team_shots_on_target', 'away_team_shots_on_target',\n",
        "    'home_team_shots_off_target', 'away_team_shots_off_target', 'home_team_fouls', 'away_team_fouls',\n",
        "    'home_team_possession', 'away_team_possession', 'Home Team Pre-Match xG', 'Away Team Pre-Match xG',\n",
        "    'team_a_xg', 'team_b_xg', 'average_goals_per_match_pre_match', 'btts_percentage_pre_match',\n",
        "    'average_corners_per_match_pre_match', 'average_cards_per_match_pre_match'\n",
        "]\n",
        "\n",
        "# Cria um DataFrame para organizar as importâncias das features\n",
        "feature_importances = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "})\n",
        "\n",
        "# Ordena as features pela importância\n",
        "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Exibe as 10 principais features\n",
        "print(\"Principais Features:\")\n",
        "print(feature_importances.head(10))\n",
        "\n",
        "# Visualiza as importâncias das features\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title('Importância das Principais Features')\n",
        "plt.barh(feature_importances['Feature'].head(10), feature_importances['Importance'].head(10))\n",
        "plt.gca().invert_yaxis()  # Inverte o eixo y para que a feature mais importante apareça no topo\n",
        "plt.xlabel('Importância')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXEO7b1WD0w4"
      },
      "source": [
        "# 3. Primeiro Modelo Candidato"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLatYv-0D0w5"
      },
      "source": [
        "### 3.1 Hipótese do Modelo: Qual a probabilidade de um time ganhar com certas variáveis.\n",
        "\n",
        "##### Premissa Principal:\n",
        "O objetivo de previsão desse modelo é que o desempenho passado de um time, medido por diversas métricas estatísticas (como posse de bola, número de chutes a gol, cartões, etc.), pode prever a probabilidade de um time vencer em uma partida futura. O modelo utiliza uma combinação de variáveis pré-jogo e dados históricos dos times para calcular essas probabilidades.\n",
        "\n",
        "##### Justificativa da Premissa:\n",
        "1. **Posse de bola e estatísticas de ataque e defesa** são fortes indicativos de domínio em uma partida. Times que têm alta posse de bola e boa eficiência nos chutes a gol, geralmente têm uma maior chance de vitória.\n",
        "2. **Cartões, faltas e escanteios** influenciam diretamente o controle da partida e as oportunidades de gol. Uma defesa que comete muitas faltas ou recebe cartões pode ser vulnerável, enquanto escanteios e chances ofensivas contribuem para as probabilidades de marcar gols.\n",
        "3. **Desempenho médio pré-jogo (PPG e xG)**: O número de pontos por jogo e o desempenho esperado de gols (xG) são métricas que oferecem uma visão do histórico do time e indicam sua capacidade de manter o desempenho ou superá-lo em partidas futuras.\n",
        "\n",
        "#### Abordagem Técnica:\n",
        "\n",
        "O modelo de **Random Forest** foi escolhido para capturar relações complexas entre as diversas variáveis. Ele é particularmente adequado para problemas com várias características preditivas, como o caso de previsão de resultados de futebol, onde a posse de bola, cartões, número de chutes, e outras estatísticas têm pesos diferentes dependendo do contexto.\n",
        "\n",
        "- **Random Forest** constrói múltiplas árvores de decisão, onde cada árvore faz previsões baseadas em subconjuntos diferentes das variáveis. O resultado final é uma agregação das previsões dessas árvores, o que ajuda a melhorar a precisão do modelo e minimiza erros causados por outliers.\n",
        "- O modelo foi treinado com um conjunto de dados que contém estatísticas de partidas anteriores e diversas métricas de desempenho dos times.\n",
        "\n",
        "#### Estrutura do Modelo:\n",
        "\n",
        "- **Variáveis Preditoras**:\n",
        "  - Estatísticas da equipe da casa e da equipe visitante, incluindo posse de bola, número de chutes a gol, cartões amarelos e vermelhos, escanteios, xG (gols esperados) e faltas cometidas.\n",
        "  - Dados pré-jogo como Pre-Match PPG (pontos por jogo) e Pre-Match xG (gols esperados).\n",
        "- **Variável Alvo**: Resultado da partida (vitória da casa, empate ou vitória do visitante).\n",
        "\n",
        "#### Previsão Ajustada:\n",
        "\n",
        "O modelo prevê as probabilidades de três possíveis resultados para a partida:\n",
        "- **Vitória da equipe da casa**\n",
        "- **Empate**\n",
        "- **Vitória da equipe visitante**\n",
        "\n",
        "Além de fornecer as probabilidades em porcentagem, as previsões são categorizadas em níveis de probabilidade, utilizando a função `categorize_win_probability`, que classifica as chances de vitória em:\n",
        "- Baixíssimas chances de ganhar\n",
        "- Baixas chances de ganhar\n",
        "- Médias chances de ganhar\n",
        "- Muitas chances de ganhar\n",
        "- Grandes chances de ganhar\n",
        "\n",
        "Essa categorização ajuda a fornecer uma interpretação mais qualitativa das previsões feitas pelo modelo.\n",
        "\n",
        "#### Exemplo de Funcionamento:\n",
        "\n",
        "O modelo é capaz de prever resultados de partidas futuras, mesmo que os dados dessas partidas não estejam no conjunto de dados de treino. Nesse caso, ele utiliza **médias históricas** dos times para fazer previsões, garantindo que ainda possa fornecer uma probabilidade estimada, com base no desempenho geral dos times.\n",
        "\n",
        "##### Exemplo de Previsão:\n",
        "Para um confronto entre o time A e o time B, a saída do modelo pode ser:\n",
        "\n",
        "- Probabilidade de vitória da casa (%): 75.0\n",
        "- Chance de vitória da casa: Muitas chances de ganhar\n",
        "- Probabilidade de empate (%): 15.0\n",
        "- Probabilidade de vitória do visitante (%): 10.0\n",
        "- Chance de vitória do visitante: Baixíssimas chances de ganhar\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJmDWbj3D0w6"
      },
      "source": [
        "#### 3.2 Criando o Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hWqBBklD0w6"
      },
      "source": [
        "#### Criando a Coluna de Resultado e Definindo Variáveis Preditoras\n",
        "\n",
        "**Explicação**:\n",
        "- `df['result']`: Estamos criando uma nova coluna chamada result que representa o resultado da partida. A classe 2 indica vitória da casa, 1 vitória do visitante, e 0 indica empate.\n",
        "\n",
        "- `Variáveis preditoras (X) e alvo (y)`: As variáveis preditoras são características como posse de bola, chutes a gol, cartões, etc., que são usadas para treinar o modelo. A variável alvo y é o resultado da partida.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "lu3Fw7peD0w7"
      },
      "outputs": [],
      "source": [
        "# Criando a coluna de resultado\n",
        "df['result'] = np.where(df['home_team_goal_count'] > df['away_team_goal_count'], 2, # Vitória da casa\n",
        "                        np.where(df['home_team_goal_count'] < df['away_team_goal_count'], 1, # Vitória do visitante\n",
        "                                 0)) # Derrota\n",
        "\n",
        "# Definindo a variável alvo e os preditores\n",
        "y = df['result']\n",
        "X = df[['home_team_encoded', 'away_team_encoded', 'Pre-Match PPG (Home)', 'Pre-Match PPG (Away)', 'home_ppg', 'away_ppg',\n",
        "        'home_team_goal_count', 'away_team_goal_count', 'home_team_corner_count', 'away_team_corner_count',\n",
        "        'home_team_yellow_cards', 'home_team_red_cards', 'away_team_yellow_cards', 'away_team_red_cards',\n",
        "        'home_team_shots', 'away_team_shots', 'home_team_shots_on_target', 'away_team_shots_on_target',\n",
        "        'home_team_shots_off_target', 'away_team_shots_off_target', 'home_team_fouls', 'away_team_fouls',\n",
        "        'home_team_possession', 'away_team_possession', 'Home Team Pre-Match xG', 'Away Team Pre-Match xG',\n",
        "        'team_a_xg', 'team_b_xg', 'average_goals_per_match_pre_match', 'btts_percentage_pre_match',\n",
        "        'average_corners_per_match_pre_match', 'average_cards_per_match_pre_match']]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjix0G1RD0w7"
      },
      "source": [
        "#### Imputação de Valores Faltantes, Padronização e Treinamento do Modelo\n",
        "\n",
        "**Explicação:**\n",
        "\n",
        "- `Imputação de valores faltantes:` Preenchemos os valores ausentes nas variáveis preditoras com a média da respectiva variável, garantindo que o modelo não falhe devido a dados incompletos.\n",
        "- `Padronização dos dados:` Para evitar que as variáveis com escalas diferentes impactem negativamente o modelo, os dados são padronizados usando StandardScaler.\n",
        "- `Divisão treino/teste:` O conjunto de dados é dividido em 70% para treino e 30% para teste, garantindo uma avaliação justa do modelo.\n",
        "- `Random Forest:` Treinamos o modelo Random Forest com 100 árvores de decisão para fazer previsões sobre o resultado das partidas.\n",
        "Avaliação: As métricas de acurácia, acurácia balanceada, e a matriz de confusão nos dão uma visão do desempenho do modelo no conjunto de teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8e33rJQD0w8",
        "outputId": "74311bbb-fc49-467a-9d91-d2ab31d19092"
      },
      "outputs": [],
      "source": [
        "# Imputação de valores faltantes\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Padronização dos dados\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Dividindo os dados em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Criando e treinando o modelo de Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Avaliando o modelo\n",
        "y_pred = rf.predict(X_test)\n",
        "print(\"Acurácia:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Acurácia Balanceada:\", balanced_accuracy_score(y_test, y_pred))\n",
        "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Matrix de confusão: \\n\", confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR2Ltfj5Pswi"
      },
      "source": [
        "## Hiperparâmetros\n",
        "\n",
        "Os hiperparâmetros são parâmetros ajustados antes do treinamento do modelo e desempenham um papel crucial no desempenho do mesmo. No caso do **Random Forest**, alguns dos hiperparâmetros mais importantes e suas funções são:\n",
        "\n",
        "### n_estimators (número de estimadores):\n",
        "\n",
        "Define o número de árvores na floresta. Um número maior de estimadores pode melhorar a performance do modelo, mas aumenta o tempo de treinamento e a complexidade computacional.\n",
        "\n",
        "### max_depth (profundidade máxima):\n",
        "\n",
        "Controla a profundidade máxima das árvores. Limitar a profundidade pode ajudar a evitar overfitting, principalmente em modelos complexos. `None` permite que nós sejam expandidos até que todas as folhas contenham menos do que min_samples_split amostras.\n",
        "\n",
        "### min_samples_split (mínimo de amostras para dividir um nó):\n",
        "\n",
        "Indica o número mínimo de amostras necessárias para dividir um nó interno. Valores mais altos previnem que a árvore se divida com poucos dados, ajudando a reduzir overfitting.\n",
        "\n",
        "### min_samples_leaf (mínimo de amostras por folha):\n",
        "\n",
        "Especifica o número mínimo de amostras que cada folha (nó terminal) deve conter. Ajustar esse hiperparâmetro é importante para reduzir o overfitting em dados ruidosos.\n",
        "\n",
        "### bootstrap (amostragem com reposição):\n",
        "\n",
        "Se `True`, as árvores são treinadas usando amostras com reposição, o que aumenta a diversidade entre as árvores e, em muitos casos, melhora a performance do modelo. Se `False`, as árvores são treinadas sem reposição, o que pode ser útil em certos contextos.\n",
        "\n",
        "## GridSearchCV para ajuste de Hiperparâmetros:\n",
        "\n",
        "O **GridSearchCV** é uma técnica que automatiza a busca pelos melhores hiperparâmetros, testando diferentes combinações de valores e avaliando o desempenho para selecionar a melhor configuração. Isso otimiza o modelo, maximizando a acurácia e reduzindo o risco de overfitting.\n",
        "\n",
        "### Hiperparâmetros ajustados:\n",
        "\n",
        "- `n_estimators`: [100, 200, 300]\n",
        "- `max_depth`: [None, 10, 20, 30]\n",
        "- `min_samples_split`: [2, 5, 10]\n",
        "- `min_samples_leaf`: [1, 2, 4]\n",
        "- `bootstrap`: [True, False]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0Jia8QPEepT",
        "outputId": "bd030039-5d2a-47a8-d3e1-849fafe20db3"
      },
      "outputs": [],
      "source": [
        "# Definindo os hiperparâmetros a serem otimizados\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Criando o modelo de Random Forest\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Aplicando o GridSearchCV para otimização dos hiperparâmetros\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
        "\n",
        "# Treinando o modelo com a otimização\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Melhor combinação de hiperparâmetros\n",
        "print(\"Melhores hiperparâmetros:\", grid_search.best_params_)\n",
        "\n",
        "# Atribuir o modelo otimizado à variável rf\n",
        "rf = grid_search.best_estimator_\n",
        "\n",
        "# Avaliando o modelo otimizado\n",
        "y_pred = rf.predict(X_test)\n",
        "print(\"Acurácia:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Acurácia Balanceada:\", balanced_accuracy_score(y_test, y_pred))\n",
        "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Matriz de confusão: \\n\", confusion_matrix(y_test, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E69nNkB0XuVo"
      },
      "source": [
        "## Validação Cruzada\n",
        "A **validação cruzada** é uma técnica fundamental para avaliar o desempenho de modelos de aprendizado de máquina de forma mais confiável. Em vez de treinar e testar o modelo apenas uma vez com um único conjunto de divisão de dados, a validação cruzada permite que o modelo seja testado múltiplas vezes em diferentes subconjuntos do conjunto de dados, garantindo que os resultados sejam menos dependentes de uma única divisão dos dados.\n",
        "\n",
        "Neste projeto, utilizamos a validação cruzada com **5 folds estratificados**:\n",
        "- O conjunto de dados é dividido em 5 partes (folds) de forma que a proporção das classes seja mantida em cada fold (estratificação).\n",
        "- Em cada iteração, o modelo é treinado em 4 folds e testado no fold restante.\n",
        "- O processo é repetido 5 vezes, trocando os folds de treinamento e teste, e ao final, é calculada a média das métricas de desempenho.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6csaPolaXpsc",
        "outputId": "282a492b-a84e-4f21-b754-4f51e0f54b7a"
      },
      "outputs": [],
      "source": [
        "# Configurando a validação cruzada com 5 folds estratificados\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Realizando a validação cruzada e obtendo as previsões de probabilidade\n",
        "cv_scores = cross_val_score(rf, X, y, cv=cv, scoring='accuracy')\n",
        "cv_predictions = cross_val_predict(rf, X, y, cv=cv, method='predict_proba')\n",
        "\n",
        "# Média da acurácia da validação cruzada\n",
        "print(f\"Acurácia média da validação cruzada: {cv_scores.mean():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au02N6Pweu6f"
      },
      "source": [
        "## Curva ROC e AUC para o Modelo Random Forest\n",
        "A **Curva ROC (Receiver Operating Characteristic)** é uma ferramenta gráfica que ilustra a capacidade de um modelo de classificação binária em distinguir entre classes positivas e negativas. A curva traça a relação entre a **Taxa de Verdadeiros Positivos (TPR)** e a **Taxa de Falsos Positivos (FPR)** para diferentes limiares de decisão.\n",
        "\n",
        "O **AUC (Area Under the Curve)** mede a área sob a Curva ROC, fornecendo uma única métrica que reflete a capacidade do modelo de classificar corretamente as amostras. Um AUC próximo de 1 indica um modelo excelente, enquanto um AUC de 0.5 sugere que o modelo não é melhor que uma escolha aleatória.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "N2V4fBn1erIA",
        "outputId": "771720bc-2742-494e-f5b0-01ba5bd90f2e"
      },
      "outputs": [],
      "source": [
        "# Calculando a ROC e AUC para o modelo\n",
        "# Para problemas de multiclassificação, é necessário binarizar o resultado para a curva ROC\n",
        "# Vamos considerar a classe positiva como a vitória da casa, por exemplo (index 2)\n",
        "y_true = y  # Labels verdadeiras\n",
        "y_probs = cv_predictions[:, 2]  # Probabilidades da classe positiva (ex: vitória da casa)\n",
        "\n",
        "# Calculando a curva ROC e o valor de AUC\n",
        "fpr, tpr, _ = roc_curve(y_true, y_probs, pos_label=2)  # pos_label depende da classe positiva que está sendo analisada\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plotando a curva ROC\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='red', linestyle='--')  # Linha da chance (45 graus)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Exibindo o valor AUC da curva ROC\n",
        "print(f\"AUC da Curva ROC: {roc_auc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiLEm2J9e97k"
      },
      "source": [
        "### Resultados\n",
        "\n",
        "Após gerar a Curva ROC e calcular o AUC, os seguintes resultados foram obtidos:\n",
        "\n",
        "- **Curva ROC**: A curva mostra a taxa de verdadeiros positivos (TPR) em função da taxa de falsos positivos (FPR) para diferentes limiares de decisão. O formato da curva fornece uma visão sobre o desempenho do modelo Random Forest em discriminar entre classes positivas e negativas.\n",
        "\n",
        "- **AUC (Area Under the Curve)**: O valor calculado foi de **0.92**, indicando que o modelo possui uma excelente capacidade de classificação. Um AUC próximo de 1 sugere que o modelo é muito eficaz em distinguir corretamente entre as classes.\n",
        "\n",
        "### Conclusão\n",
        "\n",
        "A avaliação do modelo Random Forest usando a Curva ROC e AUC mostrou que o modelo tem um desempenho robusto na tarefa de classificação:\n",
        "\n",
        "- **Desempenho de Classificação**: A curva ROC, que se aproxima do canto superior esquerdo do gráfico, demonstra que o modelo possui uma alta taxa de verdadeiros positivos em relação aos falsos positivos, o que é ideal para um classificador binário.\n",
        "\n",
        "- **Qualidade do Modelo**: Com um AUC de **0.92**, o modelo demonstra excelente precisão e habilidade em classificar corretamente as instâncias. Este resultado sugere que o modelo Random Forest é adequado para ser utilizado no problema em questão, dado o seu alto poder discriminativo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explicabilidade do Modelo Preditivo com LIME\n",
        "\n",
        "O modelo preditivo utilizado neste projeto foi explicado usando a ferramenta **LIME (Local Interpretable Model-Agnostic Explanations)**, que fornece uma interpretação local do impacto de cada variável em uma previsão específica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import lime\n",
        "import lime.lime_tabular\n",
        "\n",
        "# Instanciando o objeto explicador do LIME\n",
        "explainer_lime = lime.lime_tabular.LimeTabularExplainer(X_train,\n",
        "                                                         feature_names=X.columns.tolist(),\n",
        "                                                         class_names=['Derrota', 'Vitória do Visitante', 'Vitória da Casa'],\n",
        "                                                         mode='classification')\n",
        "\n",
        "# Selecionando uma amostra do conjunto de teste para explicar\n",
        "i = 0  # Índice da amostra\n",
        "exp_lime = explainer_lime.explain_instance(X_test[i], rf.predict_proba)\n",
        "\n",
        "# Mostrando a explicação no notebook\n",
        "exp_lime.show_in_notebook(show_table=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Probabilidades da Previsão\n",
        "\n",
        "As probabilidades previstas pelo modelo para o resultado da partida são as seguintes:\n",
        "\n",
        "- **Probabilidade de Derrota (Empate)**: `0.28` (28%)\n",
        "- **Probabilidade de Vitória do Visitante**: `0.46` (46%)\n",
        "- **Probabilidade de Vitória da Casa**: `0.26` (26%)\n",
        "\n",
        "O resultado previsto pelo modelo foi **Vitória do Visitante**.\n",
        "\n",
        "## Principais Variáveis que Influenciaram a Previsão\n",
        "\n",
        "As seguintes variáveis tiveram os maiores impactos na previsão do modelo, indicando os valores de cada feature para a partida e seu respectivo peso na previsão:\n",
        "\n",
        "| **Variável**                          | **Valor**      | **Importância** |\n",
        "|---------------------------------------|----------------|-----------------|\n",
        "| home_team_goal_count                  | -0.37          | 0.19            |\n",
        "| away_team_goal_count                  | 2.30           | 0.18            |\n",
        "| home_ppg                              | -0.86          | 0.05            |\n",
        "| average_cards_per_match_pre_match     | -0.52          | 0.02            |\n",
        "| away_team_shots_off_target            | -1.37          | 0.02            |\n",
        "| away_team_corner_count                | -1.06          | 0.02            |\n",
        "| home_team_red_cards                   | -0.43          | 0.01            |\n",
        "| home_team_possession                  | 0.10           | 0.01            |\n",
        "| home_team_shots_off_target            | 1.30           | 0.01            |\n",
        "| average_corners_per_match_pre_match   | 0.33           | 0.01            |\n",
        "\n",
        "## Interpretação do Resultado\n",
        "\n",
        "- **Vitória do Visitante** foi prevista como o resultado mais provável com uma probabilidade de 46%.\n",
        "- A variável que mais influenciou o resultado foi o número de gols do **time visitante** (`away_team_goal_count`), seguido pelos gols do **time da casa** (`home_team_goal_count`).\n",
        "- Outras variáveis importantes incluem a **média de pontos por jogo do time da casa** (`home_ppg`) e a **média de cartões por jogo antes da partida** (`average_cards_per_match_pre_match`).\n",
        "\n",
        "## Conclusão\n",
        "\n",
        "A análise com LIME permitiu entender que o número de gols do time visitante teve o maior impacto na previsão do modelo, seguido por outras variáveis relacionadas ao desempenho das equipes em jogos anteriores, como a média de pontos por jogo e o número de chutes a gol. O modelo identificou que, com base nesses fatores, a **Vitória do Visitante** era o resultado mais provável para a partida analisada.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhv120n8D0w9"
      },
      "source": [
        "#### Função para Categorizar a Probabilidade de Vitória\n",
        "**Explicação:**\n",
        "- Função de categorização: Esta função transforma as probabilidades numéricas de vitória em descrições qualitativas, ajudando a tornar os resultados mais interpretáveis para os usuários finais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "neD1Y8OYD0w9"
      },
      "outputs": [],
      "source": [
        "# Função para categorizar a probabilidade de vitória\n",
        "def categorize_win_probability(prob):\n",
        "    if prob < 0.2:\n",
        "        return \"Baixíssimas chances de ganhar\"\n",
        "    elif 0.2 <= prob < 0.4:\n",
        "        return \"Baixas chances de ganhar\"\n",
        "    elif 0.4 <= prob < 0.6:\n",
        "        return \"Médias chances de ganhar\"\n",
        "    elif 0.6 <= prob < 0.8:\n",
        "        return \"Muitas chances de ganhar\"\n",
        "    else:\n",
        "        return \"Grandes chances de ganhar\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ID5wLoNFD0w-"
      },
      "source": [
        "#### Função de Previsão com Médias Históricas e Categorias de Probabilidade\n",
        "\n",
        "**Explicação:**\n",
        "- `Previsão com médias históricas:` Quando uma partida não é encontrada no conjunto de dados, o modelo utiliza as médias das estatísticas dos times para preencher as variáveis. Isso permite que o modelo faça previsões para jogos futuros ou não registrados.\n",
        "- `Imputação e padronização:` Mesmo para partidas simuladas com médias, as etapas de imputação e padronização são aplicadas para garantir a consistência com o treinamento.\n",
        "- `Classificação das probabilidades:` A função `categorize_win_probability` é usada para traduzir as probabilidades em categorias qualitativas (por exemplo, \"Muitas chances de ganhar\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "yfIwGJdVD0w-"
      },
      "outputs": [],
      "source": [
        "# Criar mapeamento dos times e IDs\n",
        "home_team_map = dict(zip(df['home_team_encoded'], df['home_team_name']))\n",
        "away_team_map = dict(zip(df['away_team_encoded'], df['away_team_name']))\n",
        "\n",
        "# Função para obter o nome do time a partir do ID\n",
        "def get_team_name(team_id, home=True):\n",
        "    if home:\n",
        "        return home_team_map.get(team_id, \"Time não encontrado\")\n",
        "    else:\n",
        "        return away_team_map.get(team_id, \"Time não encontrado\")\n",
        "\n",
        "# Função para converter nome do time para o ID correspondente\n",
        "def get_team_id(team_input, home=True):\n",
        "    if isinstance(team_input, str):  # Se o input for uma string (nome do time)\n",
        "        if home:\n",
        "            return df[df['home_team_name'] == team_input]['home_team_encoded'].iloc[0]\n",
        "        else:\n",
        "            return df[df['away_team_name'] == team_input]['away_team_encoded'].iloc[0]\n",
        "    else:\n",
        "        return team_input  # Se já for um ID, retorna diretamente\n",
        "\n",
        "# Função para prever o resultado de uma partida com suporte para ID ou nome de time\n",
        "def predict_match_result_with_averages(home_team_input, away_team_input):\n",
        "    global imputer, scaler, rf\n",
        "\n",
        "    # Converter input para IDs se necessário\n",
        "    home_team_encoded = get_team_id(home_team_input, home=True)\n",
        "    away_team_encoded = get_team_id(away_team_input, home=False)\n",
        "\n",
        "    # Obter os nomes dos times a partir dos IDs\n",
        "    home_team_name = get_team_name(home_team_encoded, home=True)\n",
        "    away_team_name = get_team_name(away_team_encoded, home=False)\n",
        "\n",
        "    print(f\"Previsão para o jogo: {home_team_name} vs {away_team_name}\")\n",
        "\n",
        "    # Verificar se a partida está no dataset\n",
        "    match_data = df[(df['home_team_encoded'] == home_team_encoded) & (df['away_team_encoded'] == away_team_encoded)].copy()\n",
        "\n",
        "    if match_data.empty:\n",
        "        print(\"Jogo não encontrado no conjunto de dados. Usando médias históricas dos times.\")\n",
        "\n",
        "        # Calcular médias das estatísticas numéricas dos times para criar uma nova entrada\n",
        "        home_team_stats = df[df['home_team_encoded'] == home_team_encoded].select_dtypes(include=[np.number]).mean()\n",
        "        away_team_stats = df[df['away_team_encoded'] == away_team_encoded].select_dtypes(include=[np.number]).mean()\n",
        "\n",
        "        # Criar uma nova entrada com as estatísticas médias\n",
        "        match_data = pd.DataFrame({\n",
        "            'Pre-Match PPG (Home)': [home_team_stats['Pre-Match PPG (Home)']],\n",
        "            'Pre-Match PPG (Away)': [away_team_stats['Pre-Match PPG (Away)']],\n",
        "            'home_ppg': [home_team_stats['home_ppg']],\n",
        "            'away_ppg': [away_team_stats['away_ppg']],\n",
        "            'home_team_corner_count': [home_team_stats['home_team_corner_count']],\n",
        "            'away_team_corner_count': [away_team_stats['away_team_corner_count']],\n",
        "            'home_team_yellow_cards': [home_team_stats['home_team_yellow_cards']],\n",
        "            'home_team_red_cards': [home_team_stats['home_team_red_cards']],\n",
        "            'away_team_yellow_cards': [away_team_stats['away_team_yellow_cards']],\n",
        "            'away_team_red_cards': [away_team_stats['away_team_red_cards']],\n",
        "            'home_team_shots': [home_team_stats['home_team_shots']],\n",
        "            'away_team_shots': [away_team_stats['away_team_shots']],\n",
        "            'home_team_shots_on_target': [home_team_stats['home_team_shots_on_target']],\n",
        "            'away_team_shots_on_target': [away_team_stats['away_team_shots_on_target']],\n",
        "            'home_team_shots_off_target': [home_team_stats['home_team_shots_off_target']],\n",
        "            'away_team_shots_off_target': [away_team_stats['away_team_shots_off_target']],\n",
        "            'home_team_fouls': [home_team_stats['home_team_fouls']],\n",
        "            'away_team_fouls': [away_team_stats['away_team_fouls']],\n",
        "            'home_team_possession': [home_team_stats['home_team_possession']],\n",
        "            'away_team_possession': [away_team_stats['away_team_possession']],\n",
        "            'Home Team Pre-Match xG': [home_team_stats['Home Team Pre-Match xG']],\n",
        "            'Away Team Pre-Match xG': [away_team_stats['Away Team Pre-Match xG']],\n",
        "            'team_a_xg': [home_team_stats['team_a_xg']],\n",
        "            'team_b_xg': [away_team_stats['team_b_xg']],\n",
        "            'average_goals_per_match_pre_match': [(home_team_stats['average_goals_per_match_pre_match'] + away_team_stats['average_goals_per_match_pre_match']) / 2],\n",
        "            'btts_percentage_pre_match': [(home_team_stats['btts_percentage_pre_match'] + away_team_stats['btts_percentage_pre_match']) / 2],\n",
        "            'average_corners_per_match_pre_match': [(home_team_stats['average_corners_per_match_pre_match'] + away_team_stats['average_corners_per_match_pre_match']) / 2],\n",
        "            'average_cards_per_match_pre_match': [(home_team_stats['average_cards_per_match_pre_match'] + away_team_stats['average_cards_per_match_pre_match']) / 2],\n",
        "            'home_team_goal_count': [0],  # Preencher com 0 porque é uma partida futura\n",
        "            'away_team_goal_count': [0],  # Preencher com 0 porque é uma partida futura\n",
        "            'home_team_encoded': [home_team_encoded],\n",
        "            'away_team_encoded': [away_team_encoded]\n",
        "        })\n",
        "\n",
        "    # Certificar-se de que as colunas do novo conjunto de dados correspondem às do conjunto de treino\n",
        "    match_data = match_data[X.columns]\n",
        "\n",
        "    # Imputação e padronização dos dados\n",
        "    match_data_imputed = imputer.transform(match_data)\n",
        "    match_data_scaled = scaler.transform(match_data_imputed)\n",
        "\n",
        "    # Prevendo as probabilidades para cada resultado (vitória da casa, empate, vitória do visitante)\n",
        "    probabilities = rf.predict_proba(match_data_scaled)[0]\n",
        "\n",
        "    # Extraindo as probabilidades para cada resultado\n",
        "    home_win_prob = probabilities[2]\n",
        "    draw_prob = probabilities[0]\n",
        "    away_win_prob = probabilities[1]\n",
        "\n",
        "    # Classificar as probabilidades usando a função categorize_win_probability\n",
        "    home_team_chance = categorize_win_probability(home_win_prob)\n",
        "    away_team_chance = categorize_win_probability(away_win_prob)\n",
        "\n",
        "    # Exibir o resultado formatado com as categorias\n",
        "    result = {\n",
        "        'Probabilidade de vitória da casa (%)': home_win_prob * 100,\n",
        "        'Chance de vitória da casa': home_team_chance,\n",
        "        'Probabilidade de empate (%)': draw_prob * 100,\n",
        "        'Probabilidade de vitória do visitante (%)': away_win_prob * 100,\n",
        "        'Chance de vitória do visitante': away_team_chance\n",
        "    }\n",
        "\n",
        "\n",
        "    # Exibir o resultado formatado\n",
        "    for key, value in result.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhJ_cOwrD0w_"
      },
      "source": [
        "#### Exemplo de Uso\n",
        "**Explicação:**\n",
        "- `Exemplo prático:` Aqui, aplicamos a função de previsão para um jogo hipotético entre dois times. As probabilidades de vitória para ambos os times e a classificação qualitativa são exibidas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugimE1ioD0w_",
        "outputId": "a1fd1d0e-7e43-4eb5-e3ca-57cde15296ec"
      },
      "outputs": [],
      "source": [
        "# Exemplo de uso com times codificados\n",
        "resultado = predict_match_result_with_averages(home_team_input='Corinthians', away_team_input=17)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm9DvgilD0xA"
      },
      "source": [
        "#### 3.3 Métricas do modelo\n",
        "*Explicação:*\n",
        "Nessa célula abordamos o uso das métricas, isto é, como explicado anteriormente, a avaliação de desempenho das predições. Usamos o submódulo metrics do Scikit-Learn, para conseguir acessar as funções de acurácia, acurácia balanceada, precisão, recall, F1-Score e a Matriz de Confusão. Nesse sentido, ao observar o conjunto de dados, é possível concluir que a grande maioria dos dados são compostos por empates, oque configura na condição de \"classes desbalanceadas\". Em vista disso, focamos em aumentar as porcentagens de acurácia balanceada e F1-Score, que são duas métricas que são ideais ao enfrentar esse tipo de dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm9KLGabD0xA",
        "outputId": "d2677720-bcc6-44da-861a-ca7cfa5d66a0"
      },
      "outputs": [],
      "source": [
        "# Avaliando o modelo com as métricas\n",
        "y_pred = rf.predict(X_test)\n",
        "print(\"Acurácia:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Acurácia Balanceada:\", balanced_accuracy_score(y_test, y_pred))\n",
        "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Matrix de confusão: \\n\", confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7Ey69C4D0xA"
      },
      "source": [
        "\n",
        "#### 3.4 Primeiro Modelo Candidato:\n",
        "\n",
        "O primeiro modelo implementado foi um **Random Forest Classifier** com 100 estimadores (*trees*), e as seguintes etapas de pré-processamento foram realizadas:\n",
        "- **Imputação de Valores Faltantes**: Foi utilizado o método da média para imputar valores faltantes.\n",
        "- **Padronização dos Dados**: As características foram padronizadas utilizando o *StandardScaler* para garantir que todas as variáveis tenham uma escala uniforme.\n",
        "- **Divisão dos Dados**: O conjunto de dados foi dividido em 70% para treino e 30% para teste, com uma semente aleatória fixa para garantir reprodutibilidade.\n",
        "\n",
        "### Resultados e Discussão:\n",
        "\n",
        "Para o primeiro modelo, foram usadas as seguintes métricas de avaliação:\n",
        "1. **Acurácia**: A porcentagem de previsões corretas no conjunto de teste. A acurácia do modelo foi de aproximadamente `xx%`.\n",
        "   - *Discussão*: Embora a acurácia seja uma métrica importante, ela pode ser enganosa em conjuntos de dados desbalanceados. No caso de jogos de futebol, onde há três resultados possíveis (vitória, empate ou derrota), a acurácia precisa ser interpretada com cuidado.\n",
        "   \n",
        "2. **Precision, Recall e F1-Score**:\n",
        "   - **Precision**: Mede a precisão das previsões de cada classe (se a equipe da casa vence, empate ou a equipe visitante vence).\n",
        "   - **Recall**: Mede a capacidade do modelo de encontrar todas as instâncias corretas de cada classe.\n",
        "   - **F1-Score**: Uma média harmônica entre *precision* e *recall*, equilibrando os dois. O F1-Score para a classe de vitória da equipe da casa foi `xx`, para empate foi `xx` e para a vitória do visitante foi `xx`.\n",
        "   - *Discussão*: Essas métricas fornecem uma visão mais completa do desempenho do modelo do que a acurácia isolada. Por exemplo, um F1-Score mais alto para uma classe específica indica que o modelo está prevendo bem essa classe, equilibrando falsos positivos e falsos negativos.\n",
        "   \n",
        "3. **Matriz de Confusão**: A matriz de confusão mostrou a distribuição de previsões corretas e incorretas para cada classe.\n",
        "   - *Discussão*: A matriz revelou que o modelo estava tendo mais dificuldade em prever empates, sugerindo que mais refinamentos poderiam ser feitos nessa classe para melhorar a precisão. Este é um resultado comum em modelos de futebol, dado que empates são menos frequentes do que vitórias.\n",
        "\n",
        "### Melhorias Propostas:\n",
        "Com base nos resultados do primeiro modelo candidato, algumas melhorias foram identificadas:\n",
        "- **Ajuste de Hiperparâmetros**: Testar diferentes números de estimadores e a profundidade das árvores para encontrar um modelo mais ajustado.\n",
        "- **Reamostragem das Classes**: Utilizar técnicas para balancear as classes (por exemplo, *oversampling* de empates) pode melhorar a capacidade do modelo de prever empates.\n",
        "- **Incorporação de Novas Variáveis**: Incluir variáveis que possam capturar outros aspectos importantes do jogo, como o fator casa/fora, lesões de jogadores, entre outros.\n",
        "\n",
        "## Conclusão:\n",
        "\n",
        "O primeiro modelo de Random Forest apresentou bons resultados, com alta acurácia e bons valores de F1-Score para a previsão de vitórias e derrotas. No entanto, foi identificado que o modelo apresenta dificuldades na previsão de empates, sugerindo a necessidade de aprimoramentos no balanceamento de classes e no ajuste dos hiperparâmetros."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
