{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owXvyuArCGan"
      },
      "source": [
        "# Análise do Arquivo Players\n",
        "Este notebook é dedicado à implementação e análise de um modelo de classificação utilizando o algoritmo XGBoost para prever a probabilidade de jogadores marcarem gols com base em suas características, como desempenho do jogador, números de gols e outras métricas. O objetivo deste notebook é fornecer uma ferramenta para previsões, que pode ser usada para previsões de resultados.\n",
        "\n",
        "# Objetivo\n",
        "O objetivo desse notebook é fornecer previsões se um jogador marcará um gol em uma partida. Através de análise dos dados e do treinamento de um mondelo XGBoost, buscando identificar padrões e caractéristicas que mais influenciam o desempenho dos jogadores.\n",
        "\n",
        "# Como usar Este Notebook\n",
        "1. **Configuração do Ambiente:**\n",
        "\n",
        "- **Google Colab:** No Google Colab, será necessário fazer o upload das tabelas para o Google Drive e montar o drive no notebook.\n",
        "- **Localmente:** Se for rodar o notebook localmente, é necessário baixar as tabelas e colocá-las no mesmo diretório do notebook ou ajustar os caminhos dos arquivos conforme necessário.\n",
        "2. **Instalação de Dependências:**\n",
        "\n",
        "- Certifique-se de que todas as bibliotecas necessárias estão instaladas. Você pode instalar as dependências utilizando o seguinte comando:\n",
        "\n",
        " !pip install -r requirements.txt\n",
        "\n",
        "3. **Execução do Notebook:**\n",
        "- Siga as células de código sequencialmente para garantir que todas as etapas sejam executadas corretamente. Cada seção do notebook está organizada para facilitar a compreensão e a análise dos dados.\n",
        "\n",
        "# Nesse Notebook Será Abordado\n",
        "1. **Preparação e Treinamento de Dados:**\n",
        "- Definição da variável target com base no número de gols e seleção das features a partir do dataset, removendo colunas desnecessárias.\n",
        "- Divisão dos dados em conjunto de treino e teste, e padronização das variáveis para manter a mesma escala.\n",
        "- Implementação do modelo XGBoost para classificar a probabilidade de um jogador marcar gol.\n",
        "\n",
        "2. **Implementação de Função de Previsão:**\n",
        "\n",
        "- Desenvolvimento de uma função que permite prever a probabilidade de um jogador específico marcar um gol com base em seu nome.\n",
        "\n",
        "3. **Avaliação do Modelo:**\n",
        "- Cálculo de métricas de desempenho, como acurácia e acurácia balanceada, além da exibição de um relatório de classificação detalhado.\n",
        "- Visualização da matriz de confusão para melhor compreensão das previsões do modelo.\n",
        "# Dependências\n",
        "Para rodar o notebook de forma local, é recomendado que inicie uma venv (ambiente virtual) e instale as dependências.\n",
        "Em algumas máquinas o xgboost não funicionará, pois ele é muito robusto. Então, caso isso aconteça use o Google Colab\n",
        "\n",
        "Se estiver utilizando o Google Colab, pule esta etapa.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip show xgboost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIlM4VI76CU4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, balanced_accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hWDf26jCCmZ"
      },
      "source": [
        "# Carregando o dataset\n",
        "Feita a importação do arquivo para leitura dos dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oXBErIZB6mMd"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('../data/tratado/players_tratado.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRh1mc85IgLX"
      },
      "source": [
        "# 1. Preparação e Treinamento de Dados\n",
        "\n",
        "Nesta seção, os dados são preparados para o modelo de classificação. Isso inclui a seleção das features e da variável alvo (target), o tratamento de dados ausentes, a padronização das variáveis e o treinamento do modelo XGBoost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhhrcLy7OPnT"
      },
      "source": [
        "#1.1 Seleção de Features\n",
        "O objetivo é prever se um jogador marcará um gol com base no número de gols totais (goals_overall). A variável alvo foi definida como 1 (marcou gol) e 0 (não marcou gol), a partir da coluna goals_overall. Colunas irrelevantes, como jogadores que não entraram em campo e outras caractéristicas, foram removidas, pois não seriam não úteis para o modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EmtWQCA-IY_K"
      },
      "outputs": [],
      "source": [
        "colunas_para_eliminar = ['sm_goals_scored_total_overall','rank_in_club_top_scorer', 'goals_involved_per_90_overall', 'goals_per_90_overall', 'min_per_goal_overall', 'goals_away', 'goals_home']\n",
        "df = df.drop(columns=colunas_para_eliminar)\n",
        "\n",
        "# Filtra o DataFrame para remover os jogadores com aparições em casa e fora de casa igual a 0\n",
        "df = df[(df['appearances_home'] + df['appearances_away']) > 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqJ_ys2lRHNi"
      },
      "source": [
        "# 1.2 Variável alvo\n",
        "Definimos uma coluna target que classifica jogadores como 1 (se fizeram gols) ou 0 (se não fizeram). Em seguida, as features relevantes são selecionadas, enquanto informações como o número total de gols e o nome do jogador são removidas para evitar viés. Os dados são divididos em conjuntos de treino e teste, e as variáveis são padronizadas para garantir consistência nas escalas. O modelo XGBoost é treinado utilizando validação cruzada para calcular o Log Loss e ajustar o modelo. Por fim, o modelo é utilizado para fazer previsões com base nos dados de treino."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "MM1iMKyl4NDM",
        "outputId": "3b5eb0e9-6ced-44e4-9321-50b086d56b7e"
      },
      "outputs": [],
      "source": [
        "# Supondo que 'df' seja o DataFrame contendo os dados\n",
        "\n",
        "# Definir a coluna alvo (target) com base no número de gols\n",
        "df['target'] = df['goals_overall'].apply(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "# Definir as features (X) e a variável target (y)\n",
        "# Remover 'goals_overall' para evitar que o modelo fique dependente dessa informação direta\n",
        "X = df.drop(columns=['goals_overall', 'full_name', 'target', ])  # Remover colunas desnecessárias\n",
        "y = df['target']\n",
        "\n",
        "# Dividir os dados em conjunto de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Padronizar os dados com a mesma escala\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)  # Aplica a padronização nos dados de treino\n",
        "X_test_scaled = scaler.transform(X_test)  # Aplica a mesma padronização nos dados de teste\n",
        "\n",
        "# Treinar o modelo XGBoost com validação cruzada\n",
        "model = xgb.XGBClassifier(\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',  # Você também pode testar 'auc' como métrica alternativa\n",
        "    alpha=10,  # Regularização L1\n",
        "    lambda_=10,  # Regularização L2\n",
        "    subsample=0.8,  # Usar 80% dos dados para cada árvore\n",
        "    colsample_bytree=0.5,  # Usar 80% das features para cada árvore\n",
        "    max_depth=3  # Limitar a profundidade das árvores para evitar overfitting\n",
        ")\n",
        "\n",
        "# Implementar validação cruzada (cv = número de folds)\n",
        "scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='neg_log_loss')\n",
        "\n",
        "# Exibir os resultados da validação cruzada\n",
        "print(f\"Log Loss Médio: {-scores.mean():.4f}\")\n",
        "print(f\"Desvio Padrão do Log Loss: {scores.std():.4f}\")\n",
        "\n",
        "# Ajustar o modelo usando todos os dados de treino\n",
        "model.fit(X_train_scaled, y_train)\n",
        "# Função para prever a probabilidade de um jogador marcar um gol usando o nome do jogador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFwY8GGUJiVr"
      },
      "source": [
        "# 2. Implementação de Função de Previsão\n",
        "Nessa seção, desenvolvemos uma função```predict_player_goal prevê a probabilidade ``` de um jogador marcar um gol com base em um modelo treinado. Ela recebe o nome do jogador, verifica se ele está no dataset e prepara seus dados removendo colunas irrelevantes como goals_overall e full_name. Os dados do jogador são então padronizados usando o mesmo StandardScaler aplicado no treino. Por fim, a função usa o modelo XGBoost para calcular a probabilidade de gol e retorna essa informação em porcentagem.\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "**Desenvolvimento da Função predict_player_goal(player_name)**\n",
        "\n",
        "\n",
        "A função ```predict_player_goal``` tem como objetivo calcular a probabilidade de um jogador marcar um gol. Ela segue os seguintes passos:\n",
        "<br>\n",
        "\n",
        "\n",
        "1. **Verificação da Existência do Jogador:** A função primeiro verifica se o nome do jogador fornecido existe no dataset ```(df['full_name'])```. Se o jogador não for encontrado, uma mensagem de erro é retornada.\n",
        "\n",
        "2. **Seleção e Preparação dos Dados do Jogador:** Após confirmar que o jogador está presente no dataset, os dados referentes a ele são extraídos e algumas colunas irrelevantes, como ```goals_overall``` e ```full_name```, são removidas. Caso a coluna ```target``` também esteja presente, ela é excluída para manter a consistência com o modelo treinado.\n",
        "\n",
        "3. **Padronização dos Dados:** Assim como os dados de treino foram padronizados, os dados do jogador também precisam passar pelo mesmo processo de padronização utilizando o ```StandardScaler``` previamente ajustado.\n",
        "\n",
        "4. **Previsão de Probabilidade:** Após a padronização, os dados do jogador são alimentados no modelo XGBoost, que retorna a probabilidade de o jogador marcar um gol. A probabilidade é então formatada e exibida como uma porcentagem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fbp2aVIyIluM",
        "outputId": "bba3c5d6-14e3-49df-9d05-c83736de0130"
      },
      "outputs": [],
      "source": [
        "# Função para prever a probabilidade de um jogador marcar um gol usando o nome do jogador\n",
        "def predict_player_goal(player_name):\n",
        "    global scaler, model\n",
        "    # Verifica se o nome do jogador existe\n",
        "    if player_name not in df['full_name'].values:\n",
        "        return f\"Jogador com nome {player_name} não encontrado.\"\n",
        "\n",
        "    # Seleciona os dados do jogador com base no nome\n",
        "    player_data = df[df['full_name'] == player_name].copy()\n",
        "\n",
        "    # Remover a coluna 'goals_overall' caso esteja presente, pois ela foi removida durante o treinamento\n",
        "    columns_to_drop = ['goals_overall', 'full_name']\n",
        "    if 'target' in player_data.columns:\n",
        "        columns_to_drop.append('target')\n",
        "\n",
        "    # Remove colunas desnecessárias\n",
        "    player_data = player_data.drop(columns=columns_to_drop)\n",
        "\n",
        "    # Padronização dos dados\n",
        "    player_data_scaled = scaler.transform(player_data)\n",
        "\n",
        "    # Previsão da probabilidade de marcar um gol\n",
        "    probabilidade = model.predict_proba(player_data_scaled)[:, 1]\n",
        "    return f\"A probabilidade do jogador {player_name} marcar um gol é de {probabilidade[0] * 100:.2f}%.\"\n",
        "\n",
        "# Exemplo de uso\n",
        "player_name = \"Agustín Canobbio Graviz\" # fez gol\n",
        "player_name2 = 'Abner Salles da Silva'  # n fez gol\n",
        "player_name3 = 'Adriano Martins da Fonseca' # n fez\n",
        "player_name4 = 'Alan Javier Franco'\n",
        "print(predict_player_goal(player_name))\n",
        "print(predict_player_goal(player_name2))\n",
        "print(predict_player_goal(player_name3))\n",
        "print(predict_player_goal(player_name4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOolZZKGJmGa"
      },
      "source": [
        "# 3. Avaliação do Modelo\n",
        "Após o treinamento, é essencial avaliar o desempenho do modelo para verificar sua eficácia na classificação correta dos jogadores que marcaram gols. Nesta seção, calculamos métricas de desempenho como acurácia, acurácia balanceada, precisão, recall e F1-score. Além disso, visualizamos a matriz de confusão para entender as previsões do modelo. Dessa forma, ao analisar as métricas conseguimos avaliar de forma eficiente a execução do modelo, oque pode nos revelar se o conjunto de dados é satisfatório ou não para a tarefa proposta. Se o desempenho do modelo não for adequado, pode ser necessário realizar ajustes, como a coleta de mais dados, o balanceamento das classes ou a otimização de hiperparâmetros. Com esses insights, é possível aprimorar o modelo ou refinar a abordagem adotada, garantindo resultados mais precisos e confiáveis no futuro.\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "**Cálculo das Métricas de Desempenho:**\n",
        "\n",
        "Utilizamos as previsões do modelo no conjunto de teste para calcular as principais métricas de desempenho. Essas métricas ajudam a entender a precisão do modelo e como ele lida com os falsos positivos e falsos negativos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ttqh4XyM5i-T",
        "outputId": "f2d9616b-b9cc-4158-ad4d-bab9bc3f101e"
      },
      "outputs": [],
      "source": [
        "# Previsões no conjunto de teste\n",
        "y_pred = model.predict(X_test)\n",
        "# Calcular a acurácia\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
        "# Exibir as métricas\n",
        "print(f\"Acurácia do modelo: {accuracy * 100:.2f}%\")\n",
        "print(f\"Acurácia balanceada do modelo: {balanced_accuracy * 100:.2f}%\")\n",
        "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCUU8qMNJqDw"
      },
      "source": [
        "# 4. Visualização da Matriz de Confusão\n",
        "Este código gera uma matriz de confusão para visualizar o desempenho do modelo de classificação em termos de suas previsões. Utilizando o Seaborn, uma biblioteca de visualização de dados do Python, o código cria um heatmap que exibe a matriz de confusão, onde as previsões corretas e incorretas do modelo são claramente indicadas. A matriz mostra a contagem de classificações corretas (verdadeiros positivos e negativos) e incorretas (falsos positivos e negativos) para as classes \"Positivo\" e \"Negativo\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "QQGEJp9Q5lIh",
        "outputId": "aa0d4208-753e-4693-8c23-833c0e9d0451"
      },
      "outputs": [],
      "source": [
        "# Matriz de Confusão\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negativo', 'Positivo'], yticklabels=['Negativo', 'Positivo'])\n",
        "plt.xlabel('Previsão')\n",
        "plt.ylabel('Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POJKDsCrUvLV"
      },
      "source": [
        "# 5. Referências\n",
        "Está é uma seção de referências com relação as bibliotecas que utilizamos ao longo deste arquivo\n",
        "\n",
        "NUMPY. NumPy Documentation. Disponível em: https://numpy.org/doc/.\n",
        "\n",
        "‌PANDAS. pandas documentation. Disponível em: https://pandas.pydata.org/docs/.\n",
        "\n",
        "MATPLOTLIB. Matplotlib: Python plotting — Matplotlib 3.3.4 documentation. Disponível em: https://matplotlib.org/stable/index.html.\n",
        "\n",
        "‌SCIKIT-LEARN. scikit-learn: machine learning in Python. Disponível em: https://scikit-learn.org/stable/.\n",
        "\n",
        "‌SEABORN. seaborn: statistical data visualization — seaborn 0.9.0 documentation. Disponível em: https://seaborn.pydata.org/."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
