{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matches_Predicao_RL\n",
    "\n",
    "Este notebook é dedicado à predição de dados da tabela **Matches** fornecida pela IBM, que contém dados detalhados sobre as partidas, incluindo informações como quantidade de gols nas partidas, cartões amarelos que têm no total, entre outros. O objetivo deste notebook é confirmar as hipóteses e prever mais informações com os dados dessa tabela.\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "O objetivo deste notebook é fornecer uma predição de dados das partidas da série A do Campeonato Brasileiro, ajudando a identificar padrões e tendências que possam ser úteis para diversas aplicações, como previsões de resultados e desempenho dos times.\n",
    "\n",
    "## Como Usar Este Notebook\n",
    "\n",
    "1. **Configuração do Ambiente**:\n",
    "   - **Google Colab**: No Google Colab, será necessário fazer o upload das tabelas para o Google Drive e montar o drive no notebook.\n",
    "   - **Localmente**: Se for rodar o notebook localmente, é necessário baixar as tabelas e colocá-las no mesmo diretório do notebook ou ajustar os caminhos dos arquivos conforme necessário.\n",
    "\n",
    "2. **Instalação de Dependências**:\n",
    "   - Certifique-se de que todas as bibliotecas necessárias estão instaladas. Você pode instalar as dependências utilizando o seguinte comando:\n",
    "     ```python\n",
    "     !pip install -r requirements.txt\n",
    "     ```\n",
    "\n",
    "3. **Execução do Notebook**:\n",
    "   - Antes de rodar esse notebook, execute por completo o notebook `matches_tratado.ipynb` para que sejam exportadas em suas células a\n",
    "   respectiva tabela contendo os dados tratados, que serão utilizados neste notebook.\n",
    "   - Siga as células de código sequencialmente para garantir que todas as etapas sejam executadas corretamente. Cada seção do notebook está organizada para facilitar a compreensão e a análise dos dados.\n",
    "\n",
    "## Nesse Notebook Será Abordado\n",
    "\n",
    "1. **Modelagem para o problema**:\n",
    "   - Apresentar o modelo candidato - qual modelo estamos utilizando e para que;\n",
    "   - Métricas relacionadas ao modelo - avaliação de desempenho.\n",
    "   - Hiperparâmetros - aplicação de GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependências\n",
    "Para rodar o notebook de forma local, é recomendado que inicie uma venv (ambiente virtual) e instale as dependências.\n",
    "\n",
    "Se estiver utilizando o Google Colab, pule esta etapa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instala as dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala as dependências\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando bibliotecas\n",
    "\n",
    "Aqui é importado as dependências necessárias para a executação do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, balanced_accuracy_score, confusion_matrix, roc_curve, roc_auc_score, RocCurveDisplay, auc\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando o Dataset\n",
    "Carrega o CSV da tabela matches tratado para criar um dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../notebooks/data/tratado/matches_tratado.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Segundo Modelo Candidato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Regressão Logística\n",
    "\n",
    "### 1.2 Hipótese do Modelo: Qual a probabilidade de um time ganhar com certas variáveis.\n",
    "\n",
    "##### Premissa Principal:\n",
    "O objetivo de previsão desse modelo é que o desempenho passado de um time, medido por diversas métricas estatísticas (como posse de bola, número de chutes a gol, cartões, etc.), pode prever a probabilidade de um time vencer em uma partida futura. O modelo utiliza uma combinação de variáveis pré-jogo e dados históricos dos times para calcular essas probabilidades.\n",
    "\n",
    "##### Justificativa da Premissa:\n",
    "1. **Posse de bola e estatísticas de ataque e defesa** são fortes indicativos de domínio em uma partida. Times que têm alta posse de bola e boa eficiência nos chutes a gol, geralmente têm uma maior chance de vitória.\n",
    "2. **Cartões, faltas e escanteios** influenciam diretamente o controle da partida e as oportunidades de gol. Uma defesa que comete muitas faltas ou recebe cartões pode ser vulnerável, enquanto escanteios e chances ofensivas contribuem para as probabilidades de marcar gols.\n",
    "3. **Desempenho médio pré-jogo (PPG e xG)**: O número de pontos por jogo e o desempenho esperado de gols (xG) são métricas que oferecem uma visão do histórico do time e indicam sua capacidade de manter o desempenho ou superá-lo em partidas futuras.\n",
    "\n",
    "#### Abordagem Técnica:\n",
    "\n",
    "Nesta parte foi utilizado o modelo de **Regressão Logística**, sendo aplicada para realizar as previsões de futebol. Alguns passos foram: A imputação de valores faltantes, padronização dos dados, divisão dos dados e treinamento do modelo.\n",
    "\n",
    "- A **Regressão Logística** é um modelo estatístico usado para prever a probabilidade de um evento binário (com dois resultados possíveis) ou multiclasse.\n",
    "- O modelo foi treinado com um conjunto de dados que contém estatísticas de partidas anteriores e diversas métricas de desempenho dos times.\n",
    "\n",
    "#### Estrutura do Modelo:\n",
    "\n",
    "- **Variáveis Preditoras**: \n",
    "  - Estatísticas da equipe da casa e da equipe visitante, incluindo posse de bola, número de chutes a gol, cartões amarelos e vermelhos, escanteios, xG (gols esperados) e faltas cometidas.\n",
    "  - Dados pré-jogo como Pre-Match PPG (pontos por jogo) e Pre-Match xG (gols esperados).\n",
    "- **Variável Alvo**: Resultado da partida (vitória da casa, empate ou vitória do visitante).\n",
    "\n",
    "#### Previsão Ajustada:\n",
    "\n",
    "O modelo prevê as probabilidades de três possíveis resultados para a partida:\n",
    "- **Vitória da equipe da casa**\n",
    "- **Empate**\n",
    "- **Vitória da equipe visitante**\n",
    "\n",
    "Além de fornecer as probabilidades em porcentagem, as previsões são categorizadas em níveis de probabilidade, utilizando a função `categorize_win_probability`, que classifica as chances de vitória em:\n",
    "- Baixíssimas chances de ganhar\n",
    "- Baixas chances de ganhar\n",
    "- Médias chances de ganhar\n",
    "- Muitas chances de ganhar\n",
    "- Grandes chances de ganhar\n",
    "\n",
    "Essa categorização ajuda a fornecer uma interpretação mais qualitativa das previsões feitas pelo modelo.\n",
    "\n",
    "#### Exemplo de Funcionamento:\n",
    "\n",
    "O modelo é capaz de prever resultados de partidas futuras, mesmo que os dados dessas partidas não estejam no conjunto de dados de treino. Nesse caso, ele utiliza **médias históricas** dos times para fazer previsões, garantindo que ainda possa fornecer uma probabilidade estimada, com base no desempenho geral dos times.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Criando o Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando a Coluna de Resultado e Definindo Variáveis Preditoras\n",
    "\n",
    "**Explicação**:\n",
    "- `df['result']`: Estamos criando uma nova coluna chamada result que representa o resultado da partida. A classe 2 indica vitória da casa, 1 vitória do visitante, e 0 indica empate.\n",
    "\n",
    "- `Variáveis preditoras (X) e alvo (y)`: As variáveis preditoras são características como posse de bola, chutes a gol, cartões, etc., que são usadas para treinar o modelo. A variável alvo y é o resultado da partida.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a coluna de resultado\n",
    "df['result'] = np.where(df['home_team_goal_count'] > df['away_team_goal_count'], 2, # Vitória da casa\n",
    "                        np.where(df['home_team_goal_count'] < df['away_team_goal_count'], 1, # Vitória do visitante\n",
    "                                 0)) # Derrota\n",
    "\n",
    "# Definindo a variável alvo e os preditores\n",
    "y = df['result']\n",
    "X = df[['home_team_encoded', 'away_team_encoded', 'Pre-Match PPG (Home)', 'Pre-Match PPG (Away)', 'home_ppg', 'away_ppg',\n",
    "        'home_team_goal_count', 'away_team_goal_count', 'home_team_corner_count', 'away_team_corner_count',\n",
    "        'home_team_yellow_cards', 'home_team_red_cards', 'away_team_yellow_cards', 'away_team_red_cards',\n",
    "        'home_team_shots', 'away_team_shots', 'home_team_shots_on_target', 'away_team_shots_on_target',\n",
    "        'home_team_shots_off_target', 'away_team_shots_off_target', 'home_team_fouls', 'away_team_fouls',\n",
    "        'home_team_possession', 'away_team_possession', 'Home Team Pre-Match xG', 'Away Team Pre-Match xG',\n",
    "        'team_a_xg', 'team_b_xg', 'average_goals_per_match_pre_match', 'btts_percentage_pre_match',\n",
    "        'average_corners_per_match_pre_match', 'average_cards_per_match_pre_match']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputação de Valores Faltantes, Padronização e Treinamento do Modelo\n",
    "\n",
    "**Explicação:**\n",
    "\n",
    "- `Imputação de valores faltantes:` Preenchemos os valores ausentes nas variáveis preditoras com a média da respectiva variável, garantindo que o modelo não falhe devido a dados incompletos.\n",
    "- `Padronização dos dados:` Para evitar que as variáveis com escalas diferentes impactem negativamente o modelo, os dados são padronizados usando StandardScaler.\n",
    "- `Divisão treino/teste:` O conjunto de dados é dividido em 60% para treino e 40% para teste, garantindo uma avaliação justa do modelo.\n",
    "- `Logistic Regression:` Treinamos o modelo de Regressão Logística com o número máximo de 100 iterações, que são necessárias para a convergência dos solucionadores.\n",
    "- `Avaliação:` As métricas de acurácia, acurácia balanceada, e a matriz de confusão nos dão uma visão do desempenho do modelo no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputação de valores faltantes\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Padronização dos dados\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# Dividindo os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Criando e treinando o modelo de Regressão Logística\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Avaliando o modelo\n",
    "y_pred = log_reg.predict(X_test)\n",
    "print(\"Acurácia:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Acurácia Balanceada:\", balanced_accuracy_score(y_test, y_pred))\n",
    "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Matriz de confusão: \\n\", confusion_matrix(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hiperparâmetros\n",
    "\n",
    "Hiperparâmetros são parâmetros definidos antes do treinamento do modelo e que influenciam diretamente no desempenho do mesmo. Na Regressão Logística, alguns hiperparâmetros importantes são:\n",
    "\n",
    "**Penalty (penalidade):**\n",
    "\n",
    "- `l1:` Regularização Lasso, que tende a eliminar variáveis irrelevantes zerando seus coeficientes.\n",
    "- `l2:` Regularização Ridge, que encolhe os coeficientes das variáveis sem eliminá-los completamente.\n",
    "\n",
    "A escolha entre L1 e L2 depende da natureza dos dados. A regularização L1 é útil quando há muitas variáveis irrelevantes, enquanto a L2 é útil para evitar overfitting em modelos complexos.\n",
    "\n",
    "**C (parâmetro de regularização):**\n",
    "\n",
    "- O parâmetro C controla a força da regularização. Um valor menor de C implica em uma maior regularização, o que reduz a variância (overfitting) mas pode aumentar o viés. Valores altos de C, por outro lado, permitem que o modelo se ajuste mais aos dados (menor regularização), mas pode resultar em overfitting.\n",
    "\n",
    "**Solver (solucionador):**\n",
    "\n",
    "Define o algoritmo utilizado para ajustar o modelo. Alguns exemplos são:\n",
    "- `liblinear:` Solução para problemas menores e com regularização L1 ou L2.\n",
    "- `saga:` Suporta grandes datasets e regularização L1 e L2.\n",
    "\n",
    "**GridSearchCV para ajuste de Hiperparâmetros:**\n",
    "\n",
    "- O GridSearchCV é uma técnica que automatiza a busca pelos melhores hiperparâmetros, testando diferentes combinações dos mesmos e avaliando o desempenho para selecionar a melhor combinação. Isso ajuda a otimizar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os parâmetros a serem testados\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],  # Regularização L1 ou L2\n",
    "    'C': [0.01, 0.1],  # Inverso da regularização (quanto menor, mais regularização)\n",
    "    'solver': ['liblinear'],  # Solvers que suportam L1 e L2\n",
    "    'max_iter': [100]\n",
    "}\n",
    "\n",
    "# Criando o modelo base\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "# Configurando o GridSearchCV\n",
    "grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Ajustando o GridSearch ao conjunto de dados\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Exibindo os melhores parâmetros\n",
    "print(\"Melhores parâmetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Avaliando o modelo com os melhores parâmetros\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Avaliação do modelo otimizado\n",
    "print(\"Acurácia após ajuste:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Acurácia Balanceada após ajuste:\", balanced_accuracy_score(y_test, y_pred))\n",
    "print(\"Relatório de Classificação após ajuste:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Matriz de confusão após ajuste:\\n\", confusion_matrix(y_pred, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação Cruzada\n",
    "A **validação cruzada** é uma técnica fundamental para avaliar o desempenho de modelos de aprendizado de máquina de forma mais confiável. Em vez de treinar e testar o modelo apenas uma vez com um único conjunto de divisão de dados, a validação cruzada permite que o modelo seja testado múltiplas vezes em diferentes subconjuntos do conjunto de dados, garantindo que os resultados sejam menos dependentes de uma única divisão dos dados.\n",
    "\n",
    "Neste projeto, utilizamos a validação cruzada com **5 folds estratificados**:\n",
    "- O conjunto de dados é dividido em 5 partes (folds) de forma que a proporção das classes seja mantida em cada fold (estratificação).\n",
    "- Em cada iteração, o modelo é treinado em 4 folds e testado no fold restante.\n",
    "- O processo é repetido 5 vezes, trocando os folds de treinamento e teste, e ao final, é calculada a média das métricas de desempenho.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurando a validação cruzada com 5 folds estratificados\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Realizando a validação cruzada e obtendo as previsões de probabilidade\n",
    "cv_scores = cross_val_score(log_reg, X, y, cv=cv, scoring='accuracy')\n",
    "cv_predictions = cross_val_predict(log_reg, X, y, cv=cv, method='predict_proba')\n",
    "\n",
    "# Média da acurácia da validação cruzada\n",
    "print(f\"Acurácia média da validação cruzada: {cv_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curva ROC e AUC para o Modelo de Regressão Logística\n",
    "A **Curva ROC (Receiver Operating Characteristic)** é uma ferramenta gráfica que ilustra a capacidade de um modelo de classificação binária em distinguir entre classes positivas e negativas. A curva traça a relação entre a **Taxa de Verdadeiros Positivos (TPR)** e a **Taxa de Falsos Positivos (FPR)** para diferentes limiares de decisão.\n",
    "\n",
    "O **AUC (Area Under the Curve)** mede a área sob a Curva ROC, fornecendo uma única métrica que reflete a capacidade do modelo de classificar corretamente as amostras. Um AUC próximo de 1 indica um modelo excelente, enquanto um AUC de 0.5 sugere que o modelo não é melhor que uma escolha aleatória.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a ROC e AUC para o modelo\n",
    "# Para problemas de multiclassificação, é necessário binarizar o resultado para a curva ROC\n",
    "# Vamos considerar a classe positiva como a vitória da casa, por exemplo (index 2)\n",
    "y_true = y  # Labels verdadeiras\n",
    "y_probs = cv_predictions[:, 2]  # Probabilidades da classe positiva (ex: vitória da casa)\n",
    "\n",
    "# Calculando a curva ROC e o valor de AUC\n",
    "fpr, tpr, _ = roc_curve(y_true, y_probs, pos_label=2)  # pos_label depende da classe positiva que está sendo analisada\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plotando a curva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')  # Linha da chance (45 graus)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Exibindo o valor AUC da curva ROC\n",
    "print(f\"AUC da Curva ROC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados\n",
    "\n",
    "Após gerar a Curva ROC e calcular o AUC, os seguintes resultados foram obtidos:\n",
    "\n",
    "- **Curva ROC**: A curva mostra a taxa de verdadeiros positivos (TPR) em função da taxa de falsos positivos (FPR) para diferentes limiares de decisão. O formato da curva fornece uma visão sobre o desempenho do modelo de Regressão Logística em discriminar entre classes positivas e negativas.\n",
    "\n",
    "- **AUC (Area Under the Curve)**: O valor calculado foi de **0.94**, indicando que o modelo possui uma excelente capacidade de classificação. Um AUC próximo de 1 sugere que o modelo é muito eficaz em distinguir corretamente entre as classes.\n",
    "\n",
    "### Conclusão\n",
    "\n",
    "A avaliação do modelo usando a Curva ROC e AUC mostrou que o modelo tem um desempenho na tarefa de classificação:\n",
    "\n",
    "- **Desempenho de Classificação**: A curva ROC, que se aproxima do canto superior esquerdo do gráfico, demonstra que o modelo possui uma alta taxa de verdadeiros positivos em relação aos falsos positivos, o que é ideal para um classificador binário.\n",
    "\n",
    "- **Qualidade do Modelo**: Com um AUC de **0.94**, o modelo demonstra excelente precisão e habilidade em classificar corretamente as instâncias. Este resultado sugere que o modelo de Regressão Logística é adequado para ser utilizado no problema em questão, dado o seu alto poder discriminativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para Categorizar a Probabilidade de Vitória\n",
    "**Explicação:**\n",
    "- Função de categorização: Esta função transforma as probabilidades numéricas de vitória em descrições qualitativas, ajudando a tornar os resultados mais interpretáveis para os usuários finais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para categorizar a probabilidade de vitória\n",
    "def categorize_win_probability(prob):\n",
    "    if prob < 0.2:\n",
    "        return \"Baixíssimas chances de ganhar\"\n",
    "    elif 0.2 <= prob < 0.4:\n",
    "        return \"Baixas chances de ganhar\"\n",
    "    elif 0.4 <= prob < 0.6:\n",
    "        return \"Médias chances de ganhar\"\n",
    "    elif 0.6 <= prob < 0.8:\n",
    "        return \"Muitas chances de ganhar\"\n",
    "    elif prob >= 0.8:\n",
    "        return \"Grandes chances de ganhar\"\n",
    "    else:\n",
    "        return \"Erro ao categorizar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função de Previsão com Médias Históricas e Categorias de Probabilidade\n",
    "\n",
    "**Explicação:**\n",
    "- `Previsão com médias históricas:` Quando uma partida não é encontrada no conjunto de dados, o modelo utiliza as médias das estatísticas dos times para preencher as variáveis. Isso permite que o modelo faça previsões para jogos futuros ou não registrados.\n",
    "- `Imputação e padronização:` Mesmo para partidas simuladas com médias, as etapas de imputação e padronização são aplicadas para garantir a consistência com o treinamento.\n",
    "- `Classificação das probabilidades:` A função `categorize_win_probability` é usada para traduzir as probabilidades em categorias qualitativas (por exemplo, \"Muitas chances de ganhar\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar mapeamento dos times e IDs\n",
    "home_team_map = dict(zip(df['home_team_encoded'], df['home_team_name']))\n",
    "away_team_map = dict(zip(df['away_team_encoded'], df['away_team_name']))\n",
    "\n",
    "# Função para obter o nome do time a partir do ID\n",
    "def get_team_name(team_id, home=True):\n",
    "    if home:\n",
    "        return home_team_map.get(team_id, \"Time não encontrado\")\n",
    "    else:\n",
    "        return away_team_map.get(team_id, \"Time não encontrado\")\n",
    "\n",
    "# Função para converter nome do time para o ID correspondente\n",
    "def get_team_id(team_input, home=True):\n",
    "    if isinstance(team_input, str):  # Se o input for uma string (nome do time)\n",
    "        if home:\n",
    "            return df[df['home_team_name'] == team_input]['home_team_encoded'].iloc[0]\n",
    "        else:\n",
    "            return df[df['away_team_name'] == team_input]['away_team_encoded'].iloc[0]\n",
    "    else:\n",
    "        return team_input  # Se já for um ID, retorna diretamente\n",
    "\n",
    "# Função para prever o resultado de uma partida, independentemente de estar no CSV\n",
    "def predict_match_result_with_averages(home_team_input, away_team_input):\n",
    "    global imputer, scaler, log_reg\n",
    "    \n",
    "    # Converter input para IDs se necessário\n",
    "    home_team_encoded = get_team_id(home_team_input, home=True)\n",
    "    away_team_encoded = get_team_id(away_team_input, home=False)\n",
    "\n",
    "    # Obter os nomes dos times a partir dos IDs\n",
    "    home_team_name = get_team_name(home_team_encoded, home=True)\n",
    "    away_team_name = get_team_name(away_team_encoded, home=False)\n",
    "\n",
    "    print(f\"Previsão para o jogo: {home_team_name} vs {away_team_name}\")\n",
    "    \n",
    "    # Verificar se a partida está no dataset\n",
    "    match_data = df[(df['home_team_encoded'] == home_team_encoded) & (df['away_team_encoded'] == away_team_encoded)].copy()\n",
    "    \n",
    "    if match_data.empty:\n",
    "        print(\"Jogo não encontrado no conjunto de dados. Usando médias históricas dos times.\")\n",
    "        \n",
    "        # Calcular médias das estatísticas dos times para criar uma nova entrada\n",
    "        home_team_stats = df[df['home_team_encoded'] == home_team_encoded].select_dtypes(include=[np.number]).mean()\n",
    "        away_team_stats = df[df['away_team_encoded'] == away_team_encoded].select_dtypes(include=[np.number]).mean()\n",
    "\n",
    "        # Criar uma nova entrada com as estatísticas médias, preenchendo as colunas de gols com zero\n",
    "        match_data = pd.DataFrame({\n",
    "            'Pre-Match PPG (Home)': [home_team_stats['Pre-Match PPG (Home)']],\n",
    "            'Pre-Match PPG (Away)': [away_team_stats['Pre-Match PPG (Away)']],\n",
    "            'home_ppg': [home_team_stats['home_ppg']],\n",
    "            'away_ppg': [away_team_stats['away_ppg']],\n",
    "            'home_team_corner_count': [home_team_stats['home_team_corner_count']],\n",
    "            'away_team_corner_count': [away_team_stats['away_team_corner_count']],\n",
    "            'home_team_yellow_cards': [home_team_stats['home_team_yellow_cards']],\n",
    "            'home_team_red_cards': [home_team_stats['home_team_red_cards']],\n",
    "            'away_team_yellow_cards': [away_team_stats['away_team_yellow_cards']],\n",
    "            'away_team_red_cards': [away_team_stats['away_team_red_cards']],\n",
    "            'home_team_shots': [home_team_stats['home_team_shots']],\n",
    "            'away_team_shots': [away_team_stats['away_team_shots']],\n",
    "            'home_team_shots_on_target': [home_team_stats['home_team_shots_on_target']],\n",
    "            'away_team_shots_on_target': [away_team_stats['away_team_shots_on_target']],\n",
    "            'home_team_shots_off_target': [home_team_stats['home_team_shots_off_target']],\n",
    "            'away_team_shots_off_target': [away_team_stats['away_team_shots_off_target']],\n",
    "            'home_team_fouls': [home_team_stats['home_team_fouls']],\n",
    "            'away_team_fouls': [away_team_stats['away_team_fouls']],\n",
    "            'home_team_possession': [home_team_stats['home_team_possession']],\n",
    "            'away_team_possession': [away_team_stats['away_team_possession']],\n",
    "            'Home Team Pre-Match xG': [home_team_stats['Home Team Pre-Match xG']],\n",
    "            'Away Team Pre-Match xG': [away_team_stats['Away Team Pre-Match xG']],\n",
    "            'team_a_xg': [home_team_stats['team_a_xg']],\n",
    "            'team_b_xg': [away_team_stats['team_b_xg']],\n",
    "            'average_goals_per_match_pre_match': [(home_team_stats['average_goals_per_match_pre_match'] + away_team_stats['average_goals_per_match_pre_match']) / 2],\n",
    "            'btts_percentage_pre_match': [(home_team_stats['btts_percentage_pre_match'] + away_team_stats['btts_percentage_pre_match']) / 2],\n",
    "            'average_corners_per_match_pre_match': [(home_team_stats['average_corners_per_match_pre_match'] + away_team_stats['average_corners_per_match_pre_match']) / 2],\n",
    "            'average_cards_per_match_pre_match': [(home_team_stats['average_cards_per_match_pre_match'] + away_team_stats['average_cards_per_match_pre_match']) / 2],\n",
    "            'home_team_goal_count': [0],  # Preencher com 0 porque é uma partida futura\n",
    "            'away_team_goal_count': [0],  # Preencher com 0 porque é uma partida futura\n",
    "            'home_team_encoded': [home_team_encoded],\n",
    "            'away_team_encoded': [away_team_encoded]\n",
    "        })\n",
    "\n",
    "    # Certificar-se de que as colunas do novo conjunto de dados correspondem às do conjunto de treino\n",
    "    match_data = match_data[X.columns]\n",
    "    \n",
    "    # Imputação e padronização dos dados\n",
    "    match_data_imputed = imputer.transform(match_data)\n",
    "    match_data_scaled = scaler.transform(match_data_imputed)\n",
    "    \n",
    "    # Prevendo as probabilidades para cada resultado (vitória da casa, empate, vitória do visitante)\n",
    "    probabilities = log_reg.predict_proba(match_data_scaled)[0]\n",
    "    \n",
    "    # Extraindo as probabilidades para cada resultado\n",
    "    home_win_prob = probabilities[2]\n",
    "    draw_prob = probabilities[0]\n",
    "    away_win_prob = probabilities[1]\n",
    "    \n",
    "    # Classificar as probabilidades usando a função categorize_win_probability\n",
    "    home_team_chance = categorize_win_probability(home_win_prob)\n",
    "    away_team_chance = categorize_win_probability(away_win_prob)\n",
    "    \n",
    "    # Exibir o resultado formatado com as categorias\n",
    "    result = {\n",
    "        'Probabilidade de vitória da casa (%)': home_win_prob * 100,\n",
    "        'Chance de vitória da casa': home_team_chance,\n",
    "        'Probabilidade de empate (%)': draw_prob * 100,\n",
    "        'Probabilidade de vitória do visitante (%)': away_win_prob * 100,\n",
    "        'Chance de vitória do visitante': away_team_chance\n",
    "    }\n",
    "    \n",
    "    # Exibir o resultado formatado\n",
    "    for key, value in result.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemplo de Uso\n",
    "**Explicação:**\n",
    "- `Exemplo prático:` Aqui, aplicamos a função de previsão para um jogo hipotético entre dois times. As probabilidades de vitória para ambos os times e a classificação qualitativa são exibidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso\n",
    "# home_team_id = 13\n",
    "# away_team_id = 10\n",
    "resultado = predict_match_result_with_averages(home_team_input='Palmeiras', away_team_input='Atlético Mineiro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Métricas do modelo\n",
    "***Explicação:***\n",
    "\n",
    "Abordamos o uso das métricas, isto é, a avaliação de desempenho das predições. Usamos o submódulo metrics do Scikit-Learn, para conseguir acessar as funções de acurácia, acurácia balanceada, precisão, recall, F1-Score e a Matriz de Confusão. Nesse sentido, ao observar o conjunto de dados, é possível concluir que a grande maioria dos dados são compostos por empates, oque configura na condição de \"classes desbalanceadas\". Em vista disso, focamos em aumentar as porcentagens de acurácia balanceada e F1-Score, que são duas métricas que são ideais ao enfrentar esse tipo de dados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
