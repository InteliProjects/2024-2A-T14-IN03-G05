{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predição do placar de partidas do futebol\n",
    "\n",
    "Este notebook tem como objetivo desenvolver e avaliar modelos de machine learning para prever o placar de partidas de futebol, utilizando como base dados históricos de partidas e estatísticas dos times. O foco está na criação de um modelo que preveja quantos gols cada time (da casa e visitante) marcará em uma partida.\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "O objetivo deste notebook é estruturar a hipótese de maneira clara e realizar análises que possam confirmá-la ou refutá-la, utilizando métodos estatísticos e exploratórios, culminando na predição do placar das partidas de futebol.\n",
    "\n",
    "\n",
    "## Como Usar Este Notebook\n",
    "\n",
    "1. **Configuração do Ambiente**:\n",
    "   - **Google Colab**: No Google Colab, faça o upload das tabelas para o Google Drive e monte o drive no notebook.\n",
    "   - **Localmente**: Se for rodar localmente, ajuste os caminhos dos arquivos ou coloque-os no mesmo diretório do notebook.\n",
    "\n",
    "2. **Instalação de Dependências**:\n",
    "   - Instale todas as bibliotecas necessárias com o comando:\n",
    " \t```python\n",
    " \t!pip install -r requirements.txt\n",
    " \t```\n",
    "\n",
    "3. **Execução do Notebook**:\n",
    "   - Execute os notebooks relacionados à exploração e ao pré-processamento das tabela `Matches`:\n",
    "  \t- [Notebook - Exploração - Matches](https://github.com/Inteli-College/2024-2A-T14-IN03-G05/blob/3998e6d5984b905ac4588992ce6c31563b3edc0c/notebooks/exploracao/matches_explorado.ipynb)\n",
    "  \t- [Notebook - Pre Processamento - Matches](https://github.com/Inteli-College/2024-2A-T14-IN03-G05/blob/c58b4300d4dd212937e7e43199f2be18878b4b32/notebooks/pre_processamento/matches_processado.ipynb)\n",
    "\n",
    "\n",
    "## Nesse Notebook Será Abordado\n",
    "\n",
    "1. **Modelagem para o problema**:\n",
    "   - Apresentar o modelo e para que estamos utilizando;\n",
    "   - Métricas relacionadas ao modelo - avaliação de desempenho;\n",
    "   - Hiperparâmetros - aplicação de GridSearch.\n",
    "\n",
    "## Importando bibliotecas\n",
    "\n",
    "Aqui é importado as dependências necessárias para a execução do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o arquivo CSV\n",
    "O arquivo matches_tratado.csv é carregado e armazenado na variável df_matches. Este dataset contém as informações das partidas e estatísticas relevantes para a modelagem preditiva, como número de gols, cartões, posse de bola, escanteios, entre outros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches = pd.read_csv('../data/tratado/matches_tratado.csv');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Regressão Logística\n",
    "\n",
    "### 1.2 Hipótese do Modelo: Times que jogam em casa possuem uma tendência maior de ganharem.\n",
    "\n",
    "##### Premissa Principal:\n",
    "O objetivo de previsão desse modelo é que o desempenho passado de um time, medido por diversas métricas estatísticas (como posse de bola, número de chutes a gol, cartões, etc.), ainda assim tem como tendência o time que está jogando em casa ganhar. O modelo utiliza uma combinação de variáveis pré-jogo e dados históricos dos times para calcular essas probabilidades.\n",
    "\n",
    "##### Justificativa da Premissa:\n",
    "1. **Apoio da torcida, familiaridade com o campo e ausência de desgastes físicos e mentais devido a viagens** são fatores podem permitir que o time da casa jogue com mais confiança, resultando em vitórias.\n",
    "2. **Pressão do ambiente adverso e a adaptação ao campo** são fatores que podem prejudicar a performance das equipes, impactando na capacidade de pontuar.\n",
    "\n",
    "### ***Conclusões:***\n",
    "\n",
    "O gráfico confirma a hipótese de que os times têm uma média de pontos maior quando jogam em casa, reforçando a ideia de que o fator casa oferece vantagens significativas em termos de desempenho. A familiaridade com o ambiente, parece desempenhar um papel importante na conquista de pontos pelos times mandantes. Já os times visitantes enfrentam maiores dificuldades, o que justifica a menor média de pontos fora de casa.\n",
    "\n",
    "#### Abordagem Técnica\n",
    "\n",
    "Nesta parte foi utilizado o modelo de **Regressão Logística** e Random Forest, sendo aplicada para realizar as previsões de futebol. Alguns passos foram: A imputação de valores faltantes, padronização dos dados, divisão dos dados e treinamento do modelo.\n",
    "\n",
    "- A **Regressão Logística** é um modelo estatístico usado para prever a probabilidade de um evento binário (com dois resultados possíveis) ou multiclasse.\n",
    "- O **Random Forest** foi utilizado para prever as quantidades de gols dos times em uma partida, com o objetivo de gerar o placar exato e os placares mais prováveis.\n",
    "- O modelo foi treinado com um conjunto de dados que contém estatísticas de partidas anteriores e diversas métricas de desempenho dos times.\n",
    "\n",
    "#### Estrutura do Modelo\n",
    "\n",
    "- **Variáveis Preditoras**: \n",
    "  - Estatísticas da equipe da casa e da equipe visitante, incluindo posse de bola, número de chutes a gol, cartões amarelos e vermelhos, escanteios, xG (gols esperados) e faltas cometidas.\n",
    "  - Dados pré-jogo como Pre-Match PPG (pontos por jogo) e Pre-Match xG (gols esperados).\n",
    "  \n",
    "- **Variável Alvo**: Quantidade de gols do time da casa e do time visitante.\n",
    "\n",
    "#### Previsão Ajustada\n",
    "\n",
    "O modelo utiliza duas abordagens para prever os resultados das partidas de futebol:\n",
    "\n",
    "1. **Previsão do Placar Certeiro**:\n",
    "   - Este modelo é treinado para prever a quantidade exata de gols que o time da casa e o time visitante irão marcar. Utilizando variáveis preditoras, como posse de bola, escanteios, cartões, xG, entre outras, o modelo gera o placar exato esperado para a partida.\n",
    "\n",
    "2. **Previsão dos Top 3 Placares Prováveis**:\n",
    "   - O segundo modelo prevê os três resultados mais prováveis para a partida. Baseado nas estatísticas das equipes e em um sistema de variação nos gols preditos, o modelo gera os três placares mais plausíveis que podem ocorrer durante o jogo, oferecendo uma visão mais ampla das possíveis variações.\n",
    "\n",
    "Essa estrutura permite que  tenha tanto uma previsão certeira quanto uma probabilidade dos cenários mais possíveis para cada partida.\n",
    "\n",
    "#### Exemplo de Funcionamento\n",
    "\n",
    "O modelo é capaz de prever resultados de partidas futuras, mesmo que os dados dessas partidas não estejam no conjunto de dados de treino. Nesse caso, ele utiliza **médias históricas** dos times para fazer previsões, garantindo que ainda possa fornecer um placar estimado, com base no desempenho geral dos times, tanto em termos de gols exatos quanto dos três placares mais prováveis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções para Extração de Features\n",
    "\n",
    "Duas funções principais são usadas para extrair características essenciais para o modelo:\n",
    "\n",
    "- **`calcular_gols_recentes(time_encoded, n=5)`**: Calcula a média de gols marcados por um time nas últimas 5 partidas.\n",
    "- **`calcular_confronto_direto(home_team_encoded, away_team_encoded)`**: Calcula a média de gols nos confrontos diretos entre dois times específicos.\n",
    "\n",
    "Essas informações são adicionadas ao dataset como novas features: **home_gols_recentes**, **away_gols_recentes** e **historico_confronto_direto**.\n",
    "\n",
    "### Seleção de Features\n",
    "\n",
    "Além das features tradicionais, como posse de bola, escanteios e cartões, foram criadas novas variáveis que capturam interações entre os dados e relações mais complexas, ampliando o potencial preditivo do modelo.\n",
    "\n",
    "As principais features utilizadas no treinamento do modelo são:\n",
    "\n",
    "1. **Estatísticas pré-jogo (PPG - Pontos por Jogo)**:\n",
    "   - *Pre-Match PPG (Home)*: Pontos por jogo do time da casa.\n",
    "   - *Pre-Match PPG (Away)*: Pontos por jogo do time visitante.\n",
    "\n",
    "2. **Posse de Bola**:\n",
    "   - *home_team_possession*: Porcentagem de posse de bola do time da casa.\n",
    "   - *away_team_possession*: Porcentagem de posse de bola do time visitante.\n",
    "   - *Nova Feature*: *possession_diff* (diferença de posse de bola entre o time da casa e o visitante).\n",
    "\n",
    "3. **Escanteios**:\n",
    "   - *home_team_corner_count*: Escanteios do time da casa.\n",
    "   - *away_team_corner_count*: Escanteios do time visitante.\n",
    "   - *Nova Feature*: *home_corners_per_possession* e *away_corners_per_possession* (proporção de escanteios por posse de bola).\n",
    "\n",
    "4. **Cartões Amarelos e Vermelhos**:\n",
    "   - *home_team_yellow_cards*: Cartões amarelos do time da casa.\n",
    "   - *away_team_yellow_cards*: Cartões amarelos do time visitante.\n",
    "   - *home_team_red_cards*: Cartões vermelhos do time da casa.\n",
    "   - *away_team_red_cards*: Cartões vermelhos do time visitante.\n",
    "   - *Nova Feature*: *cards_diff* (diferença de cartões entre os times).\n",
    "\n",
    "5. **Eficiência Ofensiva**:\n",
    "   - *Nova Feature*: *home_efficiency_offense* e *away_efficiency_offense* (gols por posse de bola para o time da casa e visitante).\n",
    "\n",
    "6. **Outras Interações Importantes**:\n",
    "   - *xg_diff*: Diferença entre os gols esperados (xG) dos times.\n",
    "   - *ppg_x_xg*: Produto da diferença de PPG e xG do time visitante.\n",
    "   - *xg_x_corner*: Produto da diferença de xG e escanteios.\n",
    "   - *xg_x_card*: Produto de xG do time visitante e a diferença de cartões.\n",
    "   - *corner_x_card*: Produto da diferença de escanteios e cartões.\n",
    "   - *ppg_x_xg_diff*: Produto da diferença de PPG e de xG.\n",
    "   - *ppg_x_corner*: Produto da diferença de PPG e escanteios.\n",
    "   - *xg_x_ppg_away*: Produto da diferença de xG e PPG do time visitante.\n",
    "   - *team_b_xg_x_corner*: Produto do xG do time visitante e a diferença de escanteios.\n",
    "   - *ppg_x_card*: Produto da diferença de PPG e a diferença de cartões.\n",
    "\n",
    "Essas features, incluindo interações e variações calculadas entre as estatísticas, foram cuidadosamente escolhidas para melhorar a performance do modelo, capturando as complexas relações entre os dados de desempenho das equipes.\n",
    "\n",
    "### Divisão de Dados\n",
    "\n",
    "Os dados foram divididos em:\n",
    "\n",
    "- *Conjunto de Treinamento*: 80% dos dados históricos, usados para ajustar o modelo.\n",
    "- *Conjunto de Teste*: 20% dos dados, usados para avaliar o desempenho do modelo.\n",
    "\n",
    "Essa divisão foi aplicada separadamente para as variáveis dependentes (gols do time da casa e gols do time visitante).\n",
    "\n",
    "### Treinamento do Modelo Random Forest\n",
    "\n",
    "Dois modelos de **Random Forest Regressor** foram treinados para prever os gols do time da casa e do time visitante:\n",
    "\n",
    "- *Modelo para o Time da Casa (`best_rf_home`)*: Responsável por prever a quantidade de gols que o time da casa marcará.\n",
    "- *Modelo para o Time Visitante (`best_rf_away`)*: Responsável por prever a quantidade de gols que o time visitante marcará.\n",
    "\n",
    "**Hiperparâmetros Otimizados**: Utilizando técnicas como GridSearchCV e RandomSearch, foram encontrados os melhores hiperparâmetros para cada modelo. Alguns deles incluem:\n",
    "- *n_estimators*: Número de árvores no modelo.\n",
    "- *max_depth*: Profundidade máxima permitida para as árvores.\n",
    "- *min_samples_split*: Número mínimo de amostras necessárias para dividir um nó.\n",
    "- *min_samples_leaf*: Número mínimo de amostras necessárias em um nó folha.\n",
    "\n",
    "Esses hiperparâmetros permitiram melhorar o desempenho dos modelos, equilibrando a capacidade de previsão e a prevenção de overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção de features\n",
    "\n",
    "Essas features foram criadas para melhorar a capacidade preditiva do modelo de machine learning, capturando interações importantes entre as estatísticas dos times em uma partida de futebol. Aqui estão breves descrições de cada uma:\n",
    "\n",
    "1. **Diferença de posse de bola**: Mede a diferença entre a porcentagem de posse de bola do time da casa e do time visitante, indicando o controle de jogo de cada equipe.\n",
    "   \n",
    "2. **Proporção de escanteios por posse de bola**: Calcula a eficiência do time ao gerar escanteios em relação ao tempo que manteve a posse de bola, para ambos os times, casa e visitante.\n",
    "   \n",
    "3. **Diferença de cartões**: Representa a diferença entre o número de cartões amarelos e vermelhos recebidos pelos times da casa e visitante, refletindo o nível de disciplina ou agressividade em campo.\n",
    "\n",
    "4. **Eficiência ofensiva (gols por posse de bola)**: Avalia o quão eficiente é cada time ao marcar gols com base na quantidade de posse de bola que teve durante a partida.\n",
    "\n",
    "Além dessas, outras features são baseadas em diferenças entre métricas importantes como o xG (gols esperados), escanteios, cartões, e pontos por jogo, que ajudam a capturar relações mais complexas e contribuem para melhorar a precisão do modelo na previsão de placares.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1: Diferença de posse de bola\n",
    "df_matches['possession_diff'] = df_matches['home_team_possession'] - df_matches['away_team_possession']\n",
    "\n",
    "# Feature 2: Proporção de escanteios por posse de bola\n",
    "df_matches['home_corners_per_possession'] = df_matches['home_team_corner_count'] / df_matches['home_team_possession']\n",
    "df_matches['away_corners_per_possession'] = df_matches['away_team_corner_count'] / df_matches['away_team_possession']\n",
    "\n",
    "# Feature 3: Diferença de cartões (amarelos e vermelhos)\n",
    "df_matches['cards_diff'] = (\n",
    "    (df_matches['home_team_yellow_cards'] + df_matches['home_team_red_cards']) - \n",
    "    (df_matches['away_team_yellow_cards'] + df_matches['away_team_red_cards'])\n",
    ")\n",
    "\n",
    "# Adicionar as novas features solicitadas (interações entre as 10 variáveis mais importantes)\n",
    "df_matches['xg_x_btts'] = df_matches['team_b_xg'] * df_matches['btts_percentage_pre_match']\n",
    "\n",
    "# Feature 4: Eficiência ofensiva (gols por posse de bola)\n",
    "df_matches['xg_diff'] = df_matches['team_b_xg'] - df_matches['team_a_xg']\n",
    "df_matches['home_efficiency_offense'] = df_matches['home_team_goal_count'] / df_matches['home_team_possession']\n",
    "df_matches['away_efficiency_offense'] = df_matches['away_team_goal_count'] / df_matches['away_team_possession']\n",
    "df_matches['ppg_diff'] = df_matches['away_ppg'] - df_matches['home_ppg']\n",
    "df_matches['ppg_x_xg_diff'] = df_matches['ppg_diff'] * df_matches['xg_diff']\n",
    "df_matches['ppg_x_xg'] = df_matches['ppg_diff'] * df_matches['team_b_xg']\n",
    "df_matches['corner_diff'] = df_matches['home_team_corner_count'] - df_matches['away_team_corner_count']\n",
    "df_matches['xg_x_corner'] = df_matches['xg_diff'] * df_matches['corner_diff']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização 1: Modelo que prevê um único placar para as partidas\n",
    "### Descrição do Código\n",
    "\n",
    "O código realiza várias operações para modelagem preditiva de placares em partidas de futebol. Aqui está uma descrição resumida das principais funções e processos:\n",
    "\n",
    "1. **Função `calcular_gols_recentes`**: Calcula a média de gols marcados por um time nas últimas 5 partidas, permitindo capturar o desempenho recente do time. Isso é feito tanto para o time da casa quanto para o visitante.\n",
    "\n",
    "2. **Função `calcular_confronto_direto`**: Avalia o histórico de confrontos diretos entre dois times, calculando a média de gols marcados em partidas anteriores entre eles.\n",
    "\n",
    "3. **Criação de novas features**: \n",
    "   - As features como `xg_x_btts`, `ppg_x_btts`, e `corner_x_btts` são geradas para capturar interações entre estatísticas de pré-jogo, como gols esperados (xG) e a probabilidade de ambas as equipes marcarem (BTTS).\n",
    "   - Várias outras features relacionadas ao desempenho, posse de bola e cartões são incluídas no conjunto de dados.\n",
    "\n",
    "4. **Treinamento de Modelos Random Forest**: Dois modelos de Random Forest são treinados separadamente para prever os gols do time da casa e do visitante. O conjunto de dados é dividido em treino e teste, e os modelos são treinados com features específicas.\n",
    "\n",
    "5. **Função `prever_placar_otimizado`**: Esta função usa os modelos treinados para prever o placar de uma partida entre dois times. Ela utiliza dados históricos ou médias das estatísticas de cada time para prever a quantidade de gols, retornando o placar final previsto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a média de gols nas últimas 5 partidas para um time\n",
    "def calcular_gols_recentes(time_encoded, n=5):\n",
    "    ultimos_jogos = df_matches[df_matches['home_team_encoded'] == time_encoded].tail(n)\n",
    "    return ultimos_jogos['home_team_goal_count'].mean()\n",
    "\n",
    "# Adicionar a informação de gols recentes ao dataset para time da casa e visitante\n",
    "df_matches['home_gols_recentes'] = df_matches['home_team_encoded'].apply(lambda x: calcular_gols_recentes(x))\n",
    "df_matches['away_gols_recentes'] = df_matches['away_team_encoded'].apply(lambda x: calcular_gols_recentes(x))\n",
    "\n",
    "# Função para calcular o histórico de confrontos diretos entre os times\n",
    "def calcular_confronto_direto(home_team_encoded, away_team_encoded):\n",
    "    confrontos = df_matches[\n",
    "        (df_matches['home_team_encoded'] == home_team_encoded) & \n",
    "        (df_matches['away_team_encoded'] == away_team_encoded)\n",
    "    ]\n",
    "    return confrontos['home_team_goal_count'].mean()\n",
    "\n",
    "# Adicionar feature do histórico de confrontos diretos ao dataset\n",
    "df_matches['historico_confronto_direto'] = df_matches.apply(\n",
    "    lambda row: calcular_confronto_direto(row['home_team_encoded'], row['away_team_encoded']), axis=1\n",
    ")\n",
    "\n",
    "# Selecionar as mesmas features usadas no treinamento, incluindo as novas\n",
    "features = [\n",
    "    'home_team_encoded', 'away_team_encoded', \n",
    "    'Pre-Match PPG (Home)', 'Pre-Match PPG (Away)', \n",
    "    'home_ppg', 'away_ppg', \n",
    "    'home_team_possession', 'away_team_possession', \n",
    "    'home_team_corner_count', 'away_team_corner_count',\n",
    "    'home_team_yellow_cards', 'away_team_yellow_cards',\n",
    "    'home_team_red_cards', 'away_team_red_cards',\n",
    "    'home_gols_recentes', 'away_gols_recentes',  \n",
    "    'historico_confronto_direto',\n",
    "    'xg_diff', 'away_efficiency_offense', 'ppg_x_xg_diff', \n",
    "    'ppg_x_xg', 'corner_diff', 'xg_x_corner'\n",
    "]\n",
    "\n",
    "# Criar o conjunto de dados com as features selecionadas\n",
    "X = df_matches[features]\n",
    "\n",
    "# Definir as variáveis alvo (gols do time da casa e visitante)\n",
    "y_home = df_matches['home_team_goal_count']\n",
    "y_away = df_matches['away_team_goal_count']\n",
    "\n",
    "# Dividir o conjunto de dados em treino e teste\n",
    "X_train, X_test, y_home_train, y_home_test = train_test_split(\n",
    "    X, y_home, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_away_train, y_away_test = train_test_split(\n",
    "    X, y_away, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Salvar a lista de features usadas durante o treinamento\n",
    "train_features = X_train.columns\n",
    "\n",
    "# Treinar o modelo otimizado de RandomForest com as mesmas features\n",
    "best_rf_home = RandomForestRegressor(max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100, random_state=42)\n",
    "best_rf_away = RandomForestRegressor(max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100, random_state=42)\n",
    "\n",
    "# Treinar os modelos com os dados de treino\n",
    "best_rf_home.fit(X_train, y_home_train)\n",
    "best_rf_away.fit(X_train, y_away_train)\n",
    "\n",
    "# Função para prever o placar usando os modelos treinados com as mesmas features\n",
    "def prever_placar_otimizado(home_team_encoded, away_team_encoded):\n",
    "    # Selecionar os dados da partida real entre esses dois times, se disponível\n",
    "    match_data = df_matches[\n",
    "        (df_matches['home_team_encoded'] == home_team_encoded) &\n",
    "        (df_matches['away_team_encoded'] == away_team_encoded)\n",
    "    ]\n",
    "    \n",
    "    # Se houver dados de partidas entre esses times, usar esses dados, senão retornar valores médios para predição\n",
    "    if not match_data.empty:\n",
    "        input_data = match_data.iloc[0:1].copy()  # Pegar apenas uma linha relevante\n",
    "    else:\n",
    "        # Se não houver uma partida direta, usar a média das características de cada time\n",
    "        team_data_home = df_matches[df_matches['home_team_encoded'] == home_team_encoded].mean(numeric_only=True)\n",
    "        team_data_away = df_matches[df_matches['away_team_encoded'] == away_team_encoded].mean(numeric_only=True)\n",
    "\n",
    "        # Criar o input para o modelo baseado nas médias de cada time, garantindo que todas as features usadas no treino estão presentes\n",
    "        input_data = pd.DataFrame({\n",
    "            'home_team_encoded': [home_team_encoded],\n",
    "            'away_team_encoded': [away_team_encoded],\n",
    "            'Pre-Match PPG (Home)': [team_data_home['Pre-Match PPG (Home)']],\n",
    "            'Pre-Match PPG (Away)': [team_data_away['Pre-Match PPG (Away)']],\n",
    "            'home_ppg': [team_data_home['home_ppg']],\n",
    "            'away_ppg': [team_data_away['away_ppg']],\n",
    "            'home_team_possession': [team_data_home['home_team_possession']],\n",
    "            'away_team_possession': [team_data_away['away_team_possession']],\n",
    "            'home_team_corner_count': [team_data_home['home_team_corner_count']],\n",
    "            'away_team_corner_count': [team_data_away['away_team_corner_count']],\n",
    "            'home_team_yellow_cards': [team_data_home['home_team_yellow_cards']],\n",
    "            'away_team_yellow_cards': [team_data_away['away_team_yellow_cards']],\n",
    "            'home_team_red_cards': [team_data_home['home_team_red_cards']],\n",
    "            'away_team_red_cards': [team_data_away['away_team_red_cards']],\n",
    "            'home_gols_recentes': [team_data_home['home_gols_recentes']],\n",
    "            'away_gols_recentes': [team_data_away['away_gols_recentes']],\n",
    "            'historico_confronto_direto': [calcular_confronto_direto(home_team_encoded, away_team_encoded)],\n",
    "            'xg_diff': [team_data_home['xg_diff']],\n",
    "            'away_efficiency_offense': [team_data_home['away_efficiency_offense']],\n",
    "            'home_efficiency_offense': [team_data_home['home_efficiency_offense']],\n",
    "            'ppg_x_xg_diff': [team_data_home['ppg_x_xg_diff']],\n",
    "            'corner_diff': [team_data_home['corner_diff']],\n",
    "            'xg_x_corner': [team_data_home['xg_x_corner']],\n",
    "        })\n",
    "\n",
    "    # Alinhar as features da predição com as do treinamento\n",
    "    input_data = input_data[train_features]\n",
    "\n",
    "    # Prever os gols do time da casa\n",
    "    home_goals_pred = best_rf_home.predict(input_data)\n",
    "    home_goals = round(home_goals_pred[0])\n",
    "\n",
    "    # Prever os gols do time visitante\n",
    "    away_goals_pred = best_rf_away.predict(input_data)\n",
    "    away_goals = round(away_goals_pred[0])\n",
    "\n",
    "    # Retornar o placar previsto\n",
    "    return f\"Placar previsto: {home_goals} x {away_goals}\"\n",
    "\n",
    "# Testar a função com os modelos otimizados\n",
    "prever_placar_otimizado(1 , 13)\n",
    "df_matches.to_csv(\"../../notebooks/modelo/matches_table.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação de métricas\n",
    "**Predição e Avaliação**\n",
    "Após o treinamento dos modelos, as predições para o conjunto de teste são realizadas. As métricas usadas para avaliar o desempenho dos modelos são:\n",
    "\n",
    "**MAE (Erro Médio Absoluto)**: Mede a magnitude média dos erros nas predições.\n",
    "**MSE (Erro Quadrático Médio)**: Penaliza erros maiores.\n",
    "**R² (Coeficiente de Determinação)**: Indica o quão bem o modelo se ajusta aos dados de teste. [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo otimizado de RandomForest com os melhores parâmetros encontrados\n",
    "best_rf_home = RandomForestRegressor(\n",
    "    max_depth=10,               # Melhor max_depth\n",
    "    min_samples_leaf=1,         # Melhor min_samples_leaf\n",
    "    min_samples_split=5,        # Melhor min_samples_split\n",
    "    n_estimators=300,           # Melhor número de árvores\n",
    ")\n",
    "\n",
    "best_rf_away = RandomForestRegressor(\n",
    "    max_depth=10,               # Melhor max_depth\n",
    "    min_samples_leaf=1,         # Melhor min_samples_leaf\n",
    "    min_samples_split=5,        # Melhor min_samples_split\n",
    "    n_estimators=300,           # Melhor número de árvores\n",
    ")\n",
    "\n",
    "# Treinar os modelos com os dados de treino\n",
    "best_rf_home.fit(X_train, y_home_train)\n",
    "best_rf_away.fit(X_train, y_away_train)\n",
    "\n",
    "# Prever os resultados no conjunto de teste \n",
    "y_home_pred = best_rf_home.predict(X_test)\n",
    "y_away_pred = best_rf_away.predict(X_test)\n",
    "\n",
    "# Calcular métricas para as predições de gols do time da casa\n",
    "mae_home = mean_absolute_error(y_home_test, y_home_pred)\n",
    "mse_home = mean_squared_error(y_home_test, y_home_pred)\n",
    "r2_home = r2_score(y_home_test, y_home_pred)\n",
    "\n",
    "# Calcular métricas para as predições de gols do time visitante\n",
    "mae_away = mean_absolute_error(y_away_test, y_away_pred)\n",
    "mse_away = mean_squared_error(y_away_test, y_away_pred)\n",
    "r2_away = r2_score(y_away_test, y_away_pred)\n",
    "\n",
    "# Exibir as métricas de avaliação para o time da casa e visitante\n",
    "print(f\"Métricas para o time da casa:\")\n",
    "print(f\"MAE: {mae_home}\")\n",
    "print(f\"MSE: {mse_home}\")\n",
    "print(f\"R²: {r2_home}\")\n",
    "\n",
    "print(\"\\nMétricas para o time visitante:\")\n",
    "print(f\"MAE: {mae_away}\")\n",
    "print(f\"MSE: {mse_away}\")\n",
    "print(f\"R²: {r2_away}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização 2: Modelo que prevê os 3 placares mais prováveis de acontecerem em um jogo\n",
    "\n",
    "#### 1. **Coleta de Dados Históricos**\n",
    "Os dados históricos das partidas são coletados, e as seguintes features são extraídas:\n",
    "- **Pre-Match PPG (Home)**: Pontos por jogo do time da casa antes da partida.\n",
    "- **Pre-Match PPG (Away)**: Pontos por jogo do time visitante antes da partida.\n",
    "- **away_gols_recentes**: Gols recentes marcados pelo time visitante.\n",
    "- **away_ppg**: Pontos por jogo do time visitante.\n",
    "- **home_ppg**: Pontos por jogo do time da casa.\n",
    "- **home_team_corner_count**: Quantidade de escanteios do time da casa.\n",
    "- **away_team_corner_count**: Quantidade de escanteios do time visitante.\n",
    "- **possession_diff**: Diferença de posse de bola entre os dois times.\n",
    "- **home_corners_per_possession**: Escanteios por posse de bola do time da casa.\n",
    "- **away_corners_per_possession**: Escanteios por posse de bola do time visitante.\n",
    "- **cards_diff**: Diferença de cartões (amarelos/vermelhos) entre os dois times.\n",
    "- **xg_x_btts**: Expected goals (xG) multiplicado pela probabilidade de ambas as equipes marcarem (BTTS).\n",
    "- **xg_diff**: Diferença de xG entre os times.\n",
    "- **home_efficiency_offense**: Eficiência ofensiva do time da casa (gols marcados por posse).\n",
    "- **away_efficiency_offense**: Eficiência ofensiva do time visitante.\n",
    "- **ppg_diff**: Diferença de PPG entre os dois times.\n",
    "- **ppg_x_xg_diff**: Produto entre a diferença de PPG e a diferença de xG.\n",
    "- **corner_diff**: Diferença de escanteios entre os dois times.\n",
    "- **xg_x_corner**: Produto da diferença de xG e da diferença de escanteios.\n",
    "\n",
    "#### 2. **Criação da Variável-Alvo (Target)**\n",
    "A variável-alvo **`match_outcome`** é criada, representando o resultado da partida no formato `home_goals x away_goals`. Isso permite que o modelo seja treinado para prever o placar da partida.\n",
    "\n",
    "#### 3. **Divisão dos Dados em Conjunto de Treinamento e Teste**\n",
    "Os dados são divididos em dois conjuntos:\n",
    "- **Treinamento (80%)**: Usado para treinar o modelo.\n",
    "- **Teste (20%)**: Usado para avaliar a performance do modelo.\n",
    "\n",
    "#### 4. **Treinamento do Modelo**\n",
    "O modelo **RandomForestClassifier** é treinado com as seguintes configurações:\n",
    "- **n_estimators**: 300 (número de árvores na floresta).\n",
    "- **max_depth**: 10 (profundidade máxima das árvores).\n",
    "- **random_state**: 42 (para reprodutibilidade dos resultados).\n",
    "\n",
    "O modelo é ajustado para aprender padrões nos dados que associam as características dos times ao resultado final da partida.\n",
    "\n",
    "#### 5. **Previsão dos Três Placares Mais Prováveis**\n",
    "A função `prever_top_3_placares_futuro(home_team_name, away_team_name)` realiza as seguintes operações:\n",
    "\n",
    "1. Verifica se os nomes dos times fornecidos estão presentes no dataset.\n",
    "2. Calcula as médias das features numéricas relevantes para os dois times.\n",
    "3. Constrói um dicionário com as features usadas no treino, baseadas no histórico dos times fornecidos.\n",
    "4. Cria um **DataFrame** com essas features e o utiliza como input para o modelo.\n",
    "5. O modelo retorna as probabilidades associadas a cada possível placar.\n",
    "6. As três previsões mais prováveis são extraídas, classificadas em ordem decrescente de probabilidade e apresentadas ao usuário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier  # Importação do RandomForestClassifier\n",
    "\n",
    "# Certifique-se de que as features de treino e de previsão são as mesmas\n",
    "train_features = [\n",
    "    'Pre-Match PPG (Home)', 'Pre-Match PPG (Away)', 'away_gols_recentes', \n",
    "    'away_ppg', 'away_team_corner_count', 'home_team_corner_count', \n",
    "    'home_ppg', 'possession_diff', 'home_corners_per_possession', \n",
    "    'away_corners_per_possession', 'cards_diff', 'xg_x_btts', 'xg_diff', \n",
    "    'home_efficiency_offense', 'away_efficiency_offense', 'ppg_diff', \n",
    "    'ppg_x_xg_diff', 'ppg_x_xg', 'corner_diff', 'xg_x_corner'\n",
    "]\n",
    "\n",
    "# Criar a coluna 'match_outcome' com o resultado da partida\n",
    "df_matches['match_outcome'] = df_matches.apply(lambda row: f\"{row['home_team_goal_count']}x{row['away_team_goal_count']}\", axis=1)\n",
    "\n",
    "X = df_matches[train_features]  # Features\n",
    "y = df_matches['match_outcome']  # Target\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir os parâmetros do modelo\n",
    "clf = RandomForestClassifier(n_estimators=300, max_depth=10, random_state=42)\n",
    "\n",
    "# Treinar o modelo\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Função para prever os 3 placares mais prováveis usando características históricas dos times\n",
    "def prever_top_3_placares_futuro(home_team_name, away_team_name):\n",
    "    # Verificar se os times existem no DataFrame\n",
    "    if home_team_name not in df_matches['home_team_name'].values:\n",
    "        print(f\"Time da casa '{home_team_name}' não encontrado no dataset.\")\n",
    "        return\n",
    "    if away_team_name not in df_matches['away_team_name'].values:\n",
    "        print(f\"Time visitante '{away_team_name}' não encontrado no dataset.\")\n",
    "        return\n",
    "    \n",
    "    # Filtrar dados históricos do time da casa e do time visitante\n",
    "    home_team_data = df_matches[df_matches['home_team_name'] == home_team_name].select_dtypes(include='number').mean()\n",
    "    away_team_data = df_matches[df_matches['away_team_name'] == away_team_name].select_dtypes(include='number').mean()\n",
    "\n",
    "    # Construir as features baseadas no histórico dos dois times (com features usadas no treino)\n",
    "    estimated_data = {\n",
    "        'Pre-Match PPG (Home)': home_team_data['Pre-Match PPG (Home)'],\n",
    "        'Pre-Match PPG (Away)': away_team_data['Pre-Match PPG (Away)'],\n",
    "        'away_gols_recentes': away_team_data['away_gols_recentes'],\n",
    "        'away_ppg': away_team_data['away_ppg'],\n",
    "        'away_team_corner_count': away_team_data['away_team_corner_count'],\n",
    "        'home_team_corner_count': home_team_data['home_team_corner_count'],\n",
    "        'home_ppg': home_team_data['home_ppg'],\n",
    "        'possession_diff': home_team_data['home_team_possession'] - away_team_data['away_team_possession'],\n",
    "        'home_corners_per_possession': home_team_data['home_team_corner_count'] / home_team_data['home_team_possession'],\n",
    "        'away_corners_per_possession': away_team_data['away_team_corner_count'] / away_team_data['away_team_possession'],\n",
    "        'cards_diff': (home_team_data['home_team_yellow_cards'] + home_team_data['home_team_red_cards']) -\n",
    "                      (away_team_data['away_team_yellow_cards'] + away_team_data['away_team_red_cards']),\n",
    "        'xg_x_btts': home_team_data['team_b_xg'] * home_team_data['btts_percentage_pre_match'],\n",
    "        'xg_diff': away_team_data['team_b_xg'] - home_team_data['team_a_xg'],\n",
    "        'home_efficiency_offense': home_team_data['home_team_goal_count'] / home_team_data['home_team_possession'],\n",
    "        'away_efficiency_offense': away_team_data['away_team_goal_count'] / away_team_data['away_team_possession'],\n",
    "        'ppg_diff': away_team_data['away_ppg'] - home_team_data['home_ppg'],\n",
    "        'ppg_x_xg_diff': (away_team_data['away_ppg'] - home_team_data['home_ppg']) * (away_team_data['team_b_xg'] - home_team_data['team_a_xg']),\n",
    "        'ppg_x_xg': (away_team_data['away_ppg'] * away_team_data['team_b_xg']),\n",
    "        'corner_diff': home_team_data['home_team_corner_count'] - away_team_data['away_team_corner_count'],\n",
    "        'xg_x_corner': (away_team_data['team_b_xg'] - home_team_data['team_a_xg']) * (home_team_data['home_team_corner_count'] - away_team_data['away_team_corner_count'])\n",
    "    }\n",
    "\n",
    "    # Criar um DataFrame para passar como input para o modelo (usando apenas as features do treino)\n",
    "    input_data = pd.DataFrame([estimated_data])\n",
    "\n",
    "    # Prever probabilidades para todos os possíveis resultados\n",
    "    probabilities = clf.predict_proba(input_data)\n",
    "\n",
    "    # Obter os 3 resultados mais prováveis\n",
    "    top_3_indices = probabilities[0].argsort()[-3:][::-1]  # Índices das 3 maiores probabilidades\n",
    "    top_3_outcomes = [clf.classes_[i] for i in top_3_indices]  # Mapeia para os resultados\n",
    "\n",
    "    # Exibir os resultados\n",
    "    print(f\"Top 3 placares mais prováveis para {home_team_name} vs {away_team_name}:\")\n",
    "    for i, outcome in enumerate(top_3_outcomes, 1):\n",
    "        print(f\"{i}. {outcome}\")\n",
    "\n",
    "    return top_3_outcomes\n",
    "\n",
    "# Testar a função para uma partida futura\n",
    "prever_top_3_placares_futuro('Palmeiras', 'Botafogo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimização com GridSearchCV\n",
    "Para refinar ainda mais o modelo, GridSearchCV é usado para realizar a busca pelos melhores hiperparâmetros do modelo de Random Forest. O grid testado inclui parâmetros como:\n",
    "\n",
    "Número de estimadores `(n_estimators)`.\n",
    "Profundidade máxima `(max_depth)`.\n",
    "Mínimo de amostras para split `(min_samples_split)` e folhas `(min_samples_leaf)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Parâmetros para ajustar\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "# Inicializando o RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=50,  # Número de combinações a testar\n",
    "    cv=3,  # Validação cruzada\n",
    "    verbose=2, \n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Ajustando o modelo com RandomizedSearchCV\n",
    "random_search.fit(X_train, y_away_train)\n",
    "\n",
    "# Ver os melhores hiperparâmetros encontrados\n",
    "print(\"Melhores parâmetros:\", random_search.best_params_)\n",
    "\n",
    "# Testar o modelo com os melhores hiperparâmetros no conjunto de teste\n",
    "best_rf = random_search.best_estimator_\n",
    "y_pred_away = best_rf.predict(X_test)\n",
    "\n",
    "# Avaliar métricas\n",
    "mae_away = mean_absolute_error(y_away_test, y_pred_away)\n",
    "mse_away = mean_squared_error(y_away_test, y_pred_away)\n",
    "r2_away = r2_score(y_away_test, y_pred_away)\n",
    "\n",
    "print(\"MAE:\", mae_away)\n",
    "print(\"MSE:\", mse_away)\n",
    "print(\"R²:\", r2_away)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação com outros modelos\n",
    "Além do processo acima, também foi utilizado alguns outros métodos para tentativa da melhor predição possível da partida.\n",
    "\n",
    "### XGBoost\n",
    "Um algoritmo de aprendizado supervisionado baseado em boosting, que constrói modelos de forma sequencial, corrigindo erros dos modelos anteriores. O XGBoost é eficiente e conhecido por seu bom desempenho em tarefas de regressão e classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Função para calcular a média de gols nas últimas 5 partidas para um time\n",
    "def calcular_gols_recentes(time_encoded, n=5):\n",
    "    ultimos_jogos = df_matches[df_matches['home_team_encoded'] == time_encoded].tail(n)\n",
    "    return ultimos_jogos['home_team_goal_count'].mean()\n",
    "\n",
    "# Adicionar a informação de gols recentes ao dataset para time da casa e visitante\n",
    "df_matches['home_gols_recentes'] = df_matches['home_team_encoded'].apply(lambda x: calcular_gols_recentes(x))\n",
    "df_matches['away_gols_recentes'] = df_matches['away_team_encoded'].apply(lambda x: calcular_gols_recentes(x))\n",
    "\n",
    "# Função para calcular o histórico de confrontos diretos entre os times\n",
    "def calcular_confronto_direto(home_team_encoded, away_team_encoded):\n",
    "    confrontos = df_matches[\n",
    "        (df_matches['home_team_encoded'] == home_team_encoded) & \n",
    "        (df_matches['away_team_encoded'] == away_team_encoded)\n",
    "    ]\n",
    "    return confrontos['home_team_goal_count'].mean()\n",
    "\n",
    "# Adicionar feature do histórico de confrontos diretos ao dataset\n",
    "df_matches['historico_confronto_direto'] = df_matches.apply(\n",
    "    lambda row: calcular_confronto_direto(row['home_team_encoded'], row['away_team_encoded']), axis=1\n",
    ")\n",
    "\n",
    "# Selecionar as mesmas features usadas no treinamento\n",
    "features = [\n",
    "    'home_team_encoded', 'away_team_encoded', \n",
    "    'Pre-Match PPG (Home)', 'Pre-Match PPG (Away)', \n",
    "    'home_ppg', 'away_ppg', \n",
    "    'home_team_possession', 'away_team_possession', \n",
    "    'home_team_corner_count', 'away_team_corner_count',\n",
    "    'home_team_yellow_cards', 'away_team_yellow_cards',\n",
    "    'home_team_red_cards', 'away_team_red_cards',\n",
    "    'home_gols_recentes', 'away_gols_recentes',  \n",
    "    'historico_confronto_direto'  \n",
    "]\n",
    "\n",
    "# Criar o conjunto de dados com as features selecionadas\n",
    "X = df_matches[features]\n",
    "\n",
    "# Definir as variáveis alvo (gols do time da casa e visitante)\n",
    "y_home = df_matches['home_team_goal_count']\n",
    "y_away = df_matches['away_team_goal_count']\n",
    "\n",
    "# Dividir o conjunto de dados em treino e teste\n",
    "X_train, X_test, y_home_train, y_home_test = train_test_split(\n",
    "    X, y_home, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_away_train, y_away_test = train_test_split(\n",
    "    X, y_away, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Salvar a lista de features usadas durante o treinamento\n",
    "train_features = X_train.columns\n",
    "\n",
    "# Treinar o modelo otimizado de XGBoost com as mesmas features\n",
    "best_xgb_home = XGBRegressor(n_estimators=200, learning_rate=0.05, max_depth=10, random_state=42)\n",
    "best_xgb_away = XGBRegressor(n_estimators=200, learning_rate=0.05, max_depth=10, random_state=42)\n",
    "\n",
    "# Treinar os modelos com os dados de treino\n",
    "best_xgb_home.fit(X_train, y_home_train)\n",
    "best_xgb_away.fit(X_train, y_away_train)\n",
    "\n",
    "# Função para prever o placar usando os modelos treinados com as mesmas features\n",
    "def prever_placar_otimizado(home_team_encoded, away_team_encoded):\n",
    "    # Selecionar os dados da partida real entre esses dois times, se disponível\n",
    "    match_data = df_matches[\n",
    "        (df_matches['home_team_encoded'] == home_team_encoded) &\n",
    "        (df_matches['away_team_encoded'] == away_team_encoded)\n",
    "    ]\n",
    "    \n",
    "    # Se houver dados de partidas entre esses times, usar esses dados, senão retornar valores médios para predição\n",
    "    if not match_data.empty:\n",
    "        input_data = match_data.iloc[0:1].copy()  # Pegar apenas uma linha relevante\n",
    "    else:\n",
    "        # Se não houver uma partida direta, usar a média das características de cada time\n",
    "        team_data_home = df_matches[df_matches['home_team_encoded'] == home_team_encoded].mean(numeric_only=True)\n",
    "        team_data_away = df_matches[df_matches['away_team_encoded'] == away_team_encoded].mean(numeric_only=True)\n",
    "\n",
    "        # Criar o input para o modelo baseado nas médias de cada time, garantindo que todas as features usadas no treino estão presentes\n",
    "        input_data = pd.DataFrame({\n",
    "            'home_team_encoded': [home_team_encoded],\n",
    "            'away_team_encoded': [away_team_encoded],\n",
    "            'Pre-Match PPG (Home)': [team_data_home['Pre-Match PPG (Home)']],\n",
    "            'Pre-Match PPG (Away)': [team_data_away['Pre-Match PPG (Away)']],\n",
    "            'home_ppg': [team_data_home['home_ppg']],\n",
    "            'away_ppg': [team_data_away['away_ppg']],\n",
    "            'home_team_possession': [team_data_home['home_team_possession']],\n",
    "            'away_team_possession': [team_data_away['away_team_possession']],\n",
    "            'home_team_corner_count': [team_data_home['home_team_corner_count']],\n",
    "            'away_team_corner_count': [team_data_away['away_team_corner_count']],\n",
    "            'home_team_yellow_cards': [team_data_home['home_team_yellow_cards']],\n",
    "            'away_team_yellow_cards': [team_data_away['away_team_yellow_cards']],\n",
    "            'home_team_red_cards': [team_data_home['home_team_red_cards']],\n",
    "            'away_team_red_cards': [team_data_away['away_team_red_cards']],\n",
    "            'home_gols_recentes': [team_data_home['home_gols_recentes']],\n",
    "            'away_gols_recentes': [team_data_away['away_gols_recentes']],\n",
    "            'historico_confronto_direto': [calcular_confronto_direto(home_team_encoded, away_team_encoded)]\n",
    "        })\n",
    "\n",
    "    # Alinhar as features da predição com as do treinamento\n",
    "    input_data = input_data[train_features]\n",
    "\n",
    "    # Prever os gols do time da casa\n",
    "    home_goals_pred = best_xgb_home.predict(input_data)\n",
    "    home_goals = round(home_goals_pred[0])\n",
    "\n",
    "    # Prever os gols do time visitante\n",
    "    away_goals_pred = best_xgb_away.predict(input_data)\n",
    "    away_goals = round(away_goals_pred[0])\n",
    "\n",
    "    # Retornar o placar previsto\n",
    "    return f\"Placar previsto: {home_goals} x {away_goals}\"\n",
    "\n",
    "# Testar a função com os modelos otimizados\n",
    "prever_placar_otimizado(16, 1)\n",
    "\n",
    "# Prever os resultados no conjunto de teste \n",
    "y_home_pred = best_xgb_home.predict(X_test)\n",
    "y_away_pred = best_xgb_away.predict(X_test)\n",
    "\n",
    "# Calcular métricas para as predições de gols do time da casa\n",
    "mae_home = mean_absolute_error(y_home_test, y_home_pred)\n",
    "mse_home = mean_squared_error(y_home_test, y_home_pred)\n",
    "r2_home = r2_score(y_home_test, y_home_pred)\n",
    "\n",
    "# Calcular métricas para as predições de gols do time visitante\n",
    "mae_away = mean_absolute_error(y_away_test, y_away_pred)\n",
    "mse_away = mean_squared_error(y_away_test, y_away_pred)\n",
    "r2_away = r2_score(y_away_test, y_away_pred)\n",
    "\n",
    "# Exibir as métricas de avaliação para o time da casa e visitante\n",
    "print(f\"Métricas para o time da casa:\")\n",
    "print(f\"MAE: {mae_home}\")\n",
    "print(f\"MSE: {mse_home}\")\n",
    "print(f\"R²: {r2_home}\")\n",
    "\n",
    "print(\"\\nMétricas para o time visitante:\")\n",
    "print(f\"MAE: {mae_away}\")\n",
    "print(f\"MSE: {mse_away}\")\n",
    "print(f\"R²: {r2_away}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação entre XGBoost e Random Forest\n",
    "\n",
    "Neste documento, será comparado dois dos algoritmos mais populares em Machine Learning: **XGBoost** (eXtreme Gradient Boosting) e **Random Forest**. A comparação será baseada em vários aspectos, como a técnica de aprendizado, desempenho, tempo de treinamento, ajuste de hiperparâmetros e adequação a diferentes tipos de problemas.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Definição e Técnicas Utilizadas\n",
    "\n",
    "#### Random Forest\n",
    "O **Random Forest** é um algoritmo de aprendizado de máquina que opera construindo uma série de árvores de decisão durante o treinamento e retornando a média ou a maioria dos resultados (para regressão ou classificação, respectivamente). Ele utiliza **bagging (bootstrap aggregating)**, onde diversas amostras aleatórias são usadas para criar múltiplas árvores independentes. Cada árvore é treinada em uma amostra diferente dos dados de treino.\n",
    "\n",
    "**Técnicas usadas:**\n",
    "- **Bagging**: Combina o resultado de várias árvores de decisão treinadas em subconjuntos diferentes dos dados.\n",
    "- **Diversidade de Árvores**: A aleatoriedade é introduzida selecionando diferentes subconjuntos de amostras e características para cada árvore.\n",
    "- **Votação/Média**: No caso de classificação, as previsões são decididas por voto majoritário. Em regressão, é calculada a média das previsões.\n",
    "\n",
    "#### XGBoost\n",
    "O **XGBoost** é uma implementação eficiente e escalável de **gradient boosting**, uma técnica de aprendizado por conjunto. Ele constrói árvores de decisão de maneira sequencial, onde cada árvore tenta corrigir os erros cometidos pelas árvores anteriores. O XGBoost introduz várias otimizações de hardware e software, tornando-o mais rápido e eficiente em comparação com outros métodos de boosting.\n",
    "\n",
    "**Técnicas usadas:**\n",
    "- **Boosting Gradiente**: Adiciona árvores de forma sequencial para corrigir os erros das anteriores.\n",
    "- **Regularização**: Evita o overfitting aplicando penalizações aos coeficientes das árvores.\n",
    "- **Poda de Árvore**: Poda de forma inteligente árvores irrelevantes durante o processo de aprendizado.\n",
    "- **Parallel Processing**: XGBoost utiliza múltiplos núcleos de CPU para acelerar o treinamento.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Desempenho\n",
    "\n",
    "#### Random Forest\n",
    "- **Velocidade de Treinamento**: Em geral, o treinamento do Random Forest é mais rápido do que o XGBoost para pequenos conjuntos de dados, mas pode se tornar mais lento à medida que o número de árvores ou a profundidade das árvores aumenta.\n",
    "- **Desempenho**: O Random Forest tem um desempenho robusto, especialmente em problemas com poucos dados ou com dados ruidosos. Como usa várias árvores independentes, é menos suscetível ao overfitting.\n",
    "- **Generalização**: Graças ao processo de bagging e ao uso de múltiplas árvores, o Random Forest tende a generalizar bem.\n",
    "\n",
    "#### XGBoost\n",
    "- **Velocidade de Treinamento**: XGBoost pode ser mais lento no treinamento inicial devido à natureza sequencial de suas árvores, mas é altamente otimizado para grandes conjuntos de dados e hardware moderno.\n",
    "- **Desempenho**: XGBoost tende a ser mais preciso em relação ao Random Forest em muitos casos, especialmente em competições de ciência de dados (como no Kaggle), devido à sua capacidade de corrigir erros anteriores e à regularização.\n",
    "- **Generalização**: XGBoost é mais propenso ao overfitting em pequenos datasets se não for bem regulado, mas com o ajuste correto de parâmetros, ele pode ter excelente generalização.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Ajuste de Hiperparâmetros\n",
    "\n",
    "#### Random Forest\n",
    "- O Random Forest é relativamente simples de ajustar. Seus principais hiperparâmetros incluem:\n",
    "  - **n_estimators**: O número de árvores no modelo.\n",
    "  - **max_depth**: A profundidade máxima permitida para cada árvore.\n",
    "  - **min_samples_split**: O número mínimo de amostras necessárias para dividir um nó.\n",
    "  - **max_features**: O número de características a serem consideradas em cada divisão.\n",
    "  \n",
    "  A escolha desses parâmetros geralmente não é muito crítica, pois o modelo é mais robusto a pequenos erros de ajuste, devido à independência das árvores.\n",
    "\n",
    "#### XGBoost\n",
    "- XGBoost requer um ajuste de hiperparâmetros mais cuidadoso para maximizar seu desempenho. Os parâmetros mais importantes incluem:\n",
    "  - **learning_rate**: Controla o peso das árvores adicionadas ao modelo.\n",
    "  - **n_estimators**: O número de árvores.\n",
    "  - **max_depth**: A profundidade máxima das árvores.\n",
    "  - **subsample**: A fração de amostras usadas para treinar cada árvore.\n",
    "  - **min_child_weight**: Número mínimo de amostras necessárias em um nó folha para fazer uma divisão.\n",
    "  - **gamma**: Penalidade de regularização para novos nós.\n",
    "\n",
    "  Ajustar esses parâmetros pode ser mais complexo, mas oferece controle refinado sobre o modelo e pode resultar em um desempenho superior se feito corretamente.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Adequação a Diferentes Cenários\n",
    "\n",
    "#### Random Forest\n",
    "- **Vantagens**:\n",
    "  - Funciona bem com dados de alta dimensionalidade.\n",
    "  - Bom para conjuntos de dados ruidosos ou que possuem muitos outliers.\n",
    "  - Simples de ajustar e configurar.\n",
    "  - Mais robusto para evitar overfitting em comparação com XGBoost.\n",
    "- **Desvantagens**:\n",
    "  - Pode ser mais lento com grandes conjuntos de dados.\n",
    "  - Não capta muito bem relações complexas, pois todas as árvores são independentes.\n",
    "\n",
    "#### XGBoost\n",
    "- **Vantagens**:\n",
    "  - Funciona muito bem em conjuntos de dados grandes e complexos.\n",
    "  - Permite corrigir erros progressivamente e melhora a precisão geral.\n",
    "  - Tem um desempenho muito alto em competições de aprendizado de máquina.\n",
    "  - Oferece regularização para evitar overfitting, mesmo em grandes datasets.\n",
    "- **Desvantagens**:\n",
    "  - Mais propenso ao overfitting em pequenos conjuntos de dados se não houver ajuste adequado.\n",
    "  - Ajuste de hiperparâmetros pode ser mais complicado e demorado.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Casos de Uso\n",
    "\n",
    "#### Random Forest é mais adequado para:\n",
    "- **Conjuntos de dados pequenos ou médios** onde a simplicidade e a robustez são mais importantes do que o desempenho ideal.\n",
    "- Problemas onde os dados têm ruído e outliers.\n",
    "- **Cenários onde se busca um modelo de baseline** simples e rápido de implementar.\n",
    "\n",
    "#### XGBoost é mais adequado para:\n",
    "- **Conjuntos de dados grandes** e **complexos**.\n",
    "- Cenários onde o desempenho é crítico, como em competições ou projetos de produção de alto desempenho.\n",
    "- Problemas onde há um **forte foco em precisão** e em **minimizar o erro**, mesmo que isso exija mais tempo para ajuste e treino.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Comparação Geral\n",
    "\n",
    "| **Critério**               | **Random Forest**                           | **XGBoost**                                |\n",
    "|----------------------------|---------------------------------------------|--------------------------------------------|\n",
    "| **Técnica**                 | Bagging                                     | Boosting                                   |\n",
    "| **Velocidade de Treinamento** | Rápido em conjuntos menores, mas pode ser lento em grandes datasets | Mais lento inicialmente, mas otimizado para grandes datasets |\n",
    "| **Desempenho**              | Bom desempenho com ajuste mínimo            | Melhor desempenho, mas exige ajuste cuidadoso |\n",
    "| **Tolerância a Overfitting** | Alta tolerância devido à independência das árvores | Pode overfitar se mal ajustado |\n",
    "| **Ajuste de Hiperparâmetros** | Relativamente simples                      | Mais complexo e preciso |\n",
    "| **Melhor uso em**           | Pequenos datasets, baseline simples         | Grandes datasets, precisão máxima, competições |\n",
    "| **Generalização**           | Geralmente boa, mesmo com ajuste mínimo     | Requer ajuste de regularização para boa generalização |\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Conclusão\n",
    "\n",
    "- **Random Forest** é uma ótima escolha quando se precisa de um modelo robusto que funcione bem com dados variados e não requer muito ajuste de hiperparâmetros.\n",
    "- **XGBoost** é a escolha ideal para projetos que exigem o melhor desempenho possível, especialmente quando há dados grandes e complexos e pode investir tempo em ajustar os parâmetros.\n",
    "\n",
    "Se um modelo rápido e eficaz com uma boa base de desempenho sem muita complicação é o ideal, **Random Forest** é a escolha mais segura. Por outro lado, se o objetivo é maximizar a precisão e há tempo e recursos para ajustar hiperparâmetros, **XGBoost** geralmente proporciona um desempenho superior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências\n",
    "Está é uma seção de referências com relação as bibliotecas que utilizamos ao longo deste arquivo\n",
    "\n",
    "[1] Júnior, Clébio de Oliveira. “Prevendo Números: Entendendo as Métricas R2, MAE, MAPE, MSE E RMSE.” Data Hackers, 13 Dec. 2021, medium.com/data-hackers/prevendo-n%C3%BAmeros-entendendo-m%C3%A9tricas-de-regress%C3%A3o-35545e011e70."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
