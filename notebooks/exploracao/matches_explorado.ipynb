{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKqBnAbY_yFy"
      },
      "source": [
        "# Exploração de dados do Arquivo Matches\n",
        "\n",
        "Este notebook é dedicado na exploração incial da tabela **Matches** fornecida pela IBM, que contém dados detalhados sobre partidas realizadas, incluindo informações sobre os times e seus respectivos resultados. O objetivo deste notebook é facilitar a visualização e a análise desses dados, proporcionando estatísticas essenciais para estudos e pesquisas.\n",
        "\n",
        "## Objetivo\n",
        "\n",
        "O objetivo deste notebook é fornecer uma análise detalhada dos dados de partidas, ajudando a identificar padrões e tendências que possam ser úteis para diversas aplicações, como previsões de resultados e desempenho dos times.\n",
        "\n",
        "## Como Usar Este Notebook\n",
        "\n",
        "1. **Configuração do Ambiente**:\n",
        "   - **Google Colab**: No Google Colab, será necessário fazer o upload das tabelas para o Google Drive e montar o drive no notebook.\n",
        "   - **Localmente**: Se for rodar o notebook localmente, é necessário baixar as tabelas e colocá-las no mesmo diretório do notebook ou ajustar os caminhos dos arquivos conforme necessário.\n",
        "\n",
        "2. **Instalação de Dependências**:\n",
        "   - Certifique-se de que todas as bibliotecas necessárias estão instaladas. Você pode instalar as dependências utilizando o seguinte comando:\n",
        "     ```python\n",
        "     !pip install -r requirements.txt\n",
        "     ```\n",
        "\n",
        "3. **Execução do Notebook**:\n",
        "   - Siga as células de código sequencialmente para garantir que todas as etapas sejam executadas corretamente. Cada seção do notebook está organizada para facilitar a compreensão e a análise dos dados.\n",
        "\n",
        "## Nesse Notebook Será Abordado\n",
        "\n",
        "1. **Exploração de Dados**:\n",
        "   - Realização de estatísticas descritivas básicas de cada coluna, identificando se cada coluna é numérica ou categórica.\n",
        "   - Visualização dos dados através de gráficos para entender melhor a distribuição e as relações entre as variáveis.\n",
        "   - Produção de pelo menos 3 gráficos para visualizar a relação entre variáveis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijIwb3AL_yF1"
      },
      "source": [
        "# Dependências\n",
        "Para rodar o notebook de forma local, é recomendado que inicie uma venv (ambiente virtual) e instale as dependências.\n",
        "\n",
        "Se estiver utilizando o Google Colab, pule esta etapa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "377ADtO50l49"
      },
      "source": [
        "# Importando bibliotecas\n",
        "\n",
        "Aqui é importado as dependências necessárias para a executação do projeto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8Wx5s42OQqMr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd #para ler, visualizar e printar infos do df\n",
        "import matplotlib.pyplot as plt #para construir e customizar gráficos\n",
        "import seaborn as sns #para visualizar uns gráficos\n",
        "import numpy as np #numpy porque é sempre bom importar numpy\n",
        "import math #para executar operações matemáticas\n",
        "from scipy.stats.mstats import winsorize #para realizar a winsorização\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder #para realizar o pré-processamento de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUULBGIl0pyp"
      },
      "source": [
        "# Carregando o dataset\n",
        "\n",
        "Feita a importação do arquivo para leitura dos dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "al14FkqhuuTm"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('../../notebooks/data/matches_nao_tratado.csv', sep=',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwViIQImLyKN"
      },
      "source": [
        "# 1. Análise Exploratória de dados\n",
        "\n",
        "A Análise Exploratória de Dados (AED) é uma área na ciência de dados utilizada para examinar e investigar conjuntos de dados através de técnicas estatísticas e de visualização. O objetivo principal da AED é facilitar o entendimento, a navegação e o uso dos dados, permitindo que padrões, anomalias e relações entre variáveis sejam identificados de maneira eficiente. No contexto deste projeto, a AED será aplicada para obter estatísticas iniciais que orientarão as etapas subsequentes da análise de dados, como o pré-processamento e a formulação de hipóteses.\n",
        "\n",
        "Nesta etapa, serão realizadas as seguintes atividades:\n",
        "- **Informações gerais**: Coleta e apresentação de informações básicas sobre o conjunto de dados.\n",
        "- **Identificação das colunas numéricas e categóricas**: Classificação das variáveis do conjunto de dados em numéricas e categóricas, facilitando a aplicação de técnicas estatísticas apropriadas para cada tipo.\n",
        "- **Estatística descritiva das colunas**: Cálculo de medidas estatísticas como média, mediana, desvio padrão, entre outras, para resumir as características principais das variáveis numéricas e categóricas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVHE3OOQ0t3t"
      },
      "source": [
        "## 1.1 Visualização e exploração de dados\n",
        "\n",
        "Nesta subseção, será abordado as técnicas e métodos utilizados para a visualização e exploração inicial dos dados. Através dessas técnicas, é possível obter uma compreensão preliminar da estrutura e das características do conjunto de dados, o que é essencial para orientar as etapas subsequentes da análise.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw0pChEtOjtc"
      },
      "source": [
        "Utilizando o comando `shape` abaixo, se observa que há 380 linhas e 57 colunas a serem tratadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeaEsYdL_yF4"
      },
      "outputs": [],
      "source": [
        "df.shape #para obter quantidade de linhas e colunas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDQYzbdbIgmW"
      },
      "source": [
        "Com o método `.info()` consegue se obter informações detalhadas sobre o DataFrame. Especificamente, ele permite analisar os tipos de variáveis presentes no conjunto de dados.\n",
        "\n",
        "- **Identificação de colunas com variáveis numéricas**: Observando os tipos de dados associados a essas colunas, como valores inteiros (`int64`) e de ponto flutuante (`float64`), que são indicativos de variáveis numéricas.\n",
        "- **Identificação de colunas com variáveis categóricas**: Analisando os tipos de dados (`object` ou `category`) e a quantidade de valores únicos em cada coluna, que geralmente indicam variáveis categóricas.\n",
        "\n",
        "Dessa forma foi observado que a tabela tem 8 colunas categóricas e 49 numéricas. Informações importantes para o pré-processamento, onde irá ocorrer uma codificação transformando essas colunas categóricas em numéricas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ta0BrIgiuyEN"
      },
      "outputs": [],
      "source": [
        "df.info() #para obter informações do dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8jvOap3LEVs"
      },
      "source": [
        "O método `.describe()` é utilizado para fornecer um resumo estatístico detalhado das variáveis numéricas. Ao utilizar o `.describe()`, obtemos informações como a média, desvio padrão, valores mínimo e máximo, além dos quartis. Com esses dados é possível entender a distribuição e a variabilidade dos dados, ajudando a identificar padrões, tendências, valores nulos e possíveis *outliers*. Portanto, com esse resumo fica mais prático e rápido na etapa de pré-processamento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuQLipzau3TN"
      },
      "outputs": [],
      "source": [
        "df.describe() #para obter estatísticas descritivas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0nJnPtJ00td"
      },
      "source": [
        "## 1.2 Valores Nulos\n",
        "\n",
        "Aqui é feita a verificação de valores nulos no DataFrame utilizando o método `isnull().sum()`. Este método permite contar a quantidade de valores NaN (Not a Number) em cada coluna, facilitando a identificação de colunas que necessitam de tratamento para lidar com dados ausentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDiYa5gX06aS"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum() #para ver contagem de valores NaN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RgG0pUWTYgL"
      },
      "source": [
        "Além disso, é importante verificar a presença de linhas duplicadas no DataFrame. Utilizamos o método `duplicated()` para identificar essas linhas, garantindo que cada entrada no conjunto de dados seja única e evitando redundâncias que possam distorcer a análise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzYpS4Bl1E9O"
      },
      "outputs": [],
      "source": [
        "df[df.duplicated(keep='first')] # para identificar linhas duplicadas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cePWRTLTTv1K"
      },
      "source": [
        "Nas células anteriores foi observado que os valores nulos só se encontram nas colunas categóricas e não nas numéricas. Além disso, não há linhas duplicadas no conjunto de dados.\n",
        "\n",
        "A presença de valores nulos nas colunas categóricas requer um tratamento específico, que pode incluir a imputação de valores ou a exclusão das linhas afetadas, dependendo do contexto e da importância dessas colunas para a análise. A ausência de valores nulos nas colunas numéricas simplifica o pré-processamento dessas variáveis, permitindo uma análise mais direta.\n",
        "\n",
        "Após a análise das colunas categóricas e numéricas será decidido se os valores nulos serão excluídos ou imputados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU7AfC771Ggs"
      },
      "source": [
        "## 1.3 Identificação e Seleção de Colunas\n",
        "\n",
        "Nesta seção, é realizado a identificação das colunas presentes no dataset, classificando-as em numéricas e categóricas. Essa é uma etapa importante para direcionar as próximas análises, permitindo que possamos aplicar técnicas de estatística descritiva adequadas para cada tipo de dado e preparar as colunas corretamente para o pré-processamento.\n",
        "\n",
        "O código abaixo realiza essa divisão entre colunas categóricas e numéricas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZ9iIIgB1KFU"
      },
      "outputs": [],
      "source": [
        "# Identificação das colunas\n",
        "columns_info = df.dtypes\n",
        "\n",
        "# Obtém os tipos de dados de todas as colunas do DataFrame 'df' e armazena na variável 'columns_info'.\n",
        "# Seleciona todas as colunas do DataFrame 'df' que têm tipos de dados numéricos e armazena os nomes dessas colunas em uma lista chamada 'numerical_cols'.\n",
        "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "# Seleciona todas as colunas do DataFrame 'df' que não têm tipos de dados numéricos e armazena os nomes dessas colunas em uma lista chamada 'categorical_cols'.\n",
        "categorical_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "# Imprime a lista de colunas numéricas.\n",
        "print(f\"Colunas Numéricas: {numerical_cols}\")\n",
        "\n",
        "# Imprime a lista de colunas categóricas.\n",
        "print(f\"Colunas Categóricas: {categorical_cols}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWQeuWGEzXSG"
      },
      "source": [
        " A partir dessa divisão, foi realizada uma análise crítica para determinar quais colunas seriam mantidas no modelo preditivo e quais seriam excluídas, com base em sua relevância e potencial impacto nos resultados.\n",
        "\n",
        "### Colunas Categóricas\n",
        "\n",
        "As colunas categóricas foram analisadas para determinar sua utilidade no modelo. Decidimos manter aquelas que apresentam informações relevantes para a previsão, como o nome dos times e o status das partidas. Colunas que não fornecem valor direto para a análise, como datas e nomes de estádios, foram excluídas, ficando 2 categóricas.\n",
        "\n",
        "### Colunas Numéricas\n",
        "\n",
        "As colunas numéricas também passaram por uma avaliação cuidadosa. Mantivemos aquelas que contribuem diretamente para a análise preditiva, como dados de desempenho dos times e estatísticas de jogo. Algumas colunas foram consideradas redundantes ou irrelevantes, como contagens acumulativas ou identificadores temporais, e foram removidas do dataset, ficando 33 numéricas.\n",
        "\n",
        "### Resumo do Dataset\n",
        "\n",
        "A tabela abaixo resume a quantidade de colunas numéricas e categóricas que foram identificadas e mantidas para análise:\n",
        "\n",
        "| Dataset  | Colunas Numéricas | Colunas Categóricas |\n",
        "|----------|-------------------|---------------------|\n",
        "| Matches  | 33                | 2                   |\n",
        "\n",
        "Após essa filtragem, o dataset ficou mais enxuto e focado, o que nos permitirá conduzir análises mais precisas e relevantes nas etapas subsequentes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGy_DFUh4NnQ"
      },
      "source": [
        "## 1.4 Adicionando nova variável\n",
        "\n",
        "Para enriquecer a exploração dos dados e permitir análises mais detalhadas, foi criada uma nova variável que agrega informações essenciais sobre o desempenho das equipes durante as partidas. Essas variáveis sintetizam diferentes aspectos do jogo, facilitando a identificação de padrões e a realização de previsões.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "e5hnfTjn4UU8"
      },
      "outputs": [],
      "source": [
        "df['result'] = np.where(df['home_team_goal_count'] > df['away_team_goal_count'], 'home_win',\n",
        "                           np.where(df['home_team_goal_count'] < df['away_team_goal_count'], 'away_win', 'tie'))\n",
        "\n",
        "df.to_csv('../../notebooks/data/matches_nao_tratado.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRJn3MqWWaU-"
      },
      "source": [
        "### Criação da Variável\n",
        "\n",
        "- **Resultado da Partida (`result`)**: Foi criada uma nova coluna que indica o resultado da partida, classificando-o como `home_win` (vitória do time da casa), `away_win` (vitória do time visitante), ou `tie` (empate). Essa variável será fundamental para explorar as condições que levam a um time vencer ou empatar.\n",
        "\n",
        "\n",
        "### Utilização da Variável\n",
        "\n",
        "Essa nova variável foi adicionadas ao modelo com o objetivo de ampliar o escopo das análises exploratórias, permitindo uma investigação mais profunda sobre os fatores que impactam os resultados das partidas. Com essas adições, a análise fica mais aprofundada para identificar relações complexas entre diferentes aspectos do jogo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.5 Gráficos\n",
        "\n",
        "Para ilustrar melhor a exploração de dados, foram feitos dois gráficos:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Quantidade de gols marcados pelo time da casa \n",
        "\n",
        "Mostrar a distribuição de uma variável numérica específica, como a quantidade de gols marcados pelo time da casa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df['home_team_goal_count'], bins=10, kde=True)\n",
        "plt.title('Distribuição dos Gols Marcados pelo Time da Casa')\n",
        "plt.xlabel('Gols Marcados')\n",
        "plt.ylabel('Frequência')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Comparação de resultados dos times\n",
        "\n",
        "Comparar a frequência de resultados categóricos das colunas home_win, away_win, tie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='result', data=df)\n",
        "plt.title('Distribuição dos Resultados das Partidas')\n",
        "plt.xlabel('Resultado')\n",
        "plt.ylabel('Frequência')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a6M--fBqXgn"
      },
      "source": [
        "# 2. Referências\n",
        "\n",
        "Está é uma seção de referências com relação as bibliotecas que utilizamos ao longo deste arquivo\n",
        "\n",
        "NUMPY. NumPy Documentation. Disponível em: <https://numpy.org/doc/>.\n",
        "\n",
        "‌PANDAS. pandas documentation. Disponível em: <https://pandas.pydata.org/docs/>.\n",
        "\n",
        "MATPLOTLIB. Matplotlib: Python plotting — Matplotlib 3.3.4 documentation. Disponível em: <https://matplotlib.org/stable/index.html>.\n",
        "\n",
        "‌SEABORN. seaborn: statistical data visualization — seaborn 0.9.0 documentation. Disponível em: <https://seaborn.pydata.org/>.\n",
        "\n",
        "‌SciPy documentation — SciPy v1.8.1 Manual. Disponível em: <https://docs.scipy.org/doc/scipy/>.\n",
        "\n",
        "‌PYTHON SOFTWARE FOUNDATION. Math — Mathematical Functions — Python 3.8.3rc1 Documentation. Disponível em: <https://docs.python.org/3/library/math.html>.\n",
        "\n",
        "‌SCIKIT-LEARN. scikit-learn: machine learning in Python. Disponível em: <https://scikit-learn.org/stable/>.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
