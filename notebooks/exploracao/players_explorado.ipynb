{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploração de dados do Arquivo Players\n",
    "\n",
    "Este notebook é dedicado na exploração incial da tabela **Players** fornecida pela IBM, que contém dados detalhados sobre partidas realizadas, incluindo informações sobre os jogadores e seus respectivos resultados. O objetivo deste notebook é facilitar a visualização e a análise desses dados, proporcionando estatísticas essenciais para estudos e pesquisas.\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "O objetivo deste notebook é fornecer uma análise detalhada dos dados, ajudando a identificar padrões e tendências que possam ser úteis para diversas aplicações, como previsões de resultados e desempenho dos jogadores.\n",
    "\n",
    "## Como Usar Este Notebook\n",
    "\n",
    "1. **Configuração do Ambiente**:\n",
    "   - **Google Colab**: No Google Colab, será necessário fazer o upload das tabelas para o Google Drive e montar o drive no notebook.\n",
    "   - **Localmente**: Se for rodar o notebook localmente, é necessário baixar as tabelas e colocá-las no mesmo diretório do notebook ou ajustar os caminhos dos arquivos conforme necessário.\n",
    "\n",
    "2. **Instalação de Dependências**:\n",
    "   - Certifique-se de que todas as bibliotecas necessárias estão instaladas. Você pode instalar as dependências utilizando o seguinte comando:\n",
    "     ```python\n",
    "     !pip install -r requirements.txt\n",
    "     ```\n",
    "\n",
    "3. **Execução do Notebook**:\n",
    "   - Siga as células de código sequencialmente para garantir que todas as etapas sejam executadas corretamente. Cada seção do notebook está organizada para facilitar a compreensão e a análise dos dados.\n",
    "\n",
    "## Nesse Notebook Será Abordado\n",
    "\n",
    "1. **Exploração de Dados**:\n",
    "   - Realização de estatísticas descritivas básicas de cada coluna, identificando se cada coluna é numérica ou categórica.\n",
    "   - Visualização dos dados através de gráficos para entender melhor a distribuição e as relações entre as variáveis.\n",
    "   - Produção de pelo menos 3 gráficos para visualizar a relação entre variáveis.\n",
    "\n",
    "# Dependências\n",
    "Para rodar o notebook de forma local, é recomendado que inicie uma venv (ambiente virtual) e instale as dependências.\n",
    "\n",
    "Se estiver utilizando o Google Colab, pule esta etapa.\n",
    "\n",
    "# Importando bibliotecas\n",
    "\n",
    "Aqui é importado as dependências necessárias para a executação do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #para ler, visualizar e printar infos do df\n",
    "import matplotlib.pyplot as plt #para construir e customizar gráficos\n",
    "import seaborn as sns #para visualizar uns gráficos\n",
    "import numpy as np #numpy porque é sempre bom importar numpy\n",
    "import math #para executar operações matemáticas\n",
    "from scipy.stats.mstats import winsorize #para realizar a winsorização\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder #para realizar o pré-processamento de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando o dataset\n",
    "\n",
    "Feita a importação do arquivo para leitura dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../notebooks/data/tratado/players_tratado.csv', sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Análise Exploratória de dados\n",
    "\n",
    "A Análise Exploratória de Dados (AED) é uma área na ciência de dados utilizada para examinar e investigar conjuntos de dados através de técnicas estatísticas e de visualização. O objetivo principal da AED é facilitar o entendimento, a navegação e o uso dos dados, permitindo que padrões, anomalias e relações entre variáveis sejam identificados de maneira eficiente. No contexto deste projeto, a AED será aplicada para obter estatísticas iniciais que orientarão as etapas subsequentes da análise de dados, como o pré-processamento e a formulação de hipóteses.\n",
    "\n",
    "Nesta etapa, serão realizadas as seguintes atividades:\n",
    "- **Informações gerais**: Coleta e apresentação de informações básicas sobre o conjunto de dados.\n",
    "- **Identificação das colunas numéricas e categóricas**: Classificação das variáveis do conjunto de dados em numéricas e categóricas, facilitando a aplicação de técnicas estatísticas apropriadas para cada tipo.\n",
    "- **Estatística descritiva das colunas**: Cálculo de medidas estatísticas como média, mediana, desvio padrão, entre outras, para resumir as características principais das variáveis numéricas e categóricas.\n",
    "\n",
    "## 1.1 Visualização e exploração de dados\n",
    "\n",
    "Nesta subseção, será abordado as técnicas e métodos utilizados para a visualização e exploração inicial dos dados. Através dessas técnicas, é possível obter uma compreensão preliminar da estrutura e das características do conjunto de dados, o que é essencial para orientar as etapas subsequentes da análise.\n",
    "\n",
    "Utilizando o comando `shape` abaixo, se observa que há 380 linhas e 57 colunas a serem tratadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape #para obter quantidade de linhas e colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o método `.info()` consegue se obter informações detalhadas sobre o DataFrame. Especificamente, ele permite analisar os tipos de variáveis presentes no conjunto de dados.\n",
    "\n",
    "- **Identificação de colunas com variáveis numéricas**: Observando os tipos de dados associados a essas colunas, como valores inteiros (`int64`) e de ponto flutuante (`float64`), que são indicativos de variáveis numéricas.\n",
    "- **Identificação de colunas com variáveis categóricas**: Analisando os tipos de dados (`object` ou `category`) e a quantidade de valores únicos em cada coluna, que geralmente indicam variáveis categóricas.\n",
    "\n",
    "Dessa forma foi observado que a tabela tem 271 colunas categóricas e 6 numéricas. Informações importantes para o pré-processamento, onde irá ocorrer uma codificação transformando essas colunas categóricas em numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() #para obter informações do dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método `.describe()` é utilizado para fornecer um resumo estatístico detalhado das variáveis numéricas. Ao utilizar o `.describe()`, obtemos informações como a média, desvio padrão, valores mínimo e máximo, além dos quartis. Com esses dados é possível entender a distribuição e a variabilidade dos dados, ajudando a identificar padrões, tendências, valores nulos e possíveis *outliers*. Portanto, com esse resumo fica mais prático e rápido na etapa de pré-processamento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Valores Nulos\n",
    "\n",
    "Aqui é feita a verificação de valores nulos no DataFrame utilizando o método `isnull().sum()`. Este método permite contar a quantidade de valores NaN (Not a Number) em cada coluna, facilitando a identificação de colunas que necessitam de tratamento para lidar com dados ausentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() #para ver contagem de valores NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated(keep='first')] # para identificar linhas duplicadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nas células anteriores foi observado que os valores nulos só se encontram nas colunas categóricas e não nas numéricas. Além disso, não há linhas duplicadas no conjunto de dados.\n",
    "\n",
    "A presença de valores nulos nas colunas categóricas requer um tratamento específico, que pode incluir a imputação de valores ou a exclusão das linhas afetadas, dependendo do contexto e da importância dessas colunas para a análise. A ausência de valores nulos nas colunas numéricas simplifica o pré-processamento dessas variáveis, permitindo uma análise mais direta.\n",
    "\n",
    "Após a análise das colunas categóricas e numéricas será decidido se os valores nulos serão excluídos ou imputados.\n",
    "\n",
    "Além disso, é importante verificar a presença de linhas duplicadas no DataFrame. Utilizamos o método `duplicated()` para identificar essas linhas, garantindo que cada entrada no conjunto de dados seja única e evitando redundâncias que possam distorcer a análise.\n",
    "\n",
    "## 1.3 Identificação e Seleção de Colunas\n",
    "\n",
    "Nesta seção, é realizado a identificação das colunas presentes no dataset, classificando-as em numéricas e categóricas. Essa é uma etapa importante para direcionar as próximas análises, permitindo que possamos aplicar técnicas de estatística descritiva adequadas para cada tipo de dado e preparar as colunas corretamente para o pré-processamento.\n",
    "\n",
    "O código abaixo realiza essa divisão entre colunas categóricas e numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificação das colunas\n",
    "columns_info = df.dtypes\n",
    "\n",
    "# Obtém os tipos de dados de todas as colunas do DataFrame 'df' e armazena na variável 'columns_info'.\n",
    "# Seleciona todas as colunas do DataFrame 'df' que têm tipos de dados numéricos e armazena os nomes dessas colunas em uma lista chamada 'numerical_cols'.\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Seleciona todas as colunas do DataFrame 'df' que não têm tipos de dados numéricos e armazena os nomes dessas colunas em uma lista chamada 'categorical_cols'.\n",
    "categorical_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "# Imprime a lista de colunas numéricas.\n",
    "print(f\"Colunas Numéricas: {numerical_cols}\")\n",
    "\n",
    "# Imprime a lista de colunas categóricas.\n",
    "print(f\"Colunas Categóricas: {categorical_cols}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A partir dessa divisão, foi realizada uma análise crítica para determinar quais colunas seriam mantidas no modelo preditivo e quais seriam excluídas, com base em sua relevância e potencial impacto nos resultados.\n",
    "\n",
    "### Colunas Categóricas\n",
    "\n",
    "As colunas categóricas foram analisadas para determinar sua utilidade no modelo. Decidimos manter aquelas que apresentam informações relevantes para a previsão, como o nome dos times e o status das partidas. Colunas que não fornecem valor direto para a análise, como datas e nomes de estádios, foram excluídas, ficando 6 categóricas.\n",
    "\n",
    "### Colunas Numéricas\n",
    "\n",
    "As colunas numéricas também passaram por uma avaliação cuidadosa. Mantivemos aquelas que contribuem diretamente para a análise preditiva, como dados de desempenho dos times e estatísticas de jogo. Algumas colunas foram consideradas redundantes ou irrelevantes, como contagens acumulativas ou identificadores temporais, e foram removidas do dataset, ficando 271 numéricas.\n",
    "\n",
    "### Resumo do Dataset\n",
    "\n",
    "A tabela abaixo resume a quantidade de colunas numéricas e categóricas que foram identificadas e mantidas para análise:\n",
    "\n",
    "| Dataset  | Colunas Numéricas | Colunas Categóricas |\n",
    "|----------|-------------------|---------------------|\n",
    "| Matches  | 271                | 6                   |\n",
    "\n",
    "Após essa filtragem, o dataset ficou mais enxuto e focado, o que nos permitirá conduzir análises mais precisas e relevantes nas etapas subsequentes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Referências\n",
    "\n",
    "Está é uma seção de referências com relação as bibliotecas que utilizamos ao longo deste arquivo\n",
    "\n",
    "NUMPY. NumPy Documentation. Disponível em: <https://numpy.org/doc/>.\n",
    "\n",
    "‌PANDAS. pandas documentation. Disponível em: <https://pandas.pydata.org/docs/>.\n",
    "\n",
    "MATPLOTLIB. Matplotlib: Python plotting — Matplotlib 3.3.4 documentation. Disponível em: <https://matplotlib.org/stable/index.html>.\n",
    "\n",
    "‌SEABORN. seaborn: statistical data visualization — seaborn 0.9.0 documentation. Disponível em: <https://seaborn.pydata.org/>.\n",
    "\n",
    "‌SciPy documentation — SciPy v1.8.1 Manual. Disponível em: <https://docs.scipy.org/doc/scipy/>.\n",
    "\n",
    "‌PYTHON SOFTWARE FOUNDATION. Math — Mathematical Functions — Python 3.8.3rc1 Documentation. Disponível em: <https://docs.python.org/3/library/math.html>.\n",
    "\n",
    "‌SCIKIT-LEARN. scikit-learn: machine learning in Python. Disponível em: <https://scikit-learn.org/stable/>.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
