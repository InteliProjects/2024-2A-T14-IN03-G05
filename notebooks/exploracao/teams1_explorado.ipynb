{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploração de Dados do Arquivo Teams1\n",
    "\n",
    "Este notebook foca na **exploração inicial dos dados** contidos na tabela **Teams1**, fornecida pela IBM, que inclui diversas informações detalhadas sobre os times da série A do Campeonato Brasileiro. O objetivo é entender as principais características dos dados, realizando uma análise descritiva e visual das variáveis envolvidas, além de identificar padrões e possíveis correlações entre as variáveis. Esta análise é crucial para a fase posterior de modelagem e geração de insights mais complexos.\n",
    "\n",
    "## Objetivo da Exploração de Dados\n",
    "\n",
    "O principal objetivo desta seção é explorar os dados de maneira detalhada, identificando as propriedades das variáveis e compreendendo as relações entre elas. Esta etapa é fundamental para garantir que as futuras análises e modelagens sejam baseadas em dados bem compreendidos e preparados.\n",
    "\n",
    "## Como Usar Este Notebook\n",
    "\n",
    "1. **Configuração do Ambiente**:\n",
    "   - **Google Colab**: Se você estiver usando o Google Colab, será necessário fazer o upload das tabelas para o Google Drive e montar o drive no notebook.\n",
    "   - **Localmente**: Se estiver rodando o notebook localmente, baixe as tabelas e coloque-as no mesmo diretório do notebook ou ajuste os caminhos dos arquivos conforme necessário.\n",
    "\n",
    "2. **Instalação de Dependências**:\n",
    "   - Certifique-se de que todas as bibliotecas necessárias estão instaladas no ambiente de execução. Para garantir isso, você pode utilizar um arquivo de dependências (como `requirements.txt`), ou instalar as bibliotecas manualmente.\n",
    "\n",
    "3. **Execução do Notebook**:\n",
    "   - Siga as células de código de maneira sequencial. Cada seção do notebook está organizada para fornecer uma análise progressiva dos dados.\n",
    "   - Inicie pela **exploração dos dados** para obter uma visão geral e, posteriormente, siga para o **pré-processamento dos dados** e outras análises avançadas.\n",
    "\n",
    "## Nesse notebook será abordado\n",
    "\n",
    "1. **Leitura dos Dados**:\n",
    "   - Visualização inicial das primeiras linhas da tabela para entender a estrutura dos dados, as variáveis envolvidas e o tipo de informação contida.\n",
    "   - Identificação de possíveis problemas como valores ausentes ou inconsistentes, que necessitam de tratamento posterior.\n",
    "\n",
    "2. **Análise Descritiva**:\n",
    "   - Realizar uma análise descritiva básica de cada coluna, como média, mediana, moda, valores máximos e mínimos, além da dispersão dos dados.\n",
    "   - Compreender como as variáveis numéricas, como a quantidade de gols, cartões amarelos e partidas jogadas, estão distribuídas.\n",
    "   - Avaliar a presença de valores extremos ou discrepantes (outliers) que possam impactar a análise.\n",
    "   \n",
    "3. **Identificação de Tipos de Dados**:\n",
    "   - Classificar as variáveis da tabela em numéricas (como gols e cartões) e categóricas (como nomes de times ou ligas).\n",
    "   - Verificar se há colunas que possam ser transformadas ou codificadas posteriormente, como variáveis categóricas que devem ser convertidas para análise quantitativa.\n",
    "   - Examinar a existência de dados faltantes e definir como lidar com eles.\n",
    "\n",
    "4. **Visualização dos Dados**:\n",
    "   - Produzir gráficos e visualizações para entender a distribuição dos dados e as relações entre as variáveis.\n",
    "   - Criar ao menos três gráficos para facilitar a compreensão dos padrões, como:\n",
    "     - **Histograma**\n",
    "     - **Gráfico de barras**\n",
    "     - **Gráfico de dispersão**\n",
    "   \n",
    "5. **Resumo das Observações**:\n",
    "   - Após a análise descritiva e a visualização dos dados, realizar um resumo das principais observações, como tendências gerais, variações significativas entre os times e qualquer padrão interessante que possa ser explorado em análises posteriores.\n",
    "\n",
    "Com essas etapas, espera-se obter uma compreensão mais aprofundada dos dados contidos na tabela **Teams1**, preparando o terreno para fases subsequentes de análise mais avançada e modelagem. A visualização gráfica, aliada à estatística descritiva, oferece insights valiosos para a identificação de padrões e correlações importantes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependências\n",
    "Para rodar o notebook de forma local, é recomendado que inicie uma venv (ambiente virtual) e instale as dependências.\n",
    "\n",
    "Se estiver utilizando o Google Colab, pule esta etapa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala as dependências\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando bibliotecas\n",
    "\n",
    "Aqui é importado as dependências necessárias para a executação do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #para ler, visualizar e printar infos do df\n",
    "import matplotlib.pyplot as plt #para construir e customizar gráficos\n",
    "import seaborn as sns #para visualizar uns gráficos\n",
    "import numpy as np #numpy porque é sempre bom importar numpy\n",
    "import math #para executar operações matemáticas\n",
    "from scipy import stats #para executar testes estatísticos\n",
    "from scipy.stats.mstats import winsorize #para realizar a winsorização\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder #para realizar o pré-processamento de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando o dataset\n",
    "\n",
    "Feita a importação do arquivo para leitura dos dados.\n",
    "\n",
    "Na leitura de dados vamos conseguir carregar os dados para depois serem análisados\n",
    "\n",
    "* O arquivo CSV contendo as estatísticas das equipes é lido e armazenado na variável dados\n",
    "Depois que executar esse código vamos conseguir ler o arquivo e 'armazenar' na variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv('../../notebooks/data/teams1_nao_tratado.csv')\n",
    "dados\n",
    "\n",
    "# Quando executado, lê o arquivo e 'armazena' na variável \"dados\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Análise Exploratória de dados\n",
    "\n",
    "A Análise Exploratória de Dados (AED) é uma área na ciência de dados utilizada para examinar e investigar conjuntos de dados através de técnicas estatísticas e de visualização. O objetivo principal da AED é facilitar o entendimento, a navegação e o uso dos dados, permitindo que padrões, anomalias e relações entre variáveis sejam identificados de maneira eficiente. No contexto deste projeto, a AED será aplicada para obter estatísticas iniciais que orientarão as etapas subsequentes da análise de dados, como o pré-processamento e a formulação de hipóteses.\n",
    "\n",
    "Nesta etapa, serão realizadas as seguintes atividades:\n",
    "- **Informações gerais**: Coleta e apresentação de informações básicas sobre o conjunto de dados.\n",
    "- **Identificação das colunas numéricas e categóricas**: Classificação das variáveis do conjunto de dados em numéricas e categóricas, facilitando a aplicação de técnicas estatísticas apropriadas para cada tipo.\n",
    "- **Estatística descritiva das colunas**: Cálculo de medidas estatísticas como média, mediana, desvio padrão, entre outras, para resumir as características principais das variáveis numéricas e categóricas.\n",
    "\n",
    "## 1.1 Visualização e exploração de dados\n",
    "\n",
    "Nesta subseção, será abordado as técnicas e métodos utilizados para a visualização e exploração inicial dos dados. Através dessas técnicas, é possível obter uma compreensão preliminar da estrutura e das características do conjunto de dados, o que é essencial para orientar as etapas subsequentes da análise.\n",
    "\n",
    "* Dividimos as colunas do DataFrame em categóricas e numéricas para análise e tratamento diferenciados. Isso é útil para entender a estrutura dos dados antes de realizar análises ou pré-processamento.\n",
    "\n",
    "* Então primeiro iremos itentificar as colunas categóricas e numéricas, isso será feito nas primeira linha do código e por fim nas últimas duas colunas exibiremos  a quantidade e os nomes das colunas.\n",
    "\n",
    "Utilizando o comando `shape` abaixo, se observa que há 20 linhas e 293 colunas a serem tratadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.shape #para obter quantidade de linhas e colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o método `.info()` consegue se obter informações detalhadas sobre o DataFrame. Especificamente, ele permite analisar os tipos de variáveis presentes no conjunto de dados.\n",
    "\n",
    "- **Identificação de colunas com variáveis numéricas**: Observando os tipos de dados associados a essas colunas, como valores inteiros (`int64`) e de ponto flutuante (`float64`), que são indicativos de variáveis numéricas.\n",
    "- **Identificação de colunas com variáveis categóricas**: Analisando os tipos de dados (`object` ou `category`) e a quantidade de valores únicos em cada coluna, que geralmente indicam variáveis categóricas.\n",
    "\n",
    "Dessa forma foi observado que a tabela tem 36 colunas do tipo float, 254 do tipo inteiro e 3 do tipo objeto. Informações importantes para o pré-processamento, onde irá ocorrer uma codificação transformando essas colunas categóricas em numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.info() #para obter informações do dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método `.describe()` é utilizado para fornecer um resumo estatístico detalhado das variáveis numéricas. Ao utilizar o `.describe()`, obtemos informações como a média, desvio padrão, valores mínimo e máximo, além dos quartis. Com esses dados é possível entender a distribuição e a variabilidade dos dados, ajudando a identificar padrões, tendências, valores nulos e possíveis *outliers*. Portanto, com esse resumo fica mais prático e rápido na etapa de pré-processamento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.describe() #para obter estatísticas descritivas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Valores Nulos\n",
    "\n",
    "Aqui é feita a verificação de valores nulos no DataFrame utilizando o método `isnull().sum()`. Este método permite contar a quantidade de valores NaN (Not a Number) em cada coluna, facilitando a identificação de colunas que necessitam de tratamento para lidar com dados ausentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.isnull().sum() #para ver contagem de valores NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além disso, é importante verificar a presença de linhas duplicadas no DataFrame. Utilizamos o método `duplicated()` para identificar essas linhas, garantindo que cada entrada no conjunto de dados seja única e evitando redundâncias que possam distorcer a análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados[dados.duplicated(keep='first')] # para identificar linhas duplicadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nas células anteriores foi observado que os valores nulos só se encontram nas colunas categóricas e não nas numéricas. Além disso, não há linhas duplicadas no conjunto de dados.\n",
    "\n",
    "A presença de valores nulos nas colunas categóricas requer um tratamento específico, que pode incluir a imputação de valores ou a exclusão das linhas afetadas, dependendo do contexto e da importância dessas colunas para a análise. A ausência de valores nulos nas colunas numéricas simplifica o pré-processamento dessas variáveis, permitindo uma análise mais direta.\n",
    "\n",
    "Após a análise das colunas categóricas e numéricas será decidido se os valores nulos serão excluídos ou imputados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Identificação e Seleção de Colunas\n",
    "\n",
    "Nesta seção, é realizado a identificação das colunas presentes no dataset, classificando-as em numéricas e categóricas. Essa é uma etapa importante para direcionar as próximas análises, permitindo que possamos aplicar técnicas de estatística descritiva adequadas para cada tipo de dado e preparar as colunas corretamente para o pré-processamento.\n",
    "\n",
    "O código abaixo realiza essa divisão entre colunas categóricas e numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coloca em uma variável chamada colunas categóricas todas as colunas que tem dados do tipo categórico, como nome dos times\n",
    "colunas_categoricas = dados.select_dtypes(include='object').columns\n",
    "#Coloca em uma variável chamada colunas numéricas todas as colunas que tem dados do tipo numérico, como o o número de gols que fez em casa\n",
    "colunas_numericas = dados.drop(colunas_categoricas, axis=1).columns\n",
    "\n",
    "# Imprime a lista de colunas categóricas.\n",
    "print(f'Há {len(colunas_categoricas)} Colunas Categóricas: {list(colunas_categoricas)}')\n",
    "\n",
    "# Imprime a lista de colunas numéricas.\n",
    "print(f'Há {len(colunas_numericas)} Colunas Numéricas: {list(colunas_numericas)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A partir dessa divisão, foi realizada uma análise crítica para determinar quais colunas seriam mantidas no modelo preditivo e quais seriam excluídas, com base em sua relevância e potencial impacto nos resultados.\n",
    "\n",
    "### Colunas Categóricas\n",
    "\n",
    "As colunas categóricas foram analisadas para determinar sua utilidade no modelo. Decidimos manter aquelas que apresentam informações relevantes para a previsão, como o nome dos times e o status das partidas. Colunas que não fornecem valor direto para a análise, como as colunas com nome do time e nome popular, que fornecem a mesma informação, sendo assim algo redundante na base de dados.\n",
    "\n",
    "### Colunas Numéricas\n",
    "\n",
    "As colunas numéricas também passaram por uma avaliação cuidadosa. Mantivemos aquelas que contribuem diretamente para a análise preditiva, como dados de desempenho dos times e estatísticas de jogo. Algumas colunas foram consideradas redundantes ou irrelevantes, como contagens acumulativas ou identificadores temporais, e foram removidas do dataset, ficando 21 categóricas.\n",
    "\n",
    "### Resumo do Dataset\n",
    "\n",
    "A tabela abaixo resume a quantidade de colunas numéricas e categóricas que foram identificadas e mantidas para análise:\n",
    "\n",
    "| Dataset  | Colunas Numéricas | Colunas Categóricas |\n",
    "|----------|-------------------|---------------------|\n",
    "| Teams1  | 290                | 3                   |\n",
    "\n",
    "Após essa filtragem, o dataset ficou mais enxuto e focado, o que nos permitirá conduzir análises mais precisas e relevantes nas etapas subsequentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Visualização de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico 1: Histograma de gols feito em casa com quantidade de times\n",
    "\n",
    "Neste *Histograma* é possível analisar a coluna `total_goal_count_home` que mostra a quantidade de gols feitos em casa no eixo x e quantos times fizeram essa quantidade no eixo y. O histograma é um tipo de gráfico que mostra a distribuição de uma variável numérica, dividindo os valores dessa variável em intervalos. Podendo ser utilizado para entender se um time é mais ofensivo que outro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustando o histograma para que as barras correspondam aos valores exatos de gols\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.histplot(dados['total_goal_count_home'], binwidth=1, kde=False, discrete=True, color='g', )\n",
    "plt.title('Distribuição de Gols Feitos em Casa')\n",
    "plt.xlabel('Gols')\n",
    "plt.ylabel('Quantidade de times')\n",
    "\n",
    "# Definir os valores exatos que devem aparecer no eixo X\n",
    "plt.xticks(ticks=range(int(dados['total_goal_count_home'].min()), int(dados['total_goal_count_home'].max()) + 1))\n",
    "\n",
    "# Mostra o gráfico\n",
    "plt.legend(['Gols Feitos em Casa'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico 2: Comparação do número de vitórias entre times\n",
    "\n",
    "Este gráfico de barras verticais é utilizado para compreender a variação do *número de vitórias* entre os times do campeonato. Cada barra representa um time específico, e a altura da barra indica o número de vitórias que aquele time fez. Permite comparar de forma rápida e visual quais times se destacaram em termos de número de vitórias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Gráfico de Barras: Vitórias por Time\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "# Criar o gráfico de barras\n",
    "sns.barplot(x='common_name', y='wins', data=dados, color='blue')\n",
    "plt.title('Número de Vitórias por Time')\n",
    "plt.xticks(rotation=90)  # Rotacionar os nomes dos times para melhorar a visualização\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Número de Vitórias')\n",
    "\n",
    "# Criar um item de legenda manual\n",
    "blue_patch = mpatches.Patch(color='blue', label='Vitórias')\n",
    "\n",
    "# Adicionar a legenda ao gráfico\n",
    "plt.legend(handles=[blue_patch], loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico 3: Comparação do número de cartões por time\n",
    "\n",
    "Este gráfico de barras horizontais apresenta a distribuição do número total de *cartões recebidos* pelos times ao longo do campeonato. Cada barra representa um time, e sua extensão indica a quantidade de cartões acumulados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de Barras: Número de Cartões por Time (Horizontal e Ordenado)\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "# Ordenar os times com base no número de cartões em ordem decrescente\n",
    "dados_ordenados = dados.sort_values('cards_total', ascending=False)\n",
    "\n",
    "# Usando uma cor sólida (dourado) para as barras\n",
    "sns.barplot(x='cards_total', y='common_name', data=dados_ordenados, color='gold')\n",
    "plt.title('Número de Cartões por Time (Ordenado do Maior para o Menor)')\n",
    "plt.xlabel('Número de Cartões')\n",
    "plt.ylabel('Time')\n",
    "\n",
    "# Criar um item de legenda manual\n",
    "gold_patch = mpatches.Patch(color='gold', label='Cartões')\n",
    "\n",
    "# Adicionar a legenda ao gráfico\n",
    "plt.legend(handles=[gold_patch], loc='lower right', title=\"Legenda\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Resumo das observações\n",
    "Nessa seção será feito um breve resumo do que pode ser observado por meio da exploração de dados.\n",
    "### 1.5.1 Gols feitos em casa com quantidade de times \n",
    "Em relação a distribuição do número de gols marcados pelos times jogando em casa. A maior concentração de times marca entre 20 e 40 gols em casa. Isso sugere que muitos times são consistentes ao jogar em casa, com um desempenho ofensivo similar. A maioria das equipes não fizeram mais que 40 gols, o que pode ser um indicativo de equilíbrio na competição ou um nível semelhante de qualidade entre os times no ataque jogando em casa.\n",
    "\n",
    "### 1.5.2 Número de vitórias entre times \n",
    "A comparação de números de vitórias entre times mostra que algumas equipes com mais vitórias demonstram uma dominância relativa no campeonato. No entanto, a distribuição geral mostra que a maioria dos times tem um número parecido de vitórias, tendo um certo nível de competitividade entre a maioria das equipes.\n",
    "\n",
    "\n",
    "### 1.5.3 Comparação do número de cartões por time \n",
    "Em relação a times que recebem cartões durante os jogos, algumas equipes apresentaram maiores números que podem representar uma abordagem mais agressiva ou menos disciplinada em campo. Os times com menos cartões podem ser mais disciplinados ou menos envolvidos em situações que resultem em cartões, o que pode influenciar diretamente o resultado de suas partidas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Referências\n",
    "\n",
    "Está é uma seção de referências com relação as bibliotecas que utilizamos ao longo deste arquivo\n",
    "\n",
    "NUMPY. NumPy Documentation. Disponível em: <https://numpy.org/doc/>.\n",
    "\n",
    "‌PANDAS. pandas documentation. Disponível em: <https://pandas.pydata.org/docs/>.\n",
    "\n",
    "MATPLOTLIB. Matplotlib: Python plotting — Matplotlib 3.3.4 documentation. Disponível em: <https://matplotlib.org/stable/index.html>.\n",
    "\n",
    "‌SEABORN. seaborn: statistical data visualization — seaborn 0.9.0 documentation. Disponível em: <https://seaborn.pydata.org/>.\n",
    "\n",
    "‌SciPy documentation — SciPy v1.8.1 Manual. Disponível em: <https://docs.scipy.org/doc/scipy/>.\n",
    "\n",
    "‌PYTHON SOFTWARE FOUNDATION. Math — Mathematical Functions — Python 3.8.3rc1 Documentation. Disponível em: <https://docs.python.org/3/library/math.html>.\n",
    "\n",
    "‌SCIKIT-LEARN. scikit-learn: machine learning in Python. Disponível em: <https://scikit-learn.org/stable/>.\n",
    "\n",
    "‌\n",
    "‌\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
